{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé≠ Week 11: LLM Orchestration with Agents and Chains\n",
                "\n",
                "This notebook covers building complex AI systems with chains, agents, and tools.\n",
                "\n",
                "## Table of Contents\n",
                "1. [Orchestration Fundamentals](#1-orchestration-fundamentals)\n",
                "2. [Chains](#2-chains)\n",
                "3. [Tools](#3-tools)\n",
                "4. [Agents](#4-agents)\n",
                "5. [Memory](#5-memory)\n",
                "6. [Building a RAG Agent](#6-building-a-rag-agent)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import sys\n",
                "sys.path.insert(0, '../..')\n",
                "\n",
                "from src.orchestration import (\n",
                "    Chain,\n",
                "    SequentialChain,\n",
                "    ParallelChain,\n",
                "    Agent,\n",
                "    ReActAgent,\n",
                "    Tool,\n",
                "    ToolRegistry,\n",
                "    Memory,\n",
                "    ConversationMemory,\n",
                ")\n",
                "from src.orchestration.orchestration import (\n",
                "    LambdaChain, ConditionalChain, Message, MessageRole,\n",
                "    CalculatorTool, SearchTool\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 1. Orchestration Fundamentals\n",
                "\n",
                "### 1.1 Why Orchestration?\n",
                "\n",
                "Complex AI applications require:\n",
                "- **Multi-step reasoning** - Break complex tasks into steps\n",
                "- **Tool usage** - Access external systems (search, calculate, etc.)\n",
                "- **Memory** - Maintain context across interactions\n",
                "- **Error handling** - Graceful failure recovery\n",
                "\n",
                "### 1.2 Core Concepts\n",
                "\n",
                "```\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ                    ORCHESTRATION                        ‚îÇ\n",
                "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "‚îÇ   CHAINS    ‚îÇ   AGENTS    ‚îÇ   TOOLS     ‚îÇ   MEMORY     ‚îÇ\n",
                "‚îÇ  (compose)  ‚îÇ  (reason)   ‚îÇ  (act)      ‚îÇ  (remember)  ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Chains\n",
                "\n",
                "### 2.1 Sequential Chains\n",
                "\n",
                "Run steps in sequence, output of one becomes input to next."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create processing pipeline\n",
                "pipeline = SequentialChain([\n",
                "    LambdaChain(lambda x: x.strip().lower(), name=\"normalize\"),\n",
                "    LambdaChain(lambda x: x.replace(\"  \", \" \"), name=\"clean_spaces\"),\n",
                "    LambdaChain(lambda x: x.title(), name=\"title_case\"),\n",
                "])\n",
                "\n",
                "# Test\n",
                "input_text = \"  HELLO   WORLD  \"\n",
                "result = pipeline.run(input_text)\n",
                "\n",
                "print(f\"Input:  '{input_text}'\")\n",
                "print(f\"Output: '{result}'\")\n",
                "print(\"\\n‚úÖ Text normalized through 3-step pipeline!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Document Processing Pipeline\n",
                "def extract_keywords(text):\n",
                "    \"\"\"Extract key terms from text.\"\"\"\n",
                "    words = text.lower().split()\n",
                "    stopwords = {'the', 'is', 'a', 'an', 'and', 'or', 'to', 'of', 'in'}\n",
                "    keywords = [w for w in words if w not in stopwords and len(w) > 3]\n",
                "    return list(set(keywords))[:5]\n",
                "\n",
                "def summarize(keywords):\n",
                "    \"\"\"Create simple summary from keywords.\"\"\"\n",
                "    return f\"Document about: {', '.join(keywords)}\"\n",
                "\n",
                "doc_pipeline = SequentialChain([\n",
                "    LambdaChain(extract_keywords, name=\"extract\"),\n",
                "    LambdaChain(summarize, name=\"summarize\"),\n",
                "])\n",
                "\n",
                "doc = \"Machine learning is a subset of artificial intelligence that enables computers to learn from data.\"\n",
                "summary = doc_pipeline.run(doc)\n",
                "\n",
                "print(f\"Document: {doc[:50]}...\")\n",
                "print(f\"Summary:  {summary}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Parallel Chains\n",
                "\n",
                "Run multiple chains simultaneously on the same input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parallel analysis\n",
                "parallel = ParallelChain([\n",
                "    LambdaChain(lambda x: len(x), name=\"count_chars\"),\n",
                "    LambdaChain(lambda x: len(x.split()), name=\"count_words\"),\n",
                "    LambdaChain(lambda x: x.upper(), name=\"uppercase\"),\n",
                "])\n",
                "\n",
                "text = \"Hello world from parallel chains\"\n",
                "results = parallel.run(text)\n",
                "\n",
                "print(f\"Input: '{text}'\")\n",
                "print(f\"\\nResults:\")\n",
                "print(f\"  Char count:  {results[0]}\")\n",
                "print(f\"  Word count:  {results[1]}\")\n",
                "print(f\"  Uppercase:   {results[2]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Conditional Chains\n",
                "\n",
                "Route to different chains based on conditions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Conditional routing\n",
                "router = ConditionalChain(\n",
                "    condition=lambda x: len(x) > 20,\n",
                "    if_true=LambdaChain(lambda x: f\"LONG: {x[:20]}...\"),\n",
                "    if_false=LambdaChain(lambda x: f\"SHORT: {x}\")\n",
                ")\n",
                "\n",
                "short_text = \"Hello!\"\n",
                "long_text = \"This is a much longer piece of text that exceeds the limit.\"\n",
                "\n",
                "print(f\"Short: {router.run(short_text)}\")\n",
                "print(f\"Long:  {router.run(long_text)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Tools\n",
                "\n",
                "### 3.1 Creating Custom Tools"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.orchestration.orchestration import Tool, ToolResult\n",
                "\n",
                "class WeatherTool(Tool):\n",
                "    \"\"\"Tool to get weather information.\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        super().__init__(\n",
                "            name=\"weather\",\n",
                "            description=\"Get current weather for a location\",\n",
                "            parameters={\"location\": \"City name or coordinates\"}\n",
                "        )\n",
                "    \n",
                "    def run(self, location: str = \"\", **kwargs) -> ToolResult:\n",
                "        # Mock weather data\n",
                "        weather_data = {\n",
                "            \"london\": \"Cloudy, 12¬∞C\",\n",
                "            \"new york\": \"Sunny, 22¬∞C\",\n",
                "            \"tokyo\": \"Rainy, 18¬∞C\",\n",
                "        }\n",
                "        \n",
                "        location_lower = location.lower()\n",
                "        if location_lower in weather_data:\n",
                "            return ToolResult(output=weather_data[location_lower], success=True)\n",
                "        else:\n",
                "            return ToolResult(\n",
                "                output=None, \n",
                "                success=False, \n",
                "                error=f\"Weather data not available for {location}\"\n",
                "            )\n",
                "\n",
                "class DatabaseTool(Tool):\n",
                "    \"\"\"Tool to query a database.\"\"\"\n",
                "    \n",
                "    def __init__(self, data: dict):\n",
                "        super().__init__(\n",
                "            name=\"database\",\n",
                "            description=\"Query information from the database\",\n",
                "            parameters={\"query\": \"Search query\"}\n",
                "        )\n",
                "        self.data = data\n",
                "    \n",
                "    def run(self, query: str = \"\", **kwargs) -> ToolResult:\n",
                "        # Simple keyword search\n",
                "        results = [\n",
                "            v for k, v in self.data.items() \n",
                "            if query.lower() in k.lower()\n",
                "        ]\n",
                "        \n",
                "        if results:\n",
                "            return ToolResult(output=results, success=True)\n",
                "        else:\n",
                "            return ToolResult(output=\"No results found\", success=True)\n",
                "\n",
                "# Test tools\n",
                "weather = WeatherTool()\n",
                "result = weather.run(location=\"London\")\n",
                "print(f\"Weather in London: {result.output}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Tool Registry"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create tool registry\n",
                "registry = ToolRegistry()\n",
                "\n",
                "# Register tools\n",
                "registry.register(CalculatorTool())\n",
                "registry.register(SearchTool())\n",
                "registry.register(WeatherTool())\n",
                "\n",
                "# List available tools\n",
                "print(\"Available Tools:\")\n",
                "print(registry.to_prompt())\n",
                "\n",
                "# Use a tool\n",
                "calc = registry.get(\"calculator\")\n",
                "result = calc.run(expression=\"2 * 3 + 5\")\n",
                "print(f\"\\nCalculation: 2 * 3 + 5 = {result.output}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Agents\n",
                "\n",
                "### 4.1 The ReAct Pattern\n",
                "\n",
                "ReAct (Reasoning + Acting) agents interleave:\n",
                "1. **Thought** - Reason about what to do\n",
                "2. **Action** - Use a tool\n",
                "3. **Observation** - See the result\n",
                "4. **Repeat** until done\n",
                "\n",
                "```\n",
                "Question: What is 25% of 80?\n",
                "\n",
                "Thought: I need to calculate 25% of 80. I'll use the calculator.\n",
                "Action: calculator\n",
                "Action Input: 80 * 0.25\n",
                "Observation: 20\n",
                "\n",
                "Thought: I now have the answer.\n",
                "Action: finish\n",
                "Action Input: 25% of 80 is 20\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ReAct agent\n",
                "agent = ReActAgent(tools=registry)\n",
                "\n",
                "print(\"ReAct Agent Initialized\")\n",
                "print(\"=\" * 40)\n",
                "print(f\"Tools: {[t.name for t in registry.list_tools()]}\")\n",
                "print(\"\\nAgent prompt template:\")\n",
                "print(agent.REACT_PROMPT[:300] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Memory\n",
                "\n",
                "### 5.1 Conversation Memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create conversation memory\n",
                "memory = ConversationMemory(max_messages=10)\n",
                "\n",
                "# Add messages\n",
                "memory.add_message(Message(role=MessageRole.USER, content=\"What is machine learning?\"))\n",
                "memory.add_message(Message(role=MessageRole.ASSISTANT, content=\"Machine learning is a subset of AI that enables computers to learn from data.\"))\n",
                "memory.add_message(Message(role=MessageRole.USER, content=\"Can you give an example?\"))\n",
                "memory.add_message(Message(role=MessageRole.ASSISTANT, content=\"A common example is spam email detection.\"))\n",
                "\n",
                "# Get context\n",
                "print(\"Conversation Context:\")\n",
                "print(\"=\" * 40)\n",
                "print(memory.to_context())\n",
                "\n",
                "print(f\"\\nTotal messages: {len(memory.messages)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use memory with chains\n",
                "def respond_with_context(query, memory):\n",
                "    \"\"\"Generate response using conversation context.\"\"\"\n",
                "    context = memory.to_context()\n",
                "    \n",
                "    # In real implementation, this would use an LLM\n",
                "    response = f\"Based on our conversation about ML and spam detection, here's more info about: {query}\"\n",
                "    \n",
                "    # Update memory\n",
                "    memory.add_message(Message(role=MessageRole.USER, content=query))\n",
                "    memory.add_message(Message(role=MessageRole.ASSISTANT, content=response))\n",
                "    \n",
                "    return response\n",
                "\n",
                "# Test\n",
                "response = respond_with_context(\"How accurate is spam detection?\", memory)\n",
                "print(f\"Response: {response}\")\n",
                "print(f\"\\nMemory now has {len(memory.messages)} messages\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Building a RAG Agent\n",
                "\n",
                "### 6.1 Putting It All Together"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RAGAgent:\n",
                "    \"\"\"\n",
                "    Complete RAG agent with retrieval, reasoning, and tools.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, documents: list):\n",
                "        # Initialize components\n",
                "        self.memory = ConversationMemory(max_messages=20)\n",
                "        \n",
                "        # Tools\n",
                "        self.tools = ToolRegistry()\n",
                "        self.tools.register(CalculatorTool())\n",
                "        \n",
                "        # Simple retriever (use BM25 in production)\n",
                "        self.documents = documents\n",
                "    \n",
                "    def retrieve(self, query: str, top_k: int = 3) -> list:\n",
                "        \"\"\"Simple retrieval (production: use BM25/Dense).\"\"\"\n",
                "        query_words = set(query.lower().split())\n",
                "        scored = []\n",
                "        \n",
                "        for doc in self.documents:\n",
                "            doc_words = set(doc.lower().split())\n",
                "            score = len(query_words & doc_words)\n",
                "            scored.append((doc, score))\n",
                "        \n",
                "        scored.sort(key=lambda x: -x[1])\n",
                "        return [doc for doc, _ in scored[:top_k]]\n",
                "    \n",
                "    def answer(self, question: str) -> str:\n",
                "        \"\"\"Answer question using RAG.\"\"\"\n",
                "        # 1. Retrieve relevant context\n",
                "        context = self.retrieve(question)\n",
                "        \n",
                "        # 2. Build prompt\n",
                "        context_str = \"\\n\".join(f\"- {doc}\" for doc in context)\n",
                "        \n",
                "        # 3. Generate answer (mock - use LLM in production)\n",
                "        answer = f\"Based on the context, {context[0][:50]}...\"\n",
                "        \n",
                "        # 4. Update memory\n",
                "        self.memory.add_message(Message(role=MessageRole.USER, content=question))\n",
                "        self.memory.add_message(Message(role=MessageRole.ASSISTANT, content=answer))\n",
                "        \n",
                "        return {\n",
                "            \"answer\": answer,\n",
                "            \"context\": context,\n",
                "            \"sources\": len(context)\n",
                "        }\n",
                "\n",
                "# Test RAG agent\n",
                "documents = [\n",
                "    \"Machine learning enables computers to learn from data.\",\n",
                "    \"Deep learning uses neural networks with many layers.\",\n",
                "    \"Natural language processing helps computers understand text.\",\n",
                "]\n",
                "\n",
                "rag = RAGAgent(documents)\n",
                "result = rag.answer(\"What is machine learning?\")\n",
                "\n",
                "print(\"RAG Agent Response:\")\n",
                "print(\"=\" * 40)\n",
                "print(f\"Answer: {result['answer']}\")\n",
                "print(f\"Sources used: {result['sources']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Summary\n",
                "\n",
                "### Key Concepts\n",
                "\n",
                "| Component | Purpose | Example |\n",
                "|-----------|---------|--------|\n",
                "| **Chain** | Compose processing steps | Sequential, Parallel |\n",
                "| **Tool** | Extend agent capabilities | Calculator, Search |\n",
                "| **Agent** | Autonomous reasoning | ReAct pattern |\n",
                "| **Memory** | Maintain context | Conversation history |\n",
                "\n",
                "### Best Practices\n",
                "\n",
                "1. **Keep chains simple** - Single responsibility per step\n",
                "2. **Make tools atomic** - One clear purpose per tool\n",
                "3. **Limit agent iterations** - Prevent infinite loops\n",
                "4. **Manage memory size** - Use sliding window\n",
                "5. **Handle errors gracefully** - Tools should not crash agents"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}