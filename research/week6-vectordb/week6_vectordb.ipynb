{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ—„ï¸ Week 6: Vector Database Integration\n",
                "\n",
                "**Learning Objectives:**\n",
                "1. Understand vector databases vs traditional databases\n",
                "2. Implement semantic search with pgvector/Qdrant\n",
                "3. Build efficient indexing strategies\n",
                "4. Optimize query performance\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import time\n",
                "from typing import List, Tuple\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 1: Theory\n",
                "---\n",
                "\n",
                "## Vector DB vs Relational DB\n",
                "\n",
                "| Feature | Relational DB | Vector DB |\n",
                "|---------|--------------|----------|\n",
                "| Query Type | Exact match | Similarity |\n",
                "| Data Type | Structured | Embeddings |\n",
                "| Index | B-tree | HNSW, IVF |\n",
                "| Use Case | CRUD | Semantic Search |\n",
                "\n",
                "## Popular Vector Databases\n",
                "- **pgvector**: PostgreSQL extension (self-hosted)\n",
                "- **Qdrant**: Purpose-built (cloud/self-hosted)\n",
                "- **Pinecone**: Managed service\n",
                "- **Weaviate**: Open-source, full-featured"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 2: Hands-On Implementation\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.1 Simple In-Memory Vector Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleVectorStore:\n",
                "    \"\"\"Simple in-memory vector store for learning.\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.vectors = []\n",
                "        self.metadata = []\n",
                "        self.ids = []\n",
                "    \n",
                "    def add(self, id: str, vector: np.ndarray, metadata: dict = None):\n",
                "        \"\"\"Add a vector to the store.\"\"\"\n",
                "        self.ids.append(id)\n",
                "        self.vectors.append(vector)\n",
                "        self.metadata.append(metadata or {})\n",
                "    \n",
                "    def search(self, query: np.ndarray, top_k: int = 5) -> List[Tuple[str, float, dict]]:\n",
                "        \"\"\"Search for similar vectors using cosine similarity.\"\"\"\n",
                "        if not self.vectors:\n",
                "            return []\n",
                "        \n",
                "        # Compute similarities\n",
                "        similarities = []\n",
                "        query_norm = np.linalg.norm(query)\n",
                "        \n",
                "        for i, vec in enumerate(self.vectors):\n",
                "            sim = np.dot(query, vec) / (query_norm * np.linalg.norm(vec))\n",
                "            similarities.append((self.ids[i], sim, self.metadata[i]))\n",
                "        \n",
                "        # Sort by similarity\n",
                "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
                "        return similarities[:top_k]\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.vectors)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test vector store\n",
                "store = SimpleVectorStore()\n",
                "\n",
                "# Add sample documents\n",
                "documents = [\n",
                "    (\"doc1\", \"Machine learning fundamentals\", np.random.randn(384)),\n",
                "    (\"doc2\", \"Deep neural networks\", np.random.randn(384)),\n",
                "    (\"doc3\", \"Python programming\", np.random.randn(384)),\n",
                "    (\"doc4\", \"Natural language processing\", np.random.randn(384)),\n",
                "]\n",
                "\n",
                "for doc_id, text, vec in documents:\n",
                "    store.add(doc_id, vec, {\"text\": text})\n",
                "\n",
                "# Search\n",
                "query_vector = np.random.randn(384)\n",
                "results = store.search(query_vector, top_k=3)\n",
                "\n",
                "print(\"Search Results:\")\n",
                "for doc_id, score, meta in results:\n",
                "    print(f\"  {doc_id}: {meta['text']} (score: {score:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 HNSW Index (Conceptual)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleHNSW:\n",
                "    \"\"\"\n",
                "    Simplified HNSW-like index (conceptual demo).\n",
                "    Real HNSW uses multiple layers and more sophisticated graph construction.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, m=16):\n",
                "        self.m = m  # Max connections per node\n",
                "        self.vectors = []\n",
                "        self.graph = {}  # Adjacency list\n",
                "    \n",
                "    def _distance(self, a, b):\n",
                "        return 1 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
                "    \n",
                "    def add(self, vector):\n",
                "        idx = len(self.vectors)\n",
                "        self.vectors.append(vector)\n",
                "        \n",
                "        if idx == 0:\n",
                "            self.graph[0] = []\n",
                "            return\n",
                "        \n",
                "        # Find M nearest neighbors\n",
                "        distances = [(i, self._distance(vector, v)) for i, v in enumerate(self.vectors[:-1])]\n",
                "        distances.sort(key=lambda x: x[1])\n",
                "        neighbors = [d[0] for d in distances[:self.m]]\n",
                "        \n",
                "        # Add edges\n",
                "        self.graph[idx] = neighbors\n",
                "        for n in neighbors:\n",
                "            if n not in self.graph:\n",
                "                self.graph[n] = []\n",
                "            self.graph[n].append(idx)\n",
                "    \n",
                "    def search(self, query, k=5, ef=50):\n",
                "        \"\"\"Greedy search through graph.\"\"\"\n",
                "        if not self.vectors:\n",
                "            return []\n",
                "        \n",
                "        # Start from random entry point\n",
                "        entry = 0\n",
                "        visited = {entry}\n",
                "        candidates = [(self._distance(query, self.vectors[entry]), entry)]\n",
                "        \n",
                "        while candidates:\n",
                "            dist, current = min(candidates)\n",
                "            candidates.remove((dist, current))\n",
                "            \n",
                "            for neighbor in self.graph.get(current, []):\n",
                "                if neighbor not in visited:\n",
                "                    visited.add(neighbor)\n",
                "                    d = self._distance(query, self.vectors[neighbor])\n",
                "                    candidates.append((d, neighbor))\n",
                "            \n",
                "            if len(visited) >= ef:\n",
                "                break\n",
                "        \n",
                "        # Return top-k\n",
                "        results = [(self._distance(query, self.vectors[i]), i) for i in visited]\n",
                "        results.sort()\n",
                "        return [(idx, 1 - dist) for dist, idx in results[:k]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test HNSW\n",
                "hnsw = SimpleHNSW(m=8)\n",
                "\n",
                "# Add vectors\n",
                "for _ in range(100):\n",
                "    hnsw.add(np.random.randn(128))\n",
                "\n",
                "# Search\n",
                "query = np.random.randn(128)\n",
                "results = hnsw.search(query, k=5)\n",
                "\n",
                "print(\"HNSW Search Results:\")\n",
                "for idx, score in results:\n",
                "    print(f\"  Index {idx}: score {score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.3 pgvector SQL Examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pgvector_sql = \"\"\"\n",
                "-- Enable pgvector extension\n",
                "CREATE EXTENSION IF NOT EXISTS vector;\n",
                "\n",
                "-- Create table with vector column\n",
                "CREATE TABLE documents (\n",
                "    id SERIAL PRIMARY KEY,\n",
                "    content TEXT NOT NULL,\n",
                "    embedding vector(384),  -- 384-dimensional vector\n",
                "    metadata JSONB,\n",
                "    created_at TIMESTAMP DEFAULT NOW()\n",
                ");\n",
                "\n",
                "-- Create HNSW index for fast similarity search\n",
                "CREATE INDEX ON documents \n",
                "USING hnsw (embedding vector_cosine_ops)\n",
                "WITH (m = 16, ef_construction = 64);\n",
                "\n",
                "-- Insert document with embedding\n",
                "INSERT INTO documents (content, embedding, metadata)\n",
                "VALUES (\n",
                "    'Machine learning tutorial',\n",
                "    '[0.1, 0.2, 0.3, ...]'::vector,\n",
                "    '{\"category\": \"tutorial\", \"author\": \"john\"}'\n",
                ");\n",
                "\n",
                "-- Semantic search query\n",
                "SELECT id, content, \n",
                "       1 - (embedding <=> $1::vector) as similarity\n",
                "FROM documents\n",
                "ORDER BY embedding <=> $1::vector\n",
                "LIMIT 10;\n",
                "\n",
                "-- Filtered search\n",
                "SELECT id, content, \n",
                "       1 - (embedding <=> $1::vector) as similarity\n",
                "FROM documents\n",
                "WHERE metadata->>'category' = 'tutorial'\n",
                "ORDER BY embedding <=> $1::vector\n",
                "LIMIT 5;\n",
                "\"\"\"\n",
                "print(pgvector_sql)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 3: Performance Comparison\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare brute-force vs indexed search\n",
                "def benchmark_search(n_vectors, dim=128):\n",
                "    vectors = [np.random.randn(dim) for _ in range(n_vectors)]\n",
                "    query = np.random.randn(dim)\n",
                "    \n",
                "    # Brute force\n",
                "    start = time.time()\n",
                "    store = SimpleVectorStore()\n",
                "    for i, v in enumerate(vectors):\n",
                "        store.add(str(i), v)\n",
                "    store.search(query, top_k=5)\n",
                "    brute_time = time.time() - start\n",
                "    \n",
                "    # HNSW\n",
                "    start = time.time()\n",
                "    hnsw = SimpleHNSW(m=16)\n",
                "    for v in vectors:\n",
                "        hnsw.add(v)\n",
                "    hnsw.search(query, k=5)\n",
                "    hnsw_time = time.time() - start\n",
                "    \n",
                "    return brute_time, hnsw_time\n",
                "\n",
                "# Run benchmark\n",
                "sizes = [100, 500, 1000, 2000]\n",
                "brute_times = []\n",
                "hnsw_times = []\n",
                "\n",
                "for n in sizes:\n",
                "    bt, ht = benchmark_search(n)\n",
                "    brute_times.append(bt)\n",
                "    hnsw_times.append(ht)\n",
                "    print(f\"n={n}: Brute={bt:.4f}s, HNSW={ht:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(sizes, brute_times, 'o-', label='Brute Force')\n",
                "plt.plot(sizes, hnsw_times, 's-', label='HNSW-like')\n",
                "plt.xlabel('Number of Vectors')\n",
                "plt.ylabel('Time (seconds)')\n",
                "plt.title('Search Performance Comparison')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 4: Unit Tests\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_tests():\n",
                "    print(\"Running Unit Tests...\\n\")\n",
                "    \n",
                "    # Test 1: Add and retrieve\n",
                "    store = SimpleVectorStore()\n",
                "    store.add(\"1\", np.array([1, 0, 0]))\n",
                "    assert len(store) == 1\n",
                "    print(\"âœ“ Add vector test passed\")\n",
                "    \n",
                "    # Test 2: Exact match search\n",
                "    results = store.search(np.array([1, 0, 0]), top_k=1)\n",
                "    assert results[0][0] == \"1\"\n",
                "    assert abs(results[0][1] - 1.0) < 1e-6\n",
                "    print(\"âœ“ Exact match search test passed\")\n",
                "    \n",
                "    # Test 3: Multiple vectors\n",
                "    store.add(\"2\", np.array([0, 1, 0]))\n",
                "    store.add(\"3\", np.array([0.9, 0.1, 0]))\n",
                "    results = store.search(np.array([1, 0, 0]), top_k=2)\n",
                "    assert results[0][0] == \"1\" or results[0][0] == \"3\"\n",
                "    print(\"âœ“ Multiple vectors test passed\")\n",
                "    \n",
                "    print(\"\\nðŸŽ‰ All tests passed!\")\n",
                "\n",
                "run_tests()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 5: Interview Prep\n",
                "---\n",
                "\n",
                "### Q1: When to use vector DB vs relational DB?\n",
                "**Answer:** Vector DB for similarity search on embeddings. Relational for structured queries, transactions.\n",
                "\n",
                "### Q2: What is HNSW and why is it fast?\n",
                "**Answer:** Hierarchical Navigable Small World graphs. Uses skip-list layers + greedy search. O(log n) vs O(n).\n",
                "\n",
                "### Q3: Trade-offs of pgvector vs Qdrant?\n",
                "**Answer:** pgvector: simpler, SQL integration. Qdrant: better performance at scale, more features.\n",
                "\n",
                "---\n",
                "# Section 6: Deliverable\n",
                "---\n",
                "\n",
                "**Created:** `vector_db_demo.py` with vector store, search, indexing\n",
                "\n",
                "**Next Week:** Hybrid Retrieval (Lexical + Semantic)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}