{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CNN Architecture Deep Dive\n",
                "\n",
                "Understanding Convolutional Neural Networks for image classification.\n",
                "\n",
                "## Topics\n",
                "1. Convolution operation\n",
                "2. Pooling layers\n",
                "3. Building a CNN from scratch\n",
                "4. Evaluation metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Convolution Operation\n",
                "\n",
                "A convolution slides a kernel across the input, computing dot products:\n",
                "\n",
                "$$(I * K)_{ij} = \\sum_m \\sum_n I_{i+m, j+n} \\cdot K_{m,n}$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def conv2d(image, kernel, stride=1, padding=0):\n",
                "    \"\"\"2D convolution from scratch.\n",
                "    \n",
                "    Args:\n",
                "        image: (H, W) input\n",
                "        kernel: (kH, kW) filter\n",
                "        stride: step size\n",
                "        padding: zero padding\n",
                "    \"\"\"\n",
                "    if padding > 0:\n",
                "        image = np.pad(image, padding, mode='constant')\n",
                "    \n",
                "    H, W = image.shape\n",
                "    kH, kW = kernel.shape\n",
                "    \n",
                "    out_H = (H - kH) // stride + 1\n",
                "    out_W = (W - kW) // stride + 1\n",
                "    \n",
                "    output = np.zeros((out_H, out_W))\n",
                "    \n",
                "    for i in range(out_H):\n",
                "        for j in range(out_W):\n",
                "            region = image[i*stride:i*stride+kH, j*stride:j*stride+kW]\n",
                "            output[i, j] = np.sum(region * kernel)\n",
                "    \n",
                "    return output\n",
                "\n",
                "# Example: Edge detection\n",
                "image = np.array([\n",
                "    [0, 0, 0, 0, 0],\n",
                "    [0, 1, 1, 1, 0],\n",
                "    [0, 1, 1, 1, 0],\n",
                "    [0, 1, 1, 1, 0],\n",
                "    [0, 0, 0, 0, 0]\n",
                "], dtype=float)\n",
                "\n",
                "# Sobel edge detector\n",
                "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
                "\n",
                "edges = conv2d(image, sobel_x)\n",
                "print('Edge detection result:')\n",
                "print(edges)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Pooling Layers\n",
                "\n",
                "Reduce spatial dimensions while keeping important features:\n",
                "- **Max Pooling**: Take maximum in each region\n",
                "- **Average Pooling**: Take average"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def max_pool2d(x, pool_size=2):\n",
                "    \"\"\"Max pooling from scratch.\"\"\"\n",
                "    H, W = x.shape\n",
                "    out_H = H // pool_size\n",
                "    out_W = W // pool_size\n",
                "    \n",
                "    output = np.zeros((out_H, out_W))\n",
                "    \n",
                "    for i in range(out_H):\n",
                "        for j in range(out_W):\n",
                "            region = x[i*pool_size:(i+1)*pool_size, \n",
                "                      j*pool_size:(j+1)*pool_size]\n",
                "            output[i, j] = np.max(region)\n",
                "    \n",
                "    return output\n",
                "\n",
                "# Example\n",
                "feature_map = np.array([\n",
                "    [1, 3, 2, 4],\n",
                "    [5, 6, 1, 2],\n",
                "    [7, 2, 3, 1],\n",
                "    [4, 5, 6, 8]\n",
                "], dtype=float)\n",
                "\n",
                "pooled = max_pool2d(feature_map, 2)\n",
                "print('Max pooling 4x4 -> 2x2:')\n",
                "print(pooled)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Activation Functions\n",
                "\n",
                "Introduce non-linearity so networks can learn complex patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def relu(x):\n",
                "    \"\"\"ReLU: max(0, x)\"\"\"\n",
                "    return np.maximum(0, x)\n",
                "\n",
                "def sigmoid(x):\n",
                "    \"\"\"Sigmoid: 1 / (1 + e^-x)\"\"\"\n",
                "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
                "\n",
                "def softmax(x):\n",
                "    \"\"\"Softmax for classification.\"\"\"\n",
                "    x_shifted = x - np.max(x)\n",
                "    exp_x = np.exp(x_shifted)\n",
                "    return exp_x / np.sum(exp_x)\n",
                "\n",
                "# Visualization\n",
                "x = np.linspace(-5, 5, 100)\n",
                "plt.figure(figsize=(10, 3))\n",
                "plt.subplot(131); plt.plot(x, relu(x)); plt.title('ReLU')\n",
                "plt.subplot(132); plt.plot(x, sigmoid(x)); plt.title('Sigmoid')\n",
                "plt.subplot(133); plt.plot(x, np.tanh(x)); plt.title('Tanh')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Simple CNN Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleCNN:\n",
                "    \"\"\"Minimal CNN for understanding.\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        # Learnable filters (normally random init)\n",
                "        self.conv1_filters = np.random.randn(4, 3, 3) * 0.1\n",
                "        self.fc_weights = None  # Set after first forward\n",
                "    \n",
                "    def forward(self, x):\n",
                "        \"\"\"Forward pass: Conv -> ReLU -> Pool -> FC.\"\"\"\n",
                "        \n",
                "        # Conv layer (4 filters)\n",
                "        conv_out = []\n",
                "        for f in self.conv1_filters:\n",
                "            conv_out.append(conv2d(x, f, padding=1))\n",
                "        conv_out = np.stack(conv_out)  # (4, H, W)\n",
                "        \n",
                "        # ReLU\n",
                "        relu_out = relu(conv_out)\n",
                "        \n",
                "        # Max pooling\n",
                "        pool_out = []\n",
                "        for fm in relu_out:\n",
                "            pool_out.append(max_pool2d(fm, 2))\n",
                "        pool_out = np.stack(pool_out)\n",
                "        \n",
                "        # Flatten\n",
                "        flat = pool_out.flatten()\n",
                "        \n",
                "        # FC layer (init if needed)\n",
                "        if self.fc_weights is None:\n",
                "            self.fc_weights = np.random.randn(flat.shape[0], 10) * 0.1\n",
                "        \n",
                "        # Output logits\n",
                "        logits = flat @ self.fc_weights\n",
                "        probs = softmax(logits)\n",
                "        \n",
                "        return probs\n",
                "\n",
                "# Test\n",
                "cnn = SimpleCNN()\n",
                "dummy_image = np.random.randn(28, 28)\n",
                "probs = cnn.forward(dummy_image)\n",
                "print(f'Output probabilities: {probs}')\n",
                "print(f'Predicted class: {np.argmax(probs)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation Metrics\n",
                "\n",
                "For classification tasks:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(y_true, y_pred):\n",
                "    \"\"\"Compute classification metrics.\n",
                "    \n",
                "    Returns:\n",
                "        accuracy, precision, recall, specificity, f1\n",
                "    \"\"\"\n",
                "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
                "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
                "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
                "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
                "    \n",
                "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
                "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
                "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity\n",
                "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
                "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
                "    \n",
                "    return {\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'specificity': specificity,\n",
                "        'f1': f1\n",
                "    }\n",
                "\n",
                "# Example\n",
                "y_true = np.array([1, 1, 1, 0, 0, 0, 1, 0, 1, 0])\n",
                "y_pred = np.array([1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
                "\n",
                "metrics = compute_metrics(y_true, y_pred)\n",
                "for name, value in metrics.items():\n",
                "    print(f'{name}: {value:.3f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "| Component | Purpose | Math |\n",
                "|-----------|---------|------|\n",
                "| Convolution | Feature extraction | $\\sum I \\cdot K$ |\n",
                "| ReLU | Non-linearity | max(0, x) |\n",
                "| Pooling | Downsampling | max/avg over region |\n",
                "| FC Layer | Classification | Wx + b |\n",
                "| Softmax | Probabilities | $e^{z_i}/\\sum e^{z_j}$ |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}