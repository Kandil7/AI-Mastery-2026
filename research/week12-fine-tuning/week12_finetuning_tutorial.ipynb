{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ”§ Week 12: Fine-Tuning LLMs\n",
                "\n",
                "This notebook covers fine-tuning techniques for large language models.\n",
                "\n",
                "## Table of Contents\n",
                "1. [Fine-Tuning Fundamentals](#1-fine-tuning-fundamentals)\n",
                "2. [Full Fine-Tuning](#2-full-fine-tuning)\n",
                "3. [Parameter-Efficient Methods](#3-parameter-efficient-methods)\n",
                "4. [LoRA Deep Dive](#4-lora-deep-dive)\n",
                "5. [Training Best Practices](#5-training-best-practices)\n",
                "6. [Evaluation and Iteration](#6-evaluation-and-iteration)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Fine-Tuning Fundamentals\n",
                "\n",
                "### 1.1 Why Fine-Tune?\n",
                "\n",
                "| Approach | When to Use | Example |\n",
                "|----------|-------------|--------|\n",
                "| **Prompting** | Simple tasks, no data | Zero-shot classification |\n",
                "| **Few-shot** | Limited examples | In-context learning |\n",
                "| **Fine-tuning** | Specific domain/task | Legal document Q&A |\n",
                "\n",
                "### 1.2 Types of Fine-Tuning\n",
                "\n",
                "```\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚           FINE-TUNING SPECTRUM                  â”‚\n",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
                "â”‚  Full       â”‚   PEFT      â”‚   Prompting        â”‚\n",
                "â”‚  Fine-Tune  â”‚   (LoRA)    â”‚   Only             â”‚\n",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
                "â”‚ All params  â”‚ Few params  â”‚ No training        â”‚\n",
                "â”‚ Most data   â”‚ Less data   â”‚ Minimal data       â”‚\n",
                "â”‚ Best perf   â”‚ Good perf   â”‚ Quick iteration    â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example training data format\n",
                "training_examples = [\n",
                "    {\n",
                "        \"instruction\": \"Summarize the following text.\",\n",
                "        \"input\": \"Machine learning is a subset of artificial intelligence...\",\n",
                "        \"output\": \"ML is an AI subfield that enables learning from data.\"\n",
                "    },\n",
                "    {\n",
                "        \"instruction\": \"Classify the sentiment of this review.\",\n",
                "        \"input\": \"This product exceeded my expectations!\",\n",
                "        \"output\": \"Positive\"\n",
                "    }\n",
                "]\n",
                "\n",
                "print(\"Training data format:\")\n",
                "for i, ex in enumerate(training_examples):\n",
                "    print(f\"\\nExample {i+1}:\")\n",
                "    print(f\"  Instruction: {ex['instruction']}\")\n",
                "    print(f\"  Input: {ex['input'][:40]}...\")\n",
                "    print(f\"  Output: {ex['output']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Full Fine-Tuning\n",
                "\n",
                "### 2.1 When to Use Full Fine-Tuning\n",
                "\n",
                "âœ… **Good for:**\n",
                "- Large datasets (10K+ examples)\n",
                "- Maximum performance required\n",
                "- Significant domain shift\n",
                "\n",
                "âŒ **Drawbacks:**\n",
                "- Requires significant compute\n",
                "- Risk of catastrophic forgetting\n",
                "- Full model storage needed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pseudocode for full fine-tuning\n",
                "print(\"\"\"\n",
                "Full Fine-Tuning Pipeline:\n",
                "==========================\n",
                "\n",
                "1. Load pre-trained model\n",
                "   model = AutoModelForCausalLM.from_pretrained(\"base-model\")\n",
                "   \n",
                "2. Prepare dataset\n",
                "   dataset = load_and_format_data()\n",
                "   \n",
                "3. Configure training\n",
                "   training_args = TrainingArguments(\n",
                "       learning_rate=2e-5,\n",
                "       num_train_epochs=3,\n",
                "       per_device_train_batch_size=4,\n",
                "       gradient_accumulation_steps=4,\n",
                "   )\n",
                "   \n",
                "4. Train\n",
                "   trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
                "   trainer.train()\n",
                "   \n",
                "5. Save\n",
                "   model.save_pretrained(\"fine-tuned-model\")\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Parameter-Efficient Methods\n",
                "\n",
                "### 3.1 PEFT Overview\n",
                "\n",
                "| Method | Trainable Params | Memory | Quality |\n",
                "|--------|-----------------|--------|--------|\n",
                "| **LoRA** | ~0.1% | Low | High |\n",
                "| **QLoRA** | ~0.1% | Very Low | High |\n",
                "| **Prefix Tuning** | ~1% | Low | Medium |\n",
                "| **Prompt Tuning** | <0.1% | Very Low | Medium |\n",
                "| **Adapters** | ~1-3% | Low | High |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comparison of trainable parameters\n",
                "model_params = 7_000_000_000  # 7B model\n",
                "\n",
                "methods = {\n",
                "    \"Full Fine-Tune\": 1.0,\n",
                "    \"Adapters\": 0.03,\n",
                "    \"Prefix Tuning\": 0.01,\n",
                "    \"LoRA\": 0.001,\n",
                "    \"Prompt Tuning\": 0.0001,\n",
                "}\n",
                "\n",
                "print(\"Trainable Parameters Comparison (7B model):\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for method, ratio in methods.items():\n",
                "    params = model_params * ratio\n",
                "    print(f\"{method:20s}: {params:>15,.0f} params ({ratio:.4%})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. LoRA Deep Dive\n",
                "\n",
                "### 4.1 How LoRA Works\n",
                "\n",
                "LoRA (Low-Rank Adaptation) adds trainable low-rank matrices:\n",
                "\n",
                "$$W' = W + \\Delta W = W + BA$$\n",
                "\n",
                "Where:\n",
                "- $W$ = Original frozen weights (d Ã— k)\n",
                "- $B$ = Trainable matrix (d Ã— r)\n",
                "- $A$ = Trainable matrix (r Ã— k)\n",
                "- $r$ = Rank (typically 4-64)\n",
                "\n",
                "```\n",
                "Original: [d Ã— k] weights = d * k parameters\n",
                "LoRA:     [d Ã— r] + [r Ã— k] = d*r + r*k parameters\n",
                "\n",
                "If d=4096, k=4096, r=8:\n",
                "  Original: 16,777,216 params\n",
                "  LoRA:     32,768 + 32,768 = 65,536 params (0.4%)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "class LoRALayer:\n",
                "    \"\"\"\n",
                "    LoRA (Low-Rank Adaptation) layer implementation.\n",
                "    \n",
                "    Adds trainable low-rank matrices to frozen weights.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, d: int, k: int, r: int = 8, alpha: float = 16):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            d: Input dimension\n",
                "            k: Output dimension\n",
                "            r: LoRA rank\n",
                "            alpha: Scaling factor\n",
                "        \"\"\"\n",
                "        self.d = d\n",
                "        self.k = k\n",
                "        self.r = r\n",
                "        self.alpha = alpha\n",
                "        self.scaling = alpha / r\n",
                "        \n",
                "        # Initialize LoRA matrices\n",
                "        # A: Gaussian init, B: Zero init\n",
                "        self.A = np.random.randn(r, k) * 0.01\n",
                "        self.B = np.zeros((d, r))\n",
                "        \n",
                "        # Simulated frozen weights\n",
                "        self.W_frozen = np.random.randn(d, k) * 0.1\n",
                "    \n",
                "    def forward(self, x):\n",
                "        \"\"\"Forward pass with LoRA.\"\"\"\n",
                "        # Original path\n",
                "        h = x @ self.W_frozen.T\n",
                "        \n",
                "        # LoRA path: x -> A -> B\n",
                "        lora_out = (x @ self.A.T) @ self.B.T * self.scaling\n",
                "        \n",
                "        return h + lora_out\n",
                "    \n",
                "    @property\n",
                "    def trainable_params(self):\n",
                "        return self.d * self.r + self.r * self.k\n",
                "    \n",
                "    @property\n",
                "    def total_params(self):\n",
                "        return self.d * self.k\n",
                "\n",
                "# Example\n",
                "lora = LoRALayer(d=4096, k=4096, r=8)\n",
                "\n",
                "print(f\"Original params:  {lora.total_params:,}\")\n",
                "print(f\"LoRA params:      {lora.trainable_params:,}\")\n",
                "print(f\"Reduction:        {lora.trainable_params / lora.total_params:.4%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 LoRA Configuration\n",
                "\n",
                "| Parameter | Typical Value | Effect |\n",
                "|-----------|--------------|--------|\n",
                "| **r (rank)** | 8-64 | Higher = more capacity |\n",
                "| **alpha** | 16-32 | Scaling factor |\n",
                "| **target_modules** | q_proj, v_proj | Which layers to adapt |\n",
                "| **dropout** | 0.05-0.1 | Regularization |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LoRA Configuration Example\n",
                "lora_config = {\n",
                "    \"r\": 8,\n",
                "    \"lora_alpha\": 16,\n",
                "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
                "    \"lora_dropout\": 0.05,\n",
                "    \"bias\": \"none\",\n",
                "    \"task_type\": \"CAUSAL_LM\"\n",
                "}\n",
                "\n",
                "print(\"LoRA Configuration:\")\n",
                "for key, value in lora_config.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Training Best Practices\n",
                "\n",
                "### 5.1 Hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Recommended hyperparameters for LoRA fine-tuning\n",
                "training_config = {\n",
                "    # Learning rate\n",
                "    \"learning_rate\": 2e-4,  # Higher than full fine-tuning\n",
                "    \"lr_scheduler_type\": \"cosine\",\n",
                "    \"warmup_ratio\": 0.03,\n",
                "    \n",
                "    # Batch size\n",
                "    \"per_device_train_batch_size\": 4,\n",
                "    \"gradient_accumulation_steps\": 4,\n",
                "    \"effective_batch_size\": 16,  # = 4 * 4\n",
                "    \n",
                "    # Training duration\n",
                "    \"num_train_epochs\": 3,\n",
                "    \"max_steps\": -1,  # Or specify max steps\n",
                "    \n",
                "    # Memory optimization\n",
                "    \"fp16\": True,  # Or bf16 if supported\n",
                "    \"gradient_checkpointing\": True,\n",
                "    \n",
                "    # Regularization\n",
                "    \"weight_decay\": 0.01,\n",
                "    \"max_grad_norm\": 1.0,\n",
                "}\n",
                "\n",
                "print(\"Training Configuration:\")\n",
                "print(\"=\" * 40)\n",
                "for key, value in training_config.items():\n",
                "    print(f\"{key:30s}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Data Quality Tips\n",
                "\n",
                "| Aspect | Recommendation |\n",
                "|--------|---------------|\n",
                "| **Quantity** | 1K-100K examples typical |\n",
                "| **Quality** | Clean, consistent, diverse |\n",
                "| **Format** | Match desired output format |\n",
                "| **Balance** | Diverse task distribution |\n",
                "| **Validation** | 10-20% held out |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Evaluation and Iteration\n",
                "\n",
                "### 6.1 Evaluation Metrics\n",
                "\n",
                "| Task | Metrics |\n",
                "|------|--------|\n",
                "| **Classification** | Accuracy, F1 |\n",
                "| **Generation** | BLEU, ROUGE, Human eval |\n",
                "| **QA** | Exact match, F1 |\n",
                "| **Summarization** | ROUGE-L, factuality |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple evaluation loop\n",
                "def evaluate_model(model, eval_data):\n",
                "    \"\"\"Evaluate fine-tuned model.\"\"\"\n",
                "    results = {\n",
                "        \"correct\": 0,\n",
                "        \"total\": len(eval_data),\n",
                "        \"examples\": []\n",
                "    }\n",
                "    \n",
                "    for example in eval_data:\n",
                "        # Generate prediction\n",
                "        prediction = \"model.generate(example['input'])\"\n",
                "        \n",
                "        # Check correctness\n",
                "        is_correct = prediction == example[\"expected\"]\n",
                "        if is_correct:\n",
                "            results[\"correct\"] += 1\n",
                "        \n",
                "        results[\"examples\"].append({\n",
                "            \"input\": example[\"input\"],\n",
                "            \"expected\": example[\"expected\"],\n",
                "            \"predicted\": prediction,\n",
                "            \"correct\": is_correct\n",
                "        })\n",
                "    \n",
                "    results[\"accuracy\"] = results[\"correct\"] / results[\"total\"]\n",
                "    return results\n",
                "\n",
                "print(\"Evaluation function defined!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ğŸ“ Summary\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "1. **Choose method based on resources**: Full fine-tuning for max performance, LoRA for efficiency\n",
                "2. **LoRA is usually sufficient**: 90%+ of full fine-tuning quality at <1% params\n",
                "3. **Data quality > quantity**: Clean, diverse data is crucial\n",
                "4. **Iterate quickly**: Start small, validate, scale up\n",
                "\n",
                "### Decision Framework\n",
                "\n",
                "```\n",
                "Do you have 10K+ examples? â”€â”€Yesâ”€â”€> Full Fine-Tuning\n",
                "         â”‚ No\n",
                "         â–¼\n",
                "Limited compute? â”€â”€Yesâ”€â”€> QLoRA\n",
                "         â”‚ No\n",
                "         â–¼\n",
                "       LoRA\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}