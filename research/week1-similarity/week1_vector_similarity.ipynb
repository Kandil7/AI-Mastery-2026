{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¯ Week 1: Vector Similarity\n",
                "\n",
                "**Learning Objectives:**\n",
                "1. Understand vector representations and embeddings\n",
                "2. Master similarity metrics (Cosine, Euclidean, Dot Product)\n",
                "3. Build a simple semantic search engine\n",
                "4. Visualize vectors in 2D/3D space\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "import seaborn as sns\n",
                "\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 1: Theory\n",
                "---\n",
                "\n",
                "## Why Vector Similarity?\n",
                "\n",
                "In AI/ML, we represent data as vectors:\n",
                "- **Word embeddings**: Words â†’ Vectors (Word2Vec, GloVe)\n",
                "- **Sentence embeddings**: Sentences â†’ Vectors (BERT, Sentence-BERT)\n",
                "- **Image embeddings**: Images â†’ Vectors (ResNet, CLIP)\n",
                "\n",
                "**Key Insight**: Similar items have similar vectors!\n",
                "\n",
                "## Similarity Metrics\n",
                "\n",
                "| Metric | Formula | Range | Best For |\n",
                "|--------|---------|-------|----------|\n",
                "| Cosine | $\\frac{a \\cdot b}{\\|a\\| \\|b\\|}$ | [-1, 1] | Text, normalized vectors |\n",
                "| Euclidean | $\\sqrt{\\sum(a_i - b_i)^2}$ | [0, âˆž) | Dense, continuous features |\n",
                "| Dot Product | $\\sum a_i \\cdot b_i$ | (-âˆž, âˆž) | When magnitude matters |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 2: Hands-On Implementation\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.1 Core Vector Operations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def dot_product(v1, v2):\n",
                "    \"\"\"Compute dot product of two vectors.\"\"\"\n",
                "    return sum(a * b for a, b in zip(v1, v2))\n",
                "\n",
                "\n",
                "def magnitude(v):\n",
                "    \"\"\"Compute the magnitude (L2 norm) of a vector.\"\"\"\n",
                "    return sum(x**2 for x in v) ** 0.5\n",
                "\n",
                "\n",
                "def cosine_similarity(v1, v2):\n",
                "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
                "    mag1 = magnitude(v1)\n",
                "    mag2 = magnitude(v2)\n",
                "    if mag1 == 0 or mag2 == 0:\n",
                "        return 0\n",
                "    return dot_product(v1, v2) / (mag1 * mag2)\n",
                "\n",
                "\n",
                "def euclidean_distance(v1, v2):\n",
                "    \"\"\"Compute Euclidean distance between two vectors.\"\"\"\n",
                "    return sum((a - b)**2 for a, b in zip(v1, v2)) ** 0.5\n",
                "\n",
                "\n",
                "def normalize(v):\n",
                "    \"\"\"Normalize a vector to unit length.\"\"\"\n",
                "    mag = magnitude(v)\n",
                "    if mag == 0:\n",
                "        return v\n",
                "    return [x / mag for x in v]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the implementations\n",
                "v1 = [1, 2, 3]\n",
                "v2 = [4, 5, 6]\n",
                "\n",
                "print(f\"v1 = {v1}\")\n",
                "print(f\"v2 = {v2}\")\n",
                "print(f\"Dot product: {dot_product(v1, v2)}\")\n",
                "print(f\"Magnitude v1: {magnitude(v1):.4f}\")\n",
                "print(f\"Cosine similarity: {cosine_similarity(v1, v2):.4f}\")\n",
                "print(f\"Euclidean distance: {euclidean_distance(v1, v2):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 Simple Semantic Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulated document embeddings (in real apps, use sentence-transformers)\n",
                "documents = {\n",
                "    \"doc1\": {\"text\": \"Python programming tutorial\", \"vector\": [0.8, 0.3, 0.1]},\n",
                "    \"doc2\": {\"text\": \"Machine learning basics\", \"vector\": [0.2, 0.9, 0.4]},\n",
                "    \"doc3\": {\"text\": \"Deep neural networks\", \"vector\": [0.1, 0.7, 0.9]},\n",
                "    \"doc4\": {\"text\": \"Python data analysis\", \"vector\": [0.7, 0.5, 0.2]},\n",
                "    \"doc5\": {\"text\": \"Natural language processing\", \"vector\": [0.3, 0.6, 0.8]},\n",
                "}\n",
                "\n",
                "# Query embedding\n",
                "query = {\"text\": \"Python coding\", \"vector\": [0.9, 0.2, 0.1]}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def search(query_vector, documents, top_k=3):\n",
                "    \"\"\"Search for most similar documents.\"\"\"\n",
                "    results = []\n",
                "    for doc_id, doc in documents.items():\n",
                "        similarity = cosine_similarity(query_vector, doc[\"vector\"])\n",
                "        results.append({\n",
                "            \"id\": doc_id,\n",
                "            \"text\": doc[\"text\"],\n",
                "            \"similarity\": similarity\n",
                "        })\n",
                "    \n",
                "    # Sort by similarity (descending)\n",
                "    results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
                "    return results[:top_k]\n",
                "\n",
                "\n",
                "# Run search\n",
                "print(f\"Query: '{query['text']}'\\n\")\n",
                "print(\"Search Results:\")\n",
                "print(\"-\" * 50)\n",
                "for i, result in enumerate(search(query[\"vector\"], documents), 1):\n",
                "    print(f\"{i}. {result['text']}\")\n",
                "    print(f\"   Similarity: {result['similarity']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.3 Cosine vs Euclidean: When to Use Which?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Same direction, different magnitudes\n",
                "short_vector = [1, 1]\n",
                "long_vector = [10, 10]\n",
                "\n",
                "print(\"Same direction, different magnitudes:\")\n",
                "print(f\"  Cosine similarity: {cosine_similarity(short_vector, long_vector):.4f}\")\n",
                "print(f\"  Euclidean distance: {euclidean_distance(short_vector, long_vector):.4f}\")\n",
                "\n",
                "# Different directions, same magnitude\n",
                "v1 = [1, 0]\n",
                "v2 = [0, 1]\n",
                "\n",
                "print(\"\\nDifferent directions, same magnitude:\")\n",
                "print(f\"  Cosine similarity: {cosine_similarity(v1, v2):.4f}\")\n",
                "print(f\"  Euclidean distance: {euclidean_distance(v1, v2):.4f}\")\n",
                "\n",
                "print(\"\\nðŸ’¡ Key Insight:\")\n",
                "print(\"   - Cosine: Measures DIRECTION (angle) - good for text\")\n",
                "print(\"   - Euclidean: Measures DISTANCE - good for spatial data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 3: Visualizations\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 2D Vector Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_2d_vectors(vectors, labels, query=None, query_label=\"Query\"):\n",
                "    \"\"\"Plot 2D vectors with arrows from origin.\"\"\"\n",
                "    fig, ax = plt.subplots(figsize=(10, 8))\n",
                "    \n",
                "    colors = plt.cm.Set2(np.linspace(0, 1, len(vectors)))\n",
                "    \n",
                "    # Plot document vectors\n",
                "    for i, (vec, label) in enumerate(zip(vectors, labels)):\n",
                "        ax.arrow(0, 0, vec[0], vec[1], head_width=0.05, head_length=0.03,\n",
                "                 fc=colors[i], ec=colors[i], linewidth=2)\n",
                "        ax.annotate(label, (vec[0], vec[1]), fontsize=10, \n",
                "                    xytext=(5, 5), textcoords='offset points')\n",
                "    \n",
                "    # Plot query vector\n",
                "    if query is not None:\n",
                "        ax.arrow(0, 0, query[0], query[1], head_width=0.05, head_length=0.03,\n",
                "                 fc='red', ec='red', linewidth=3)\n",
                "        ax.annotate(query_label, (query[0], query[1]), fontsize=12, \n",
                "                    color='red', fontweight='bold',\n",
                "                    xytext=(5, 5), textcoords='offset points')\n",
                "    \n",
                "    ax.set_xlim(-0.2, 1.2)\n",
                "    ax.set_ylim(-0.2, 1.2)\n",
                "    ax.set_xlabel('Dimension 1')\n",
                "    ax.set_ylabel('Dimension 2')\n",
                "    ax.set_title('Vector Space Visualization')\n",
                "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
                "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    ax.set_aspect('equal')\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "# Extract 2D vectors (first 2 dimensions)\n",
                "doc_vectors = [doc[\"vector\"][:2] for doc in documents.values()]\n",
                "doc_labels = [doc[\"text\"][:20] for doc in documents.values()]\n",
                "query_2d = query[\"vector\"][:2]\n",
                "\n",
                "plot_2d_vectors(doc_vectors, doc_labels, query_2d, \"Query\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 3D Vector Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_3d_vectors(vectors, labels, query=None):\n",
                "    \"\"\"Plot 3D vectors.\"\"\"\n",
                "    fig = plt.figure(figsize=(12, 9))\n",
                "    ax = fig.add_subplot(111, projection='3d')\n",
                "    \n",
                "    colors = plt.cm.Set2(np.linspace(0, 1, len(vectors)))\n",
                "    \n",
                "    # Plot document vectors as arrows\n",
                "    for i, (vec, label) in enumerate(zip(vectors, labels)):\n",
                "        ax.quiver(0, 0, 0, vec[0], vec[1], vec[2], \n",
                "                  color=colors[i], arrow_length_ratio=0.1, linewidth=2)\n",
                "        ax.text(vec[0], vec[1], vec[2], label[:15], fontsize=8)\n",
                "    \n",
                "    # Plot query vector\n",
                "    if query is not None:\n",
                "        ax.quiver(0, 0, 0, query[0], query[1], query[2],\n",
                "                  color='red', arrow_length_ratio=0.1, linewidth=3)\n",
                "        ax.text(query[0], query[1], query[2], 'QUERY', \n",
                "                fontsize=10, color='red', fontweight='bold')\n",
                "    \n",
                "    ax.set_xlabel('Dim 1')\n",
                "    ax.set_ylabel('Dim 2')\n",
                "    ax.set_zlabel('Dim 3')\n",
                "    ax.set_title('3D Vector Space')\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "doc_vectors_3d = [doc[\"vector\"] for doc in documents.values()]\n",
                "doc_labels = [doc[\"text\"] for doc in documents.values()]\n",
                "\n",
                "plot_3d_vectors(doc_vectors_3d, doc_labels, query[\"vector\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3 Similarity Heatmap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute pairwise similarities\n",
                "doc_names = list(documents.keys())\n",
                "n_docs = len(doc_names)\n",
                "similarity_matrix = np.zeros((n_docs, n_docs))\n",
                "\n",
                "for i, doc1 in enumerate(doc_names):\n",
                "    for j, doc2 in enumerate(doc_names):\n",
                "        similarity_matrix[i, j] = cosine_similarity(\n",
                "            documents[doc1][\"vector\"],\n",
                "            documents[doc2][\"vector\"]\n",
                "        )\n",
                "\n",
                "# Plot heatmap\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(similarity_matrix, \n",
                "            xticklabels=[documents[d][\"text\"][:15] for d in doc_names],\n",
                "            yticklabels=[documents[d][\"text\"][:15] for d in doc_names],\n",
                "            annot=True, fmt=\".2f\", cmap=\"YlOrRd\",\n",
                "            vmin=0, vmax=1)\n",
                "plt.title(\"Document Similarity Heatmap\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 4: Unit Tests\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_tests():\n",
                "    \"\"\"Run all unit tests.\"\"\"\n",
                "    print(\"Running Unit Tests...\\n\")\n",
                "    \n",
                "    # Test 1: Dot product\n",
                "    assert dot_product([1, 2, 3], [4, 5, 6]) == 32\n",
                "    print(\"âœ“ Dot product test passed\")\n",
                "    \n",
                "    # Test 2: Magnitude\n",
                "    assert abs(magnitude([3, 4]) - 5.0) < 1e-10\n",
                "    print(\"âœ“ Magnitude test passed\")\n",
                "    \n",
                "    # Test 3: Cosine similarity - identical vectors\n",
                "    assert abs(cosine_similarity([1, 0], [1, 0]) - 1.0) < 1e-10\n",
                "    print(\"âœ“ Cosine similarity (identical) test passed\")\n",
                "    \n",
                "    # Test 4: Cosine similarity - perpendicular vectors\n",
                "    assert abs(cosine_similarity([1, 0], [0, 1]) - 0.0) < 1e-10\n",
                "    print(\"âœ“ Cosine similarity (perpendicular) test passed\")\n",
                "    \n",
                "    # Test 5: Cosine similarity - opposite vectors\n",
                "    assert abs(cosine_similarity([1, 0], [-1, 0]) - (-1.0)) < 1e-10\n",
                "    print(\"âœ“ Cosine similarity (opposite) test passed\")\n",
                "    \n",
                "    # Test 6: Euclidean distance\n",
                "    assert abs(euclidean_distance([0, 0], [3, 4]) - 5.0) < 1e-10\n",
                "    print(\"âœ“ Euclidean distance test passed\")\n",
                "    \n",
                "    # Test 7: Normalize\n",
                "    normalized = normalize([3, 4])\n",
                "    assert abs(magnitude(normalized) - 1.0) < 1e-10\n",
                "    print(\"âœ“ Normalize test passed\")\n",
                "    \n",
                "    # Test 8: Zero vector handling\n",
                "    assert cosine_similarity([0, 0], [1, 1]) == 0\n",
                "    print(\"âœ“ Zero vector handling test passed\")\n",
                "    \n",
                "    print(\"\\nðŸŽ‰ All tests passed!\")\n",
                "\n",
                "\n",
                "run_tests()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 5: Interview Prep\n",
                "---\n",
                "\n",
                "## Key Questions\n",
                "\n",
                "### Q1: Why use Cosine Similarity instead of Euclidean Distance for text?\n",
                "\n",
                "**Answer:**\n",
                "- Cosine measures **angle** (direction), not magnitude\n",
                "- Longer documents have larger vectors but may have same meaning\n",
                "- Cosine is invariant to vector scaling\n",
                "- Example: \"cat dog\" vs \"cat cat dog dog dog\" should be similar\n",
                "\n",
                "### Q2: What is the range of cosine similarity?\n",
                "\n",
                "**Answer:** [-1, 1]\n",
                "- 1 = Identical direction\n",
                "- 0 = Perpendicular (orthogonal)\n",
                "- -1 = Opposite direction\n",
                "\n",
                "### Q3: How do you handle the curse of dimensionality?\n",
                "\n",
                "**Answer:**\n",
                "- Use dimensionality reduction (PCA, t-SNE)\n",
                "- Use approximate nearest neighbor (ANN) algorithms\n",
                "- Index vectors with HNSW, IVF, or LSH\n",
                "\n",
                "### Q4: What are the trade-offs of different similarity metrics?\n",
                "\n",
                "**Answer:**\n",
                "- Dot product: Fast, but magnitude-sensitive\n",
                "- Cosine: Normalized, direction-only\n",
                "- Euclidean: Intuitive distance, but affected by scale"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 6: Exercises\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1: Implement Manhattan Distance (L1)\n",
                "def manhattan_distance(v1, v2):\n",
                "    \"\"\"Implement L1 (Manhattan) distance.\"\"\"\n",
                "    # TODO: Your implementation here\n",
                "    pass\n",
                "\n",
                "\n",
                "# Exercise 2: Implement Jaccard Similarity (for sets)\n",
                "def jaccard_similarity(set1, set2):\n",
                "    \"\"\"Implement Jaccard similarity for two sets.\"\"\"\n",
                "    # TODO: Your implementation here\n",
                "    pass\n",
                "\n",
                "\n",
                "# Exercise 3: Build a simple KNN classifier\n",
                "def knn_classify(query, labeled_data, k=3):\n",
                "    \"\"\"\n",
                "    K-Nearest Neighbors classification.\n",
                "    \n",
                "    Args:\n",
                "        query: Vector to classify\n",
                "        labeled_data: List of (vector, label) tuples\n",
                "        k: Number of neighbors\n",
                "    \n",
                "    Returns:\n",
                "        Predicted label (majority vote)\n",
                "    \"\"\"\n",
                "    # TODO: Your implementation here\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Section 7: Deliverable\n",
                "---\n",
                "\n",
                "## What You Built This Week:\n",
                "\n",
                "1. **`similarity_utils.py`** - Reusable similarity functions\n",
                "2. **Simple Vector Search Engine** - Query â†’ Ranked results\n",
                "3. **2D/3D Visualizations** - Understanding vector spaces\n",
                "\n",
                "## Key Takeaways:\n",
                "\n",
                "- Similar meanings = Similar vectors\n",
                "- Cosine similarity is the standard for text/embeddings\n",
                "- Vector search is O(n) - need indexing for scale\n",
                "\n",
                "## Next Week: Probability & Statistics\n",
                "- Probability distributions\n",
                "- Bayes' theorem for ML\n",
                "- Statistical inference"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}