{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Embeddings Module - Complete Tutorial\n",
                "\n",
                "This notebook provides a comprehensive guide to understanding and using embeddings in AI/ML applications.\n",
                "\n",
                "## Table of Contents\n",
                "1. [What are Embeddings?](#1-what-are-embeddings)\n",
                "2. [Text Embeddings](#2-text-embeddings)\n",
                "3. [Image Embeddings](#3-image-embeddings)\n",
                "4. [Multi-Modal Embeddings](#4-multi-modal-embeddings)\n",
                "5. [Embedding Caching](#5-embedding-caching)\n",
                "6. [Similarity Search](#6-similarity-search)\n",
                "7. [Practical Applications](#7-practical-applications)\n",
                "8. [Best Practices](#8-best-practices)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. What are Embeddings?\n",
                "\n",
                "### 1.1 Definition\n",
                "\n",
                "**Embeddings** are dense vector representations of data (text, images, audio, etc.) in a continuous vector space. They capture semantic meaning and relationships between data points.\n",
                "\n",
                "### 1.2 Key Properties\n",
                "\n",
                "| Property | Description |\n",
                "|----------|-------------|\n",
                "| **Dense** | Unlike sparse representations (one-hot, TF-IDF), embeddings are dense vectors |\n",
                "| **Fixed Dimension** | Each embedding has the same dimensionality (e.g., 384, 768) |\n",
                "| **Semantic** | Similar concepts have similar embeddings (close in vector space) |\n",
                "| **Learnable** | Embeddings are learned from data, not hand-crafted |\n",
                "\n",
                "### 1.3 Why Embeddings?\n",
                "\n",
                "```\n",
                "Traditional:  \"cat\" ‚Üí [0, 0, 0, ..., 1, 0, 0]  (10,000+ dimensions, sparse)\n",
                "Embeddings:   \"cat\" ‚Üí [0.21, -0.45, 0.89, ...]  (384 dimensions, dense)\n",
                "```\n",
                "\n",
                "**Benefits:**\n",
                "- Capture semantic relationships (\"king\" - \"man\" + \"woman\" ‚âà \"queen\")\n",
                "- Enable efficient similarity search\n",
                "- Work across languages and modalities\n",
                "- Serve as features for downstream ML models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import sys\n",
                "sys.path.insert(0, '../..')  # Add project root to path\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.manifold import TSNE\n",
                "\n",
                "# Import our embeddings module\n",
                "from src.embeddings import (\n",
                "    TextEmbedder,\n",
                "    ImageEmbedder,\n",
                "    MultiModalEmbedder,\n",
                "    EmbeddingCache,\n",
                "    EmbeddingConfig\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Text Embeddings\n",
                "\n",
                "### 2.1 Understanding Text Embeddings\n",
                "\n",
                "Text embeddings transform natural language into numerical vectors that capture semantic meaning.\n",
                "\n",
                "**Popular Models:**\n",
                "\n",
                "| Model | Dimensions | Speed | Quality | Use Case |\n",
                "|-------|------------|-------|---------|----------|\n",
                "| all-MiniLM-L6-v2 | 384 | ‚ö° Fast | Good | General purpose |\n",
                "| all-mpnet-base-v2 | 768 | Medium | Best | High quality |\n",
                "| OpenAI text-embedding-3-small | 1536 | API | Excellent | Production |\n",
                "\n",
                "### 2.2 Basic Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the text embedder\n",
                "text_embedder = TextEmbedder(model_name=\"all-MiniLM-L6-v2\")\n",
                "\n",
                "# Encode a single sentence\n",
                "sentence = \"Machine learning is transforming the world of technology.\"\n",
                "embedding = text_embedder.encode(sentence)\n",
                "\n",
                "print(f\"Input: '{sentence}'\")\n",
                "print(f\"Embedding shape: {embedding.shape}\")\n",
                "print(f\"First 10 values: {embedding[0][:10]}\")\n",
                "print(f\"Embedding dimension: {text_embedder.embedding_dim}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode multiple sentences\n",
                "sentences = [\n",
                "    \"The quick brown fox jumps over the lazy dog.\",\n",
                "    \"A fast auburn fox leaps above a sleepy canine.\",\n",
                "    \"The weather is beautiful today in New York.\",\n",
                "    \"It's sunny and warm in Manhattan this afternoon.\",\n",
                "    \"Python is a popular programming language.\"\n",
                "]\n",
                "\n",
                "embeddings = text_embedder.encode(sentences)\n",
                "print(f\"Embeddings shape: {embeddings.shape}\")\n",
                "print(f\"\\nNumber of sentences: {len(sentences)}\")\n",
                "print(f\"Embedding dimension: {embeddings.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Computing Similarity\n",
                "\n",
                "**Cosine Similarity** measures the angle between two vectors:\n",
                "\n",
                "$$\\text{cosine}(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\|\\mathbf{b}\\|}$$\n",
                "\n",
                "- **1.0**: Identical meaning\n",
                "- **0.0**: Unrelated\n",
                "- **-1.0**: Opposite meaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute similarity between sentence pairs\n",
                "pairs = [\n",
                "    (sentences[0], sentences[1]),  # Similar (fox sentences)\n",
                "    (sentences[2], sentences[3]),  # Similar (weather sentences)\n",
                "    (sentences[0], sentences[4]),  # Different topics\n",
                "]\n",
                "\n",
                "print(\"Similarity Scores:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for s1, s2 in pairs:\n",
                "    similarity = text_embedder.similarity(s1, s2)\n",
                "    print(f\"\\nSentence 1: '{s1[:50]}...'\")\n",
                "    print(f\"Sentence 2: '{s2[:50]}...'\")\n",
                "    print(f\"Similarity: {similarity:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Finding Similar Texts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a knowledge base\n",
                "knowledge_base = [\n",
                "    \"Python is a high-level programming language known for its readability.\",\n",
                "    \"JavaScript is essential for web development and runs in browsers.\",\n",
                "    \"Machine learning algorithms learn patterns from data.\",\n",
                "    \"Deep learning uses neural networks with multiple layers.\",\n",
                "    \"Natural language processing helps computers understand human language.\",\n",
                "    \"Computer vision enables machines to interpret visual information.\",\n",
                "    \"Reinforcement learning trains agents through rewards and penalties.\",\n",
                "    \"Data science combines statistics, programming, and domain expertise.\"\n",
                "]\n",
                "\n",
                "# Search query\n",
                "query = \"How do neural networks learn?\"\n",
                "\n",
                "# Find most similar documents\n",
                "results = text_embedder.most_similar(query, knowledge_base, top_k=3)\n",
                "\n",
                "print(f\"Query: '{query}'\")\n",
                "print(\"\\nTop 3 Results:\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "for i, (text, score) in enumerate(results, 1):\n",
                "    print(f\"{i}. [Score: {score:.4f}] {text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.5 Visualizing Embeddings\n",
                "\n",
                "We use **t-SNE** to reduce high-dimensional embeddings to 2D for visualization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Categorized sentences for visualization\n",
                "categories = {\n",
                "    \"Technology\": [\n",
                "        \"Artificial intelligence is revolutionizing industries.\",\n",
                "        \"Machine learning models can predict future trends.\",\n",
                "        \"Deep neural networks power modern AI systems.\"\n",
                "    ],\n",
                "    \"Nature\": [\n",
                "        \"The forest is home to many species of birds.\",\n",
                "        \"Mountains covered in snow look beautiful at sunrise.\",\n",
                "        \"The ocean waves crash against the rocky shore.\"\n",
                "    ],\n",
                "    \"Food\": [\n",
                "        \"Italian pizza is loved all around the world.\",\n",
                "        \"Sushi is a traditional Japanese dish with rice and fish.\",\n",
                "        \"Chocolate cake is a popular dessert choice.\"\n",
                "    ]\n",
                "}\n",
                "\n",
                "# Flatten and embed\n",
                "all_texts = []\n",
                "all_labels = []\n",
                "for category, texts in categories.items():\n",
                "    all_texts.extend(texts)\n",
                "    all_labels.extend([category] * len(texts))\n",
                "\n",
                "embeddings = text_embedder.encode(all_texts)\n",
                "\n",
                "# Apply t-SNE\n",
                "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
                "embeddings_2d = tsne.fit_transform(embeddings)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(10, 8))\n",
                "colors = {'Technology': 'blue', 'Nature': 'green', 'Food': 'red'}\n",
                "\n",
                "for category in categories:\n",
                "    mask = [l == category for l in all_labels]\n",
                "    plt.scatter(\n",
                "        embeddings_2d[mask, 0],\n",
                "        embeddings_2d[mask, 1],\n",
                "        c=colors[category],\n",
                "        label=category,\n",
                "        s=100\n",
                "    )\n",
                "\n",
                "plt.title(\"Text Embeddings Visualization (t-SNE)\")\n",
                "plt.xlabel(\"Dimension 1\")\n",
                "plt.ylabel(\"Dimension 2\")\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"‚úÖ Notice how semantically similar texts cluster together!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Image Embeddings\n",
                "\n",
                "### 3.1 Understanding Image Embeddings\n",
                "\n",
                "Image embeddings convert visual content into dense vectors, enabling:\n",
                "- Similar image search\n",
                "- Image classification\n",
                "- Cross-modal search (find images using text)\n",
                "\n",
                "**CLIP (Contrastive Language-Image Pre-training)**:\n",
                "- Trained on 400M image-text pairs\n",
                "- Learns joint embedding space for images and text\n",
                "- Enables zero-shot image classification\n",
                "\n",
                "### 3.2 Basic Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize image embedder\n",
                "image_embedder = ImageEmbedder(model_name=\"openai/clip-vit-base-patch32\")\n",
                "\n",
                "print(f\"Image Embedder initialized\")\n",
                "print(f\"Embedding dimension: {image_embedder.embedding_dim}\")\n",
                "\n",
                "# Note: To use with actual images:\n",
                "# embedding = image_embedder.encode(\"path/to/image.jpg\")\n",
                "# \n",
                "# Or with PIL Images:\n",
                "# from PIL import Image\n",
                "# img = Image.open(\"path/to/image.jpg\")\n",
                "# embedding = image_embedder.encode(img)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Image-Text Similarity with CLIP\n",
                "\n",
                "CLIP projects both images and text into the same embedding space, allowing direct comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demonstrate the concept with synthetic example\n",
                "# In production, you would use actual images\n",
                "\n",
                "print(\"CLIP Image-Text Matching Concept:\")\n",
                "print(\"=\"*60)\n",
                "print(\"\"\"\n",
                "Given an image of a cat:\n",
                "  - \"a photo of a cat\"      ‚Üí High similarity (0.85)\n",
                "  - \"a photo of a dog\"      ‚Üí Medium similarity (0.45)\n",
                "  - \"a photo of a car\"      ‚Üí Low similarity (0.15)\n",
                "  \n",
                "This enables:\n",
                "  ‚úÖ Zero-shot image classification\n",
                "  ‚úÖ Image search using natural language\n",
                "  ‚úÖ Content-based image retrieval\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Multi-Modal Embeddings\n",
                "\n",
                "### 4.1 Understanding Multi-Modal Embeddings\n",
                "\n",
                "Multi-modal embeddings project different types of data (text, images, audio) into a shared vector space.\n",
                "\n",
                "```\n",
                "Text: \"a cute puppy\"     ‚îÄ‚îÄ‚îÄ‚îê\n",
                "                            ‚îú‚îÄ‚îÄ‚Üí Same Vector Space\n",
                "Image: [puppy.jpg]      ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```\n",
                "\n",
                "### 4.2 Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize multi-modal embedder\n",
                "multimodal_embedder = MultiModalEmbedder()\n",
                "\n",
                "# Encode text descriptions\n",
                "text_descriptions = [\n",
                "    \"a photo of a cat\",\n",
                "    \"a photo of a dog\",\n",
                "    \"a photo of a car\",\n",
                "    \"a photo of a sunset\"\n",
                "]\n",
                "\n",
                "text_embeddings = multimodal_embedder.encode_text(text_descriptions)\n",
                "\n",
                "print(f\"Text embeddings shape: {text_embeddings.shape}\")\n",
                "print(f\"Embedding dimension: {multimodal_embedder.embedding_dim}\")\n",
                "\n",
                "# In production, you would compare with image embeddings:\n",
                "# image_embedding = multimodal_embedder.encode_image(\"sunset.jpg\")\n",
                "# similarity = np.dot(text_embeddings[3], image_embedding[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Embedding Caching\n",
                "\n",
                "### 5.1 Why Cache Embeddings?\n",
                "\n",
                "| Without Cache | With Cache |\n",
                "|--------------|------------|\n",
                "| Compute every time | Compute once, reuse |\n",
                "| Slow for repeated queries | Fast repeated lookups |\n",
                "| Higher API costs | Reduced API costs |\n",
                "\n",
                "### 5.2 Using EmbeddingCache"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Create cache\n",
                "cache = EmbeddingCache(max_size=1000, persist=False)\n",
                "\n",
                "# Create embedder with cache\n",
                "cached_embedder = TextEmbedder(\n",
                "    model_name=\"all-MiniLM-L6-v2\",\n",
                "    cache=cache\n",
                ")\n",
                "\n",
                "test_texts = [\n",
                "    \"This is a test sentence for caching.\",\n",
                "    \"Another example to demonstrate caching.\",\n",
                "    \"Embedding cache improves performance significantly.\"\n",
                "]\n",
                "\n",
                "# First call - Cache miss (computes embeddings)\n",
                "start = time.time()\n",
                "_ = cached_embedder.encode(test_texts)\n",
                "first_call_time = time.time() - start\n",
                "\n",
                "print(f\"First call (cache miss): {first_call_time:.4f}s\")\n",
                "print(f\"Cache stats: {cache.stats}\")\n",
                "\n",
                "# Second call - Cache hit (retrieves from cache)\n",
                "start = time.time()\n",
                "_ = cached_embedder.encode(test_texts)\n",
                "second_call_time = time.time() - start\n",
                "\n",
                "print(f\"\\nSecond call (cache hit): {second_call_time:.4f}s\")\n",
                "print(f\"Cache stats: {cache.stats}\")\n",
                "\n",
                "speedup = first_call_time / second_call_time if second_call_time > 0 else float('inf')\n",
                "print(f\"\\n‚ö° Speedup: {speedup:.1f}x faster with cache!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 Cache Persistence\n",
                "\n",
                "Enable `persist=True` to save cache to disk:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create persistent cache\n",
                "persistent_cache = EmbeddingCache(\n",
                "    max_size=10000,\n",
                "    persist=True,\n",
                "    cache_path=\"./embedding_cache.pkl\"\n",
                ")\n",
                "\n",
                "print(\"Persistent cache created!\")\n",
                "print(\"- Cache is saved to disk after each write\")\n",
                "print(\"- Cache is loaded automatically on restart\")\n",
                "print(\"- Useful for production deployments\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 6. Similarity Search\n",
                "\n",
                "### 6.1 Building a Simple Search Engine\n",
                "\n",
                "Let's build a document search engine using embeddings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class EmbeddingSearchEngine:\n",
                "    \"\"\"\n",
                "    Simple search engine using text embeddings.\n",
                "    \n",
                "    Example:\n",
                "        >>> engine = EmbeddingSearchEngine()\n",
                "        >>> engine.index([\"doc1\", \"doc2\", \"doc3\"])\n",
                "        >>> results = engine.search(\"query\", top_k=2)\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, embedder: TextEmbedder = None):\n",
                "        self.embedder = embedder or TextEmbedder()\n",
                "        self.documents = []\n",
                "        self.embeddings = None\n",
                "    \n",
                "    def index(self, documents: list):\n",
                "        \"\"\"Index documents by computing their embeddings.\"\"\"\n",
                "        self.documents = documents\n",
                "        self.embeddings = self.embedder.encode(documents)\n",
                "        print(f\"Indexed {len(documents)} documents\")\n",
                "    \n",
                "    def search(self, query: str, top_k: int = 5) -> list:\n",
                "        \"\"\"Search for documents similar to the query.\"\"\"\n",
                "        query_embedding = self.embedder.encode(query)[0]\n",
                "        \n",
                "        # Compute cosine similarities\n",
                "        similarities = np.dot(self.embeddings, query_embedding)\n",
                "        \n",
                "        # Get top-k indices\n",
                "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
                "        \n",
                "        return [\n",
                "            {\"document\": self.documents[i], \"score\": float(similarities[i])}\n",
                "            for i in top_indices\n",
                "        ]\n",
                "\n",
                "\n",
                "# Create search engine\n",
                "search_engine = EmbeddingSearchEngine(text_embedder)\n",
                "\n",
                "# Index some documents\n",
                "documents = [\n",
                "    \"Python is a versatile programming language used in AI and web development.\",\n",
                "    \"JavaScript enables interactive web pages and is essential for frontend development.\",\n",
                "    \"Machine learning algorithms can learn patterns from data without explicit programming.\",\n",
                "    \"Deep learning uses neural networks with many layers to learn complex representations.\",\n",
                "    \"Natural language processing helps computers understand and generate human language.\",\n",
                "    \"Computer vision enables machines to interpret and understand visual information.\",\n",
                "    \"Reinforcement learning trains AI agents through trial and error with rewards.\",\n",
                "    \"Data science combines statistics, programming, and domain knowledge to extract insights.\",\n",
                "    \"Cloud computing provides on-demand access to computing resources over the internet.\",\n",
                "    \"Cybersecurity protects computer systems and networks from digital attacks.\"\n",
                "]\n",
                "\n",
                "search_engine.index(documents)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform searches\n",
                "queries = [\n",
                "    \"How do neural networks work?\",\n",
                "    \"Best language for building websites\",\n",
                "    \"Protecting computers from hackers\"\n",
                "]\n",
                "\n",
                "for query in queries:\n",
                "    print(f\"\\nüîç Query: '{query}'\")\n",
                "    print(\"-\" * 60)\n",
                "    \n",
                "    results = search_engine.search(query, top_k=3)\n",
                "    \n",
                "    for i, result in enumerate(results, 1):\n",
                "        print(f\"  {i}. [{result['score']:.3f}] {result['document'][:60]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 7. Practical Applications\n",
                "\n",
                "### 7.1 Semantic Duplicate Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_duplicates(texts: list, threshold: float = 0.85) -> list:\n",
                "    \"\"\"\n",
                "    Find semantically similar (duplicate) texts.\n",
                "    \n",
                "    Args:\n",
                "        texts: List of texts to check\n",
                "        threshold: Similarity threshold for duplicates\n",
                "        \n",
                "    Returns:\n",
                "        List of duplicate pairs with similarity scores\n",
                "    \"\"\"\n",
                "    embeddings = text_embedder.encode(texts)\n",
                "    \n",
                "    duplicates = []\n",
                "    for i in range(len(texts)):\n",
                "        for j in range(i + 1, len(texts)):\n",
                "            similarity = np.dot(embeddings[i], embeddings[j])\n",
                "            if similarity >= threshold:\n",
                "                duplicates.append({\n",
                "                    \"text1\": texts[i],\n",
                "                    \"text2\": texts[j],\n",
                "                    \"similarity\": float(similarity)\n",
                "                })\n",
                "    \n",
                "    return duplicates\n",
                "\n",
                "\n",
                "# Test duplicate detection\n",
                "product_reviews = [\n",
                "    \"This product is amazing! Great quality and fast shipping.\",\n",
                "    \"Excellent product, shipped quickly, very high quality!\",\n",
                "    \"The weather has been nice this week.\",\n",
                "    \"Amazing quality, fast delivery, love this product!\",\n",
                "    \"It's been sunny and warm lately.\"\n",
                "]\n",
                "\n",
                "duplicates = find_duplicates(product_reviews, threshold=0.7)\n",
                "\n",
                "print(\"Potential Duplicates Found:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for dup in duplicates:\n",
                "    print(f\"\\nSimilarity: {dup['similarity']:.3f}\")\n",
                "    print(f\"  Text 1: {dup['text1']}\")\n",
                "    print(f\"  Text 2: {dup['text2']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Text Classification with Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Sample dataset\n",
                "texts_and_labels = [\n",
                "    (\"I love this product! It's the best!\", \"positive\"),\n",
                "    (\"Amazing experience, will buy again!\", \"positive\"),\n",
                "    (\"Great quality and fast shipping.\", \"positive\"),\n",
                "    (\"Terrible product, waste of money.\", \"negative\"),\n",
                "    (\"Worst purchase ever, very disappointed.\", \"negative\"),\n",
                "    (\"Poor quality, arrived broken.\", \"negative\"),\n",
                "    (\"It's okay, nothing special.\", \"neutral\"),\n",
                "    (\"Average product, works as expected.\", \"neutral\"),\n",
                "]\n",
                "\n",
                "texts = [t for t, _ in texts_and_labels]\n",
                "labels = [l for _, l in texts_and_labels]\n",
                "\n",
                "# Generate embeddings\n",
                "X = text_embedder.encode(texts)\n",
                "\n",
                "# Train classifier\n",
                "classifier = LogisticRegression(max_iter=1000)\n",
                "classifier.fit(X, labels)\n",
                "\n",
                "# Test on new examples\n",
                "test_texts = [\n",
                "    \"This is absolutely fantastic!\",\n",
                "    \"Complete garbage, don't buy.\",\n",
                "    \"It does the job, I guess.\"\n",
                "]\n",
                "\n",
                "test_embeddings = text_embedder.encode(test_texts)\n",
                "predictions = classifier.predict(test_embeddings)\n",
                "\n",
                "print(\"\\nSentiment Classification Results:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for text, pred in zip(test_texts, predictions):\n",
                "    emoji = {\"positive\": \"üòä\", \"negative\": \"üòû\", \"neutral\": \"üòê\"}\n",
                "    print(f\"{emoji.get(pred, '?')} [{pred:8}] {text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 8. Best Practices\n",
                "\n",
                "### 8.1 Choosing the Right Model\n",
                "\n",
                "| Use Case | Recommended Model | Why |\n",
                "|----------|------------------|-----|\n",
                "| **General Search** | all-MiniLM-L6-v2 | Fast, good quality |\n",
                "| **High Accuracy** | all-mpnet-base-v2 | Best quality, slower |\n",
                "| **Multilingual** | paraphrase-multilingual-* | Cross-language support |\n",
                "| **Q&A Systems** | multi-qa-* | Optimized for questions |\n",
                "| **Production** | OpenAI text-embedding-3-* | Excellent quality, API |\n",
                "\n",
                "### 8.2 Performance Optimization Tips\n",
                "\n",
                "```python\n",
                "# ‚úÖ DO: Batch your embeddings\n",
                "embeddings = embedder.encode(list_of_texts)  # Single call\n",
                "\n",
                "# ‚ùå DON'T: Encode one at a time\n",
                "for text in list_of_texts:\n",
                "    embedding = embedder.encode(text)  # Slow!\n",
                "\n",
                "# ‚úÖ DO: Use caching for repeated queries\n",
                "cache = EmbeddingCache(max_size=10000)\n",
                "embedder = TextEmbedder(cache=cache)\n",
                "\n",
                "# ‚úÖ DO: Use GPU for large batches\n",
                "embedder = TextEmbedder(use_gpu=True)\n",
                "\n",
                "# ‚úÖ DO: Normalize embeddings for cosine similarity\n",
                "config = EmbeddingConfig(normalize=True)\n",
                "embedder = TextEmbedder(config=config)\n",
                "```\n",
                "\n",
                "### 8.3 Common Pitfalls\n",
                "\n",
                "| Pitfall | Solution |\n",
                "|---------|----------|\n",
                "| Long texts truncated | Chunk documents into smaller pieces |\n",
                "| Slow inference | Use batching, caching, GPU |\n",
                "| High memory usage | Process in batches, clear cache |\n",
                "| Domain mismatch | Fine-tune or use domain-specific model |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Summary\n",
                "\n",
                "In this notebook, we covered:\n",
                "\n",
                "1. **Embeddings Fundamentals** - Dense vector representations of data\n",
                "2. **Text Embeddings** - Using sentence-transformers for text\n",
                "3. **Image Embeddings** - Using CLIP for visual content\n",
                "4. **Multi-Modal Embeddings** - Joint text-image embedding space\n",
                "5. **Caching** - Improving performance with EmbeddingCache\n",
                "6. **Similarity Search** - Building search engines with embeddings\n",
                "7. **Applications** - Duplicate detection, classification\n",
                "8. **Best Practices** - Model selection, optimization\n",
                "\n",
                "### üéØ Key Takeaways\n",
                "\n",
                "- Embeddings capture semantic meaning in dense vectors\n",
                "- Cosine similarity measures how related two embeddings are\n",
                "- Caching dramatically improves performance\n",
                "- CLIP enables cross-modal (text-image) similarity\n",
                "- Choose models based on your specific use case\n",
                "\n",
                "### üìö Next Steps\n",
                "\n",
                "1. Explore the [Retrieval Module](../week7-retrieval/) for advanced search\n",
                "2. Learn about [Reranking](../week8-reranking/) to improve results\n",
                "3. Build a complete [RAG Pipeline](../week9-orchestration/) with embeddings"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}