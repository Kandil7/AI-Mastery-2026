{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéì Week 15: Capstone Project - End-to-End RAG System\n",
                "\n",
                "This notebook guides you through building a complete production RAG system.\n",
                "\n",
                "## Project Overview\n",
                "\n",
                "Build a **Document Q&A System** that:\n",
                "1. Ingests and processes documents\n",
                "2. Retrieves relevant context\n",
                "3. Generates accurate answers\n",
                "4. Provides citations\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## System Architecture\n",
                "\n",
                "```\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ                     DOCUMENT Q&A SYSTEM                              ‚îÇ\n",
                "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "‚îÇ                                                                      ‚îÇ\n",
                "‚îÇ  Documents ‚Üí [Chunking] ‚Üí [Embedding] ‚Üí [Vector Store]              ‚îÇ\n",
                "‚îÇ                                               ‚Üì                      ‚îÇ\n",
                "‚îÇ  Query ‚Üí [Query Processing] ‚Üí [Retrieval] ‚Üí [Context]               ‚îÇ\n",
                "‚îÇ                                               ‚Üì                      ‚îÇ\n",
                "‚îÇ                               [Reranking] ‚Üí [Top-K Docs]             ‚îÇ\n",
                "‚îÇ                                               ‚Üì                      ‚îÇ\n",
                "‚îÇ                               [Generation] ‚Üí [Answer + Citations]    ‚îÇ\n",
                "‚îÇ                                               ‚Üì                      ‚îÇ\n",
                "‚îÇ                               [Evaluation] ‚Üí [Quality Metrics]       ‚îÇ\n",
                "‚îÇ                                                                      ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import sys\n",
                "sys.path.insert(0, '../..')\n",
                "\n",
                "from dataclasses import dataclass\n",
                "from typing import List, Dict, Optional\n",
                "import numpy as np\n",
                "\n",
                "# Import our modules\n",
                "from src.embeddings import TextEmbedder, EmbeddingCache\n",
                "from src.retrieval import BM25Retriever, DenseRetriever, HybridRetriever\n",
                "from src.reranking import CrossEncoderReranker, DiversityReranker\n",
                "from src.orchestration import Chain, SequentialChain, LambdaChain, ConversationMemory, Message, MessageRole\n",
                "from src.evaluation import RAGEvaluator, EvaluationReport\n",
                "\n",
                "print(\"‚úÖ All modules imported!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 1: Document Processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class Chunk:\n",
                "    \"\"\"A document chunk with metadata.\"\"\"\n",
                "    id: str\n",
                "    content: str\n",
                "    doc_id: str\n",
                "    start_idx: int\n",
                "    end_idx: int\n",
                "    metadata: Dict = None\n",
                "\n",
                "class DocumentProcessor:\n",
                "    \"\"\"\n",
                "    Process documents into chunks for retrieval.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, chunk_size: int = 500, overlap: int = 50):\n",
                "        self.chunk_size = chunk_size\n",
                "        self.overlap = overlap\n",
                "    \n",
                "    def chunk_document(self, doc_id: str, text: str) -> List[Chunk]:\n",
                "        \"\"\"Split document into overlapping chunks.\"\"\"\n",
                "        chunks = []\n",
                "        start = 0\n",
                "        chunk_idx = 0\n",
                "        \n",
                "        while start < len(text):\n",
                "            end = min(start + self.chunk_size, len(text))\n",
                "            \n",
                "            # Try to end at sentence boundary\n",
                "            if end < len(text):\n",
                "                for punct in ['. ', '? ', '! ', '\\n']:\n",
                "                    last_punct = text[start:end].rfind(punct)\n",
                "                    if last_punct != -1:\n",
                "                        end = start + last_punct + len(punct)\n",
                "                        break\n",
                "            \n",
                "            chunk = Chunk(\n",
                "                id=f\"{doc_id}_chunk_{chunk_idx}\",\n",
                "                content=text[start:end].strip(),\n",
                "                doc_id=doc_id,\n",
                "                start_idx=start,\n",
                "                end_idx=end\n",
                "            )\n",
                "            chunks.append(chunk)\n",
                "            \n",
                "            start = end - self.overlap\n",
                "            chunk_idx += 1\n",
                "        \n",
                "        return chunks\n",
                "\n",
                "# Test\n",
                "processor = DocumentProcessor(chunk_size=200, overlap=20)\n",
                "\n",
                "sample_doc = \"\"\"\n",
                "Machine learning is a subset of artificial intelligence. It enables computers to learn from data.\n",
                "Deep learning is a type of machine learning that uses neural networks. Neural networks have many layers.\n",
                "Natural language processing helps computers understand text. It is used in chatbots and translation.\n",
                "\"\"\"\n",
                "\n",
                "chunks = processor.chunk_document(\"doc1\", sample_doc)\n",
                "print(f\"Created {len(chunks)} chunks from document\")\n",
                "for c in chunks:\n",
                "    print(f\"  [{c.id}]: {c.content[:50]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 2: Indexing Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.retrieval.retrieval import Document\n",
                "\n",
                "class IndexingPipeline:\n",
                "    \"\"\"\n",
                "    Pipeline for indexing documents.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.processor = DocumentProcessor(chunk_size=300, overlap=30)\n",
                "        self.embedder = TextEmbedder()\n",
                "        self.retriever = HybridRetriever(alpha=0.5)\n",
                "        self.chunks = []\n",
                "    \n",
                "    def ingest(self, documents: Dict[str, str]):\n",
                "        \"\"\"\n",
                "        Ingest documents into the index.\n",
                "        \n",
                "        Args:\n",
                "            documents: Dict of doc_id -> content\n",
                "        \"\"\"\n",
                "        print(f\"Ingesting {len(documents)} documents...\")\n",
                "        \n",
                "        # Chunk all documents\n",
                "        all_chunks = []\n",
                "        for doc_id, content in documents.items():\n",
                "            chunks = self.processor.chunk_document(doc_id, content)\n",
                "            all_chunks.extend(chunks)\n",
                "        \n",
                "        self.chunks = all_chunks\n",
                "        print(f\"Created {len(all_chunks)} chunks\")\n",
                "        \n",
                "        # Convert to Document objects for retriever\n",
                "        docs = [\n",
                "            Document(id=c.id, content=c.content, metadata={\"doc_id\": c.doc_id})\n",
                "            for c in all_chunks\n",
                "        ]\n",
                "        \n",
                "        # Index\n",
                "        self.retriever.index(docs)\n",
                "        print(\"‚úÖ Indexing complete!\")\n",
                "    \n",
                "    def search(self, query: str, top_k: int = 5):\n",
                "        \"\"\"Search for relevant chunks.\"\"\"\n",
                "        return self.retriever.retrieve(query, top_k=top_k)\n",
                "\n",
                "# Test\n",
                "pipeline = IndexingPipeline()\n",
                "\n",
                "docs = {\n",
                "    \"ml_intro\": \"Machine learning is AI that learns from data. It powers recommendations and predictions.\",\n",
                "    \"dl_intro\": \"Deep learning uses neural networks with many layers. It excels at image and text tasks.\",\n",
                "    \"nlp_intro\": \"NLP enables computers to understand human language. Applications include chatbots and translation.\"\n",
                "}\n",
                "\n",
                "pipeline.ingest(docs)\n",
                "\n",
                "results = pipeline.search(\"What is deep learning?\")\n",
                "print(f\"\\nSearch results:\")\n",
                "for r in results[:3]:\n",
                "    print(f\"  [{r.score:.3f}] {r.document.content[:60]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 3: RAG System"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class RAGResponse:\n",
                "    \"\"\"Response from RAG system.\"\"\"\n",
                "    answer: str\n",
                "    sources: List[str]\n",
                "    confidence: float\n",
                "\n",
                "class RAGSystem:\n",
                "    \"\"\"\n",
                "    Complete Retrieval-Augmented Generation system.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.indexer = IndexingPipeline()\n",
                "        self.reranker = CrossEncoderReranker()\n",
                "        self.memory = ConversationMemory(max_messages=10)\n",
                "        self.evaluator = RAGEvaluator()\n",
                "    \n",
                "    def ingest_documents(self, documents: Dict[str, str]):\n",
                "        \"\"\"Ingest documents for retrieval.\"\"\"\n",
                "        self.indexer.ingest(documents)\n",
                "    \n",
                "    def query(self, question: str, top_k: int = 3) -> RAGResponse:\n",
                "        \"\"\"Answer a question using RAG.\"\"\"\n",
                "        # 1. Retrieve\n",
                "        initial_results = self.indexer.search(question, top_k=top_k * 2)\n",
                "        \n",
                "        # 2. Rerank\n",
                "        docs = [r.document for r in initial_results]\n",
                "        reranked = self.reranker.rerank(question, docs, top_k=top_k)\n",
                "        \n",
                "        # 3. Build context\n",
                "        context_docs = [r.document for r in reranked]\n",
                "        context = \"\\n\\n\".join([f\"[{i+1}] {d.content}\" for i, d in enumerate(context_docs)])\n",
                "        \n",
                "        # 4. Generate answer (mock - replace with actual LLM)\n",
                "        answer = self._generate_answer(question, context)\n",
                "        \n",
                "        # 5. Update memory\n",
                "        self.memory.add_message(Message(role=MessageRole.USER, content=question))\n",
                "        self.memory.add_message(Message(role=MessageRole.ASSISTANT, content=answer))\n",
                "        \n",
                "        # 6. Compute confidence\n",
                "        avg_score = np.mean([r.rerank_score for r in reranked]) if reranked else 0\n",
                "        \n",
                "        return RAGResponse(\n",
                "            answer=answer,\n",
                "            sources=[d.id for d in context_docs],\n",
                "            confidence=avg_score\n",
                "        )\n",
                "    \n",
                "    def _generate_answer(self, question: str, context: str) -> str:\n",
                "        \"\"\"Generate answer from context (mock implementation).\"\"\"\n",
                "        # In production, call your LLM here\n",
                "        return f\"Based on the provided context about {context[:50]}..., the answer is: [Generated answer]\"\n",
                "\n",
                "# Test complete system\n",
                "rag = RAGSystem()\n",
                "rag.ingest_documents(docs)\n",
                "\n",
                "response = rag.query(\"What can deep learning do?\")\n",
                "print(f\"\\nAnswer: {response.answer}\")\n",
                "print(f\"Sources: {response.sources}\")\n",
                "print(f\"Confidence: {response.confidence:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Step 4: Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the RAG system\n",
                "evaluator = RAGEvaluator()\n",
                "\n",
                "# Test data\n",
                "test_cases = [\n",
                "    {\n",
                "        \"question\": \"What is machine learning?\",\n",
                "        \"expected\": \"Machine learning is AI that learns from data.\"\n",
                "    },\n",
                "    {\n",
                "        \"question\": \"What are neural networks?\",\n",
                "        \"expected\": \"Neural networks are used in deep learning.\"\n",
                "    }\n",
                "]\n",
                "\n",
                "# Run evaluation\n",
                "report = EvaluationReport(title=\"RAG System Evaluation\")\n",
                "\n",
                "for i, test in enumerate(test_cases):\n",
                "    response = rag.query(test[\"question\"])\n",
                "    \n",
                "    # Evaluate\n",
                "    faithfulness = evaluator.evaluate_faithfulness(response.answer, response.sources)\n",
                "    relevance = evaluator.evaluate_relevance(test[\"question\"], response.answer)\n",
                "    \n",
                "    report.add_metrics(f\"Test Case {i+1}\", {\n",
                "        \"faithfulness\": faithfulness,\n",
                "        \"relevance\": relevance,\n",
                "        \"confidence\": response.confidence\n",
                "    })\n",
                "\n",
                "print(report.to_markdown())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Capstone Checklist\n",
                "\n",
                "### Core Components\n",
                "- [x] Document chunking with overlap\n",
                "- [x] Hybrid retrieval (BM25 + Dense)\n",
                "- [x] Cross-encoder reranking\n",
                "- [x] Answer generation with context\n",
                "- [x] Conversation memory\n",
                "- [x] Evaluation metrics\n",
                "\n",
                "### Next Steps\n",
                "- [ ] Add actual LLM integration\n",
                "- [ ] Implement citation extraction\n",
                "- [ ] Add streaming responses\n",
                "- [ ] Deploy as API\n",
                "- [ ] Add monitoring"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}