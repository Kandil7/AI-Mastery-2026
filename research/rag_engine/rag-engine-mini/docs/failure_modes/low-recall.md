# ‚ùå Failure Mode: Low Recall (The "I Don't Know" Problem)

## ü§ï Symptoms
*   The user asks a question where the answer **definitely exists** in the documents.
*   The model replies: *"I'm sorry, I don't have that information"* or gives a generic answer.

## üîç Root Causes
1. **Wrong Chunk Size**: Information gets split across chunks, so no single chunk contains the full answer
2. **Vector-only retrieval**: Missing keyword search for exact phrase matching
3. **Poor Embeddings**: Model doesn't understand the semantic relationship between query and document
4. **Insufficient Query Expansion**: Single query doesn't capture all relevant terms

## üí° How This Repository Fixes This
### 1. Hybrid Search (Vector + Keyword)
```python
# Both vector and keyword search are performed
vector_results = await vector_store.search(query_embedding, top_k=10)
keyword_results = await keyword_store.search(query_text, top_k=10)

# Then fused together using RRF (Reciprocal Rank Fusion)
final_results = rrf_fusion(vector_results, keyword_results)
```

### 2. Proper Chunking Strategy
- Configurable chunk size (defaults to 512 tokens)
- Overlap preserves context across splits
- Semantic boundaries respected

### 3. Query Expansion
- Expands single query into multiple related queries
- Increases chance of finding relevant information

## üîß How to Trigger/Debug This Issue
1. **Disable Keyword Search**: Set `ENABLE_KEYWORD_SEARCH=false` in `.env`
2. **Reduce Top-K**: Lower the number of results retrieved from each store
3. **Use Simple Embeddings**: Switch to basic sentence transformers instead of domain-specific ones

## üìä Expected Impact
Without hybrid search: ~30% recall on information that exists in documents
With hybrid search: ~85% recall on the same information