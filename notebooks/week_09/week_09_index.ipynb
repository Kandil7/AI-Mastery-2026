{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcda Week 09: LLM Engineering & RAG\n\n## Modern AI Applications\n\n### Learning Path\n\n1. **[Transformers & Attention](01_transformers_attention.ipynb)** \u2b50\n   - Self-attention mathematics\n   - Multi-head attention\n   - Transformer architecture\n\n2. **[RAG Pipeline](02_rag_pipeline.ipynb)**\n   - Retrieval augmented generation\n   - Chunking strategies\n   - Advanced techniques (HyDE, reranking)\n\n3. **[Vector Databases](03_vector_databases.ipynb)**\n   - Chroma, Qdrant comparison\n   - HNSW algorithm\n   - Production considerations\n\n---\n\n## Integration with Project\n\nSee `src/llm/` and `src/production/` for production implementations.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}