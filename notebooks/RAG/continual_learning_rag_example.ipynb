{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning RAG Example\n",
    "\n",
    "This notebook demonstrates the Continual Learning RAG architecture that adapts and improves over time without forgetting previously learned information. It incorporates techniques like elastic weight consolidation and experience replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from src.rag_specialized.continual_learning.continual_learning_rag import (\n",
    "    ContinualLearningRAG, ContinualDocument, ContinualQuery, ForgettingMechanism\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Continual Learning RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Continual Learning RAG system\n",
    "continual_rag = ContinualLearningRAG(\n",
    "    forgetting_mechanism=ForgettingMechanism.EXPERIENCE_REPLAY,\n",
    "    experience_buffer_size=100\n",
    ")\n",
    "print(\"Continual Learning RAG system initialized!\")\n",
    "print(f\"Forgetting mechanism: {continual_rag.retriever.forgetting_mechanism.mechanism.value}\")\n",
    "print(f\"Experience buffer size: {continual_rag.retriever.experience_buffer.capacity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Continual Learning Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample continual learning documents with different topics and importance levels\n",
    "documents = [\n",
    "    ContinualDocument(\n",
    "        id=\"doc1\",\n",
    "        content=\"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data. It encompasses supervised, unsupervised, and reinforcement learning techniques.\",\n",
    "        importance_score=0.8,\n",
    "        metadata={\"domain\": \"AI\", \"difficulty\": 0.5, \"topic\": \"ML Basics\"}\n",
    "    ),\n",
    "    ContinualDocument(\n",
    "        id=\"doc2\",\n",
    "        content=\"Deep learning uses neural networks with multiple layers to model complex patterns in data. These networks can automatically discover representations needed for feature detection or classification.\",\n",
    "        importance_score=0.9,\n",
    "        metadata={\"domain\": \"Deep Learning\", \"difficulty\": 0.7, \"topic\": \"Neural Networks\"}\n",
    "    ),\n",
    "    ContinualDocument(\n",
    "        id=\"doc3\",\n",
    "        content=\"Natural language processing enables computers to understand, interpret, and generate human language in a valuable way. NLP combines computational linguistics with machine learning and deep learning models.\",\n",
    "        importance_score=0.7,\n",
    "        metadata={\"domain\": \"NLP\", \"difficulty\": 0.6, \"topic\": \"Language Models\"}\n",
    "    ),\n",
    "    ContinualDocument(\n",
    "        id=\"doc4\",\n",
    "        content=\"Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects.\",\n",
    "        importance_score=0.8,\n",
    "        metadata={\"domain\": \"Computer Vision\", \"difficulty\": 0.6, \"topic\": \"Image Recognition\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Created {len(documents)} sample continual learning documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"  Doc {i+1}: {doc.id} - {doc.metadata['domain']} - Importance: {doc.importance_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Documents to the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents to the system\n",
    "num_added = continual_rag.add_documents(documents)\n",
    "print(f\"Added {num_added} continual learning documents to the system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Execute Continual Learning Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continual learning query\n",
    "ml_query = ContinualQuery(\n",
    "    text=\"What is machine learning?\",\n",
    "    domain=\"AI\",\n",
    "    difficulty=0.4\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "query_text_hash = hashlib.md5(ml_query.text.encode()).hexdigest()\n",
    "query_embedding = np.frombuffer(bytes.fromhex(query_text_hash[:32]), dtype=np.float32)\n",
    "if len(query_embedding) < 384:\n",
    "    query_embedding = np.pad(query_embedding, (0, 384 - len(query_embedding)), 'constant')\n",
    "elif len(query_embedding) > 384:\n",
    "    query_embedding = query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "ml_result = continual_rag.query(ml_query, query_embedding, k=2)\n",
    "\n",
    "print(\"Machine Learning Query:\")\n",
    "print(f\"Query: {ml_query.text}\")\n",
    "print(f\"Answer: {ml_result.answer}\")\n",
    "print(f\"Adaptation needed: {ml_result.adaptation_needed}\")\n",
    "print(f\"Confidence: {ml_result.confidence:.3f}\")\n",
    "print(f\"Latency: {ml_result.latency_ms:.2f}ms\")\n",
    "print(f\"Sources: {len(ml_result.sources)} documents retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another query about deep learning\n",
    "dl_query = ContinualQuery(\n",
    "    text=\"Explain deep learning concepts\",\n",
    "    domain=\"Deep Learning\",\n",
    "    difficulty=0.7\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "dl_query_hash = hashlib.md5(dl_query.text.encode()).hexdigest()\n",
    "dl_query_embedding = np.frombuffer(bytes.fromhex(dl_query_hash[:32]), dtype=np.float32)\n",
    "if len(dl_query_embedding) < 384:\n",
    "    dl_query_embedding = np.pad(dl_query_embedding, (0, 384 - len(dl_query_embedding)), 'constant')\n",
    "elif len(dl_query_embedding) > 384:\n",
    "    dl_query_embedding = dl_query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "dl_result = continual_rag.query(dl_query, dl_query_embedding, k=2)\n",
    "\n",
    "print(\"\\nDeep Learning Query:\")\n",
    "print(f\"Query: {dl_query.text}\")\n",
    "print(f\"Answer: {dl_result.answer}\")\n",
    "print(f\"Adaptation needed: {dl_result.adaptation_needed}\")\n",
    "print(f\"Sources: {len(dl_result.sources)} documents retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Learning Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multiple interactions to demonstrate learning\n",
    "print(\"Simulating learning over multiple interactions...\")\n",
    "\n",
    "interaction_queries = [\n",
    "    (\"How does supervised learning work?\", \"ML\", 0.5),\n",
    "    (\"What are convolutional neural networks?\", \"CV\", 0.8),\n",
    "    (\"Explain transformer models\", \"NLP\", 0.7),\n",
    "    (\"What is reinforcement learning?\", \"RL\", 0.6),\n",
    "    (\"How does backpropagation work?\", \"ML\", 0.7)\n",
    "]\n",
    "\n",
    "for i, (query_text, domain, difficulty) in enumerate(interaction_queries):\n",
    "    query = ContinualQuery(text=query_text, domain=domain, difficulty=difficulty)\n",
    "    \n",
    "    # Create embedding\n",
    "    query_hash = hashlib.md5(query_text.encode()).hexdigest()\n",
    "    query_emb = np.frombuffer(bytes.fromhex(query_hash[:32]), dtype=np.float32)\n",
    "    if len(query_emb) < 384:\n",
    "        query_emb = np.pad(query_emb, (0, 384 - len(query_emb)), 'constant')\n",
    "    elif len(query_emb) > 384:\n",
    "        query_emb = query_emb[:384]\n",
    "    \n",
    "    result = continual_rag.query(query, query_emb, k=2)\n",
    "    print(f\"  Interaction {i+1}: '{query_text[:30]}...' -> Adaptation needed: {result.adaptation_needed}\")\n",
    "\n",
    "print(f\"\\nExperience buffer now contains {len(continual_rag.retriever.experience_buffer.buffer)} experiences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Learning Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the learning status of the system\n",
    "learning_status = continual_rag.get_learning_status()\n",
    "print(\"Learning Status:\")\n",
    "print(f\"  Total documents: {learning_status['total_documents']}\")\n",
    "print(f\"  Total experiences: {learning_status['total_experiences']}\")\n",
    "print(f\"  Total queries processed: {learning_status['total_queries_processed']}\")\n",
    "print(f\"  Average performance: {learning_status['average_performance']:.3f}\")\n",
    "print(f\"  Domains handled: {learning_status['domains_handled']}\")\n",
    "print(f\"  Adaptation needed: {learning_status['adaptation_needed']}\")\n",
    "\n",
    "# Show performance statistics\n",
    "perf_stats = learning_status['performance_stats']\n",
    "print(f\"  Performance stats: avg={perf_stats['average']:.3f}, min={perf_stats['min']:.3f}, max={perf_stats['max']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple queries to analyze performance over time\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"Explain natural language processing\",\n",
    "    \"What is computer vision?\",\n",
    "    \"Describe reinforcement learning\"\n",
    "]\n",
    "\n",
    "latencies = []\n",
    "confidences = []\n",
    "adaptation_needed = []\n",
    "\n",
    "for i, query_text in enumerate(test_queries):\n",
    "    query = ContinualQuery(text=query_text, domain=\"General\", difficulty=0.5)\n",
    "    \n",
    "    # Create embedding\n",
    "    query_hash = hashlib.md5(query_text.encode()).hexdigest()\n",
    "    query_emb = np.frombuffer(bytes.fromhex(query_hash[:32]), dtype=np.float32)\n",
    "    if len(query_emb) < 384:\n",
    "        query_emb = np.pad(query_emb, (0, 384 - len(query_emb)), 'constant')\n",
    "    elif len(query_emb) > 384:\n",
    "        query_emb = query_emb[:384]\n",
    "    \n",
    "    result = continual_rag.query(query, query_emb, k=2)\n",
    "    latencies.append(result.latency_ms)\n",
    "    confidences.append(result.confidence)\n",
    "    adaptation_needed.append(result.adaptation_needed)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Query {i+1}: '{query_text[:20]}...' -> Latency: {result.latency_ms:.2f}ms, Confidence: {result.confidence:.3f}\")\n",
    "\n",
    "print(f\"\\nOverall Performance:\")\n",
    "print(f\"Average query latency: {np.mean(latencies):.2f}ms\")\n",
    "print(f\"Latency std deviation: {np.std(latencies):.2f}ms\")\n",
    "print(f\"Average confidence: {np.mean(confidences):.3f}\")\n",
    "print(f\"Adaptation needed in {sum(adaptation_needed)}/{len(adaptation_needed)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger System Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more documents to trigger adaptation\n",
    "additional_docs = [\n",
    "    ContinualDocument(\n",
    "        id=\"doc5\",\n",
    "        content=\"Large language models are transformer-based neural networks trained on vast amounts of text data. They can generate human-like text and perform various natural language tasks.\",\n",
    "        importance_score=0.9,\n",
    "        metadata={\"domain\": \"LLM\", \"difficulty\": 0.8, \"topic\": \"Transformers\"}\n",
    "    ),\n",
    "    ContinualDocument(\n",
    "        id=\"doc6\",\n",
    "        content=\"Generative AI models can create new content such as text, images, music, or other data based on patterns learned from training data.\",\n",
    "        importance_score=0.8,\n",
    "        metadata={\"domain\": \"GenAI\", \"difficulty\": 0.7, \"topic\": \"Content Generation\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "continual_rag.add_documents(additional_docs)\n",
    "print(f\"Added {len(additional_docs)} additional documents\")\n",
    "\n",
    "# Check if adaptation is needed\n",
    "adaptation_performed = continual_rag.adapt()\n",
    "print(f\"System adaptation performed: {adaptation_performed}\")\n",
    "\n",
    "# Check updated learning status\n",
    "updated_status = continual_rag.get_learning_status()\n",
    "print(f\"Updated total documents: {updated_status['total_documents']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored the Continual Learning RAG architecture:\n",
    "\n",
    "1. **Initialization**: Created an instance of the ContinualLearningRAG system with experience replay\n",
    "2. **Continual Learning Documents**: Added documents with importance scores and domain metadata\n",
    "3. **Learning Simulation**: Executed multiple queries to simulate learning over time\n",
    "4. **Learning Status**: Examined the system's learning progress and experience accumulation\n",
    "5. **Performance Evaluation**: Measured query latency, confidence, and adaptation needs\n",
    "6. **System Adaptation**: Demonstrated how the system adapts based on accumulated experiences\n",
    "\n",
    "The Continual Learning RAG system successfully demonstrated learning capabilities, accumulating experiences and adapting its behavior over time while preventing catastrophic forgetting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}