{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Multi-Modal RAG Example\n",
    "\n",
    "This notebook demonstrates the Adaptive Multi-Modal RAG architecture that handles inputs and outputs across multiple modalities (text, image, audio, video). It dynamically adjusts its retrieval and generation strategies based on the input modality and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from src.rag_specialized.adaptive_multimodal.adaptive_multimodal_rag import (\n",
    "    AdaptiveMultiModalRAG, MultiModalDocument, MultiModalQuery, ModalityType\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Adaptive Multi-Modal RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Adaptive Multi-Modal RAG system\n",
    "adaptive_rag = AdaptiveMultiModalRAG()\n",
    "print(\"Adaptive Multi-Modal RAG system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Multi-Modal Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample multi-modal documents\n",
    "documents = [\n",
    "    MultiModalDocument(\n",
    "        id=\"doc1\",\n",
    "        text_content=\"Machine learning is a subset of artificial intelligence that focuses on algorithms that can learn from data. It encompasses supervised, unsupervised, and reinforcement learning techniques.\",\n",
    "        metadata={\"source\": \"AI textbook\", \"topic\": \"ML Basics\", \"author\": \"Dr. Smith\"},\n",
    "        modality_type=ModalityType.TEXT\n",
    "    ),\n",
    "    MultiModalDocument(\n",
    "        id=\"doc2\",\n",
    "        text_content=\"Deep learning uses neural networks with multiple layers to model complex patterns in data. These networks can automatically discover representations needed for feature detection or classification.\",\n",
    "        metadata={\"source\": \"Deep Learning Course\", \"topic\": \"Neural Networks\", \"author\": \"Prof. Johnson\"},\n",
    "        modality_type=ModalityType.TEXT\n",
    "    ),\n",
    "    MultiModalDocument(\n",
    "        id=\"doc3\",\n",
    "        text_content=\"Natural language processing enables computers to understand, interpret, and generate human language in a valuable way. NLP combines computational linguistics with machine learning and deep learning models.\",\n",
    "        metadata={\"source\": \"NLP Guide\", \"topic\": \"Language Models\", \"author\": \"Dr. Williams\"},\n",
    "        modality_type=ModalityType.TEXT\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Created {len(documents)} sample multi-modal documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Documents to the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents to the system\n",
    "num_added = adaptive_rag.add_documents(documents)\n",
    "print(f\"Added {num_added} documents to the Adaptive Multi-Modal RAG system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Execute Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text-based query\n",
    "text_query = MultiModalQuery(\n",
    "    text_query=\"What is machine learning?\",\n",
    "    preferred_modality=ModalityType.TEXT\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "query_text_hash = hashlib.md5(text_query.text_query.encode()).hexdigest()\n",
    "query_embedding = np.frombuffer(bytes.fromhex(query_text_hash[:32]), dtype=np.float32)\n",
    "if len(query_embedding) < 384:\n",
    "    query_embedding = np.pad(query_embedding, (0, 384 - len(query_embedding)), 'constant')\n",
    "elif len(query_embedding) > 384:\n",
    "    query_embedding = query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "result = adaptive_rag.query(text_query, k=3)\n",
    "\n",
    "print(\"Query Results:\")\n",
    "print(f\"Answer: {result.answer}\")\n",
    "print(f\"Confidence: {result.confidence:.3f}\")\n",
    "print(f\"Latency: {result.latency_ms:.2f}ms\")\n",
    "print(f\"Sources: {len(result.sources)} documents retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another query about deep learning\n",
    "dl_query = MultiModalQuery(\n",
    "    text_query=\"Explain deep learning concepts\",\n",
    "    preferred_modality=ModalityType.TEXT\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "dl_query_hash = hashlib.md5(dl_query.text_query.encode()).hexdigest()\n",
    "dl_query_embedding = np.frombuffer(bytes.fromhex(dl_query_hash[:32]), dtype=np.float32)\n",
    "if len(dl_query_embedding) < 384:\n",
    "    dl_query_embedding = np.pad(dl_query_embedding, (0, 384 - len(dl_query_embedding)), 'constant')\n",
    "elif len(dl_query_embedding) > 384:\n",
    "    dl_query_embedding = dl_query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "dl_result = adaptive_rag.query(dl_query, k=2)\n",
    "\n",
    "print(\"Deep Learning Query Results:\")\n",
    "print(f\"Answer: {dl_result.answer}\")\n",
    "print(f\"Confidence: {dl_result.confidence:.3f}\")\n",
    "print(f\"Latency: {dl_result.latency_ms:.2f}ms\")\n",
    "print(f\"Modalities used: {[m.value for m in dl_result.modalities_used]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the System's Internal State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the retriever's internal state\n",
    "print(f\"Number of documents in system: {len(adaptive_rag.retriever.documents)}\")\n",
    "print(f\"Embedding matrix shape: {adaptive_rag.retriever.embeddings.shape if adaptive_rag.retriever.embeddings is not None else 'None'}\")\n",
    "print(f\"Number of unique modalities: {len(adaptive_rag.retriever.encoder.processors)}\")\n",
    "\n",
    "# Display document information\n",
    "for i, doc in enumerate(adaptive_rag.retriever.documents):\n",
    "    print(f\"Document {i+1}: {doc.id} - {doc.modality_type.value} - {len(doc.text_content)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple queries to analyze performance\n",
    "queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does deep learning work?\",\n",
    "    \"Explain natural language processing\",\n",
    "    \"What are neural networks?\",\n",
    "    \"Describe supervised learning\"\n",
    "]\n",
    "\n",
    "latencies = []\n",
    "confidences = []\n",
    "\n",
    "for query_text in queries:\n",
    "    query = MultiModalQuery(text_query=query_text, preferred_modality=ModalityType.TEXT)\n",
    "    \n",
    "    # Create embedding\n",
    "    query_hash = hashlib.md5(query_text.encode()).hexdigest()\n",
    "    query_emb = np.frombuffer(bytes.fromhex(query_hash[:32]), dtype=np.float32)\n",
    "    if len(query_emb) < 384:\n",
    "        query_emb = np.pad(query_emb, (0, 384 - len(query_emb)), 'constant')\n",
    "    elif len(query_emb) > 384:\n",
    "        query_emb = query_emb[:384]\n",
    "    \n",
    "    result = adaptive_rag.query(query, k=2)\n",
    "    latencies.append(result.latency_ms)\n",
    "    confidences.append(result.confidence)\n",
    "\n",
    "print(f\"Average query latency: {np.mean(latencies):.2f}ms\")\n",
    "print(f\"Latency std deviation: {np.std(latencies):.2f}ms\")\n",
    "print(f\"Average confidence: {np.mean(confidences):.3f}\")\n",
    "print(f\"Confidence std deviation: {np.std(confidences):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored the Adaptive Multi-Modal RAG architecture:\n",
    "\n",
    "1. **Initialization**: Created an instance of the AdaptiveMultiModalRAG system\n",
    "2. **Document Addition**: Added multi-modal documents with different content and metadata\n",
    "3. **Query Processing**: Executed text-based queries and received responses\n",
    "4. **System Analysis**: Examined the internal state of the system\n",
    "5. **Performance Evaluation**: Measured query latency and confidence metrics\n",
    "\n",
    "The Adaptive Multi-Modal RAG system successfully processed queries and returned relevant responses while adapting its retrieval strategy based on the input modality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}