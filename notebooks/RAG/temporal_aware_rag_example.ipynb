{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal-Aware RAG Example\n",
    "\n",
    "This notebook demonstrates the Temporal-Aware RAG architecture that considers time-based information in both retrieval and generation processes. It handles time-sensitive queries and retrieves documents based on temporal relevance, recency, and historical context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "from src.rag_specialized.temporal_aware.temporal_aware_rag import (\n",
    "    TemporalAwareRAG, TemporalDocument, TemporalQuery, TemporalScope\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Temporal-Aware RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Temporal-Aware RAG system\n",
    "temporal_rag = TemporalAwareRAG(temporal_weight=0.4)\n",
    "print(\"Temporal-Aware RAG system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Temporal Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample temporal documents with different timestamps\n",
    "now = datetime.now()\n",
    "\n",
    "documents = [\n",
    "    TemporalDocument(\n",
    "        id=\"doc1\",\n",
    "        content=\"The company reported record profits in Q4 2023, with revenues reaching $1.2 billion.\",\n",
    "        timestamp=now - timedelta(days=30),  # 1 month ago\n",
    "        metadata={\"source\": \"financial_report\", \"quarter\": \"Q4_2023\", \"revenue\": \"$1.2B\"}\n",
    "    ),\n",
    "    TemporalDocument(\n",
    "        id=\"doc2\",\n",
    "        content=\"Market analysis from early 2023 showed steady growth across all sectors.\",\n",
    "        timestamp=now - timedelta(days=300),  # ~10 months ago\n",
    "        metadata={\"source\": \"market_analysis\", \"period\": \"early_2023\", \"growth\": \"steady\"}\n",
    "    ),\n",
    "    TemporalDocument(\n",
    "        id=\"doc3\",\n",
    "        content=\"The new product launch scheduled for next quarter is expected to drive significant growth.\",\n",
    "        timestamp=now + timedelta(days=90),  # 3 months in future\n",
    "        metadata={\"source\": \"planning_doc\", \"event\": \"product_launch\", \"expected_impact\": \"significant_growth\"}\n",
    "    ),\n",
    "    TemporalDocument(\n",
    "        id=\"doc4\",\n",
    "        content=\"Historical data from 2020 shows the impact of global events on market stability.\",\n",
    "        timestamp=now - timedelta(days=2200),  # ~6 years ago\n",
    "        metadata={\"source\": \"historical_data\", \"year\": \"2020\", \"impact\": \"market_volatility\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Created {len(documents)} sample temporal documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"  Doc {i+1}: {doc.timestamp.strftime('%Y-%m-%d')} - {doc.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Documents to the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents to the system\n",
    "num_added = temporal_rag.add_documents(documents)\n",
    "print(f\"Added {num_added} temporal documents to the system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Execute Temporal Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a recent-focused query\n",
    "recent_query = TemporalQuery(\n",
    "    text=\"What were the recent financial results?\",\n",
    "    reference_time=now,\n",
    "    temporal_scope=TemporalScope.RECENT,\n",
    "    recency_bias=0.8,\n",
    "    time_window_days=60  # Only consider last 60 days\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "query_text_hash = hashlib.md5(recent_query.text.encode()).hexdigest()\n",
    "query_embedding = np.frombuffer(bytes.fromhex(query_text_hash[:32]), dtype=np.float32)\n",
    "if len(query_embedding) < 384:\n",
    "    query_embedding = np.pad(query_embedding, (0, 384 - len(query_embedding)), 'constant')\n",
    "elif len(query_embedding) > 384:\n",
    "    query_embedding = query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "recent_result = temporal_rag.query(recent_query, query_embedding, k=2)\n",
    "\n",
    "print(\"Recent Financial Results Query:\")\n",
    "print(f\"Query: {recent_query.text}\")\n",
    "print(f\"Answer: {recent_result.answer}\")\n",
    "print(f\"Temporal context: {recent_result.temporal_context}\")\n",
    "print(f\"Temporal accuracy: {recent_result.temporal_accuracy:.3f}\")\n",
    "print(f\"Confidence: {recent_result.confidence:.3f}\")\n",
    "print(f\"Latency: {recent_result.latency_ms:.2f}ms\")\n",
    "print(f\"Sources: {len(recent_result.sources)} documents retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a historical-focused query\n",
    "historical_query = TemporalQuery(\n",
    "    text=\"What happened in 2020?\",\n",
    "    reference_time=now,\n",
    "    temporal_scope=TemporalScope.HISTORICAL,\n",
    "    recency_bias=0.1  # Low recency bias for historical focus\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "hist_query_hash = hashlib.md5(historical_query.text.encode()).hexdigest()\n",
    "hist_query_embedding = np.frombuffer(bytes.fromhex(hist_query_hash[:32]), dtype=np.float32)\n",
    "if len(hist_query_embedding) < 384:\n",
    "    hist_query_embedding = np.pad(hist_query_embedding, (0, 384 - len(hist_query_embedding)), 'constant')\n",
    "elif len(hist_query_embedding) > 384:\n",
    "    hist_query_embedding = hist_query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "hist_result = temporal_rag.query(historical_query, hist_query_embedding, k=2)\n",
    "\n",
    "print(\"\\nHistorical Query:\")\n",
    "print(f\"Query: {historical_query.text}\")\n",
    "print(f\"Answer: {hist_result.answer}\")\n",
    "print(f\"Temporal context: {hist_result.temporal_context}\")\n",
    "print(f\"Sources: {len(hist_result.sources)} documents retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a future-focused query\n",
    "future_query = TemporalQuery(\n",
    "    text=\"What are upcoming events?\",\n",
    "    reference_time=now,\n",
    "    temporal_scope=TemporalScope.FUTURE,\n",
    "    recency_bias=0.2\n",
    ")\n",
    "\n",
    "# Create a simple embedding for the query\n",
    "future_query_hash = hashlib.md5(future_query.text.encode()).hexdigest()\n",
    "future_query_embedding = np.frombuffer(bytes.fromhex(future_query_hash[:32]), dtype=np.float32)\n",
    "if len(future_query_embedding) < 384:\n",
    "    future_query_embedding = np.pad(future_query_embedding, (0, 384 - len(future_query_embedding)), 'constant')\n",
    "elif len(future_query_embedding) > 384:\n",
    "    future_query_embedding = future_query_embedding[:384]\n",
    "\n",
    "# Execute the query\n",
    "future_result = temporal_rag.query(future_query, future_query_embedding, k=2)\n",
    "\n",
    "print(\"\\nFuture Events Query:\")\n",
    "print(f\"Query: {future_query.text}\")\n",
    "print(f\"Answer: {future_result.answer}\")\n",
    "print(f\"Temporal context: {future_result.temporal_context}\")\n",
    "print(f\"Sources: {len(future_result.sources)} documents retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the System's Internal State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the retriever's internal state\n",
    "print(f\"Number of documents in system: {len(temporal_rag.retriever.documents)}\")\n",
    "print(f\"Embedding matrix shape: {temporal_rag.retriever.embeddings.shape if temporal_rag.retriever.embeddings is not None else 'None'}\")\n",
    "print(f\"Temporal weight: {temporal_rag.retriever.temporal_weight}\")\n",
    "\n",
    "# Display document information\n",
    "for i, doc in enumerate(temporal_rag.retriever.documents):\n",
    "    age_days = (now - doc.timestamp).days\n",
    "    print(f\"Document {i+1}: {doc.id} - {doc.timestamp.strftime('%Y-%m-%d')} ({age_days} days old) - {len(doc.content)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple queries to analyze performance\n",
    "queries = [\n",
    "    (\"recent\", \"What were the recent financial results?\"),\n",
    "    (\"historical\", \"What happened in early 2023?\"),\n",
    "    (\"general\", \"Tell me about company performance\"),\n",
    "    (\"future\", \"What are upcoming initiatives?\")\n",
    "]\n",
    "\n",
    "latencies = []\n",
    "confidences = []\n",
    "temporal_accuracies = []\n",
    "\n",
    "for scope, query_text in queries:\n",
    "    # Create temporal query based on scope\n",
    "    if scope == \"recent\":\n",
    "        query = TemporalQuery(\n",
    "            text=query_text,\n",
    "            reference_time=now,\n",
    "            temporal_scope=TemporalScope.RECENT,\n",
    "            recency_bias=0.8\n",
    "        )\n",
    "    elif scope == \"historical\":\n",
    "        query = TemporalQuery(\n",
    "            text=query_text,\n",
    "            reference_time=now,\n",
    "            temporal_scope=TemporalScope.HISTORICAL,\n",
    "            recency_bias=0.1\n",
    "        )\n",
    "    elif scope == \"future\":\n",
    "        query = TemporalQuery(\n",
    "            text=query_text,\n",
    "            reference_time=now,\n",
    "            temporal_scope=TemporalScope.FUTURE,\n",
    "            recency_bias=0.2\n",
    "        )\n",
    "    else:\n",
    "        query = TemporalQuery(\n",
    "            text=query_text,\n",
    "            reference_time=now,\n",
    "            temporal_scope=TemporalScope.ALL_TIME,\n",
    "            recency_bias=0.5\n",
    "        )\n",
    "    \n",
    "    # Create embedding\n",
    "    query_hash = hashlib.md5(query_text.encode()).hexdigest()\n",
    "    query_emb = np.frombuffer(bytes.fromhex(query_hash[:32]), dtype=np.float32)\n",
    "    if len(query_emb) < 384:\n",
    "        query_emb = np.pad(query_emb, (0, 384 - len(query_emb)), 'constant')\n",
    "    elif len(query_emb) > 384:\n",
    "        query_emb = query_emb[:384]\n",
    "    \n",
    "    result = temporal_rag.query(query, query_emb, k=2)\n",
    "    latencies.append(result.latency_ms)\n",
    "    confidences.append(result.confidence)\n",
    "    temporal_accuracies.append(result.temporal_accuracy)\n",
    "\n",
    "print(f\"Average query latency: {np.mean(latencies):.2f}ms\")\n",
    "print(f\"Latency std deviation: {np.std(latencies):.2f}ms\")\n",
    "print(f\"Average confidence: {np.mean(confidences):.3f}\")\n",
    "print(f\"Average temporal accuracy: {np.mean(temporal_accuracies):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored the Temporal-Aware RAG architecture:\n",
    "\n",
    "1. **Initialization**: Created an instance of the TemporalAwareRAG system\n",
    "2. **Temporal Documents**: Added documents with different timestamps (past, present, future)\n",
    "3. **Temporal Queries**: Executed queries with different temporal scopes (recent, historical, future)\n",
    "4. **System Analysis**: Examined the internal state and temporal characteristics\n",
    "5. **Performance Evaluation**: Measured query latency, confidence, and temporal accuracy\n",
    "\n",
    "The Temporal-Aware RAG system successfully processed time-sensitive queries and returned relevant responses while considering the temporal context of both documents and queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}