{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Week 11: RAG Systems\n",
                "\n",
                "Building a Retrieval-Augmented Generation system from scratch.\n",
                "\n",
                "## Learning Objectives\n",
                "1. Implement a Dense Retriever (Embeddings + Cosine Sim)\n",
                "2. Build a Chunking Strategy\n",
                "3. Create a Generator loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from typing import List, Dict, Any"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Document Chunking\n",
                "\n",
                "Simple sliding window chunker."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def chunk_text(text: str, chunk_size: int = 100, overlap: int = 20) -> List[str]:\n",
                "    words = text.split()\n",
                "    chunks = []\n",
                "    \n",
                "    for i in range(0, len(words), chunk_size - overlap):\n",
                "        chunk = \" \".join(words[i : i + chunk_size])\n",
                "        chunks.append(chunk)\n",
                "        \n",
                "    return chunks\n",
                "\n",
                "docs = [\n",
                "    \"Machine learning is a field of inquiry devoted to understanding and building methods that 'learn'\",\n",
                "    \"Deep learning is part of a broader family of machine learning methods based on artificial neural networks\",\n",
                "    \"Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability\"\n",
                "]\n",
                "\n",
                "all_chunks = []\n",
                "for doc in docs:\n",
                "    all_chunks.extend(chunk_text(doc, chunk_size=10, overlap=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Vector Database (Mock)\n",
                "\n",
                "Using numpy for dense retrieval."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class VectorStore:\n",
                "    def __init__(self):\n",
                "        self.embeddings = []\n",
                "        self.documents = []\n",
                "    \n",
                "    def add(self, docs: List[str]):\n",
                "        # Mock embeddings: random vectors for demo\n",
                "        self.documents.extend(docs)\n",
                "        new_embs = np.random.randn(len(docs), 128)\n",
                "        # Normalize\n",
                "        new_embs /= np.linalg.norm(new_embs, axis=1, keepdims=True)\n",
                "        \n",
                "        if len(self.embeddings) == 0:\n",
                "            self.embeddings = new_embs\n",
                "        else:\n",
                "            self.embeddings = np.vstack([self.embeddings, new_embs])\n",
                "            \n",
                "    def search(self, query: str, k: int = 3):\n",
                "        # Mock query embedding\n",
                "        q_emb = np.random.randn(128)\n",
                "        q_emb /= np.linalg.norm(q_emb)\n",
                "        \n",
                "        # Cosine similarity\n",
                "        scores = self.embeddings @ q_emb\n",
                "        top_indices = np.argsort(scores)[::-1][:k]\n",
                "        \n",
                "        return [(self.documents[i], scores[i]) for i in top_indices]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test RAG Retrieve\n",
                "store = VectorStore()\n",
                "store.add(all_chunks)\n",
                "\n",
                "results = store.search(\"What is machine learning?\")\n",
                "for doc, score in results:\n",
                "    print(f\"[{score:.4f}] {doc}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. RAG Pipeline\n",
                "\n",
                "Retrieve -> Augment -> Generate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def rag_generate(query, vector_store):\n",
                "    # 1. Retrieve\n",
                "    retrieved = vector_store.search(query, k=2)\n",
                "    context = \"\\n\".join([doc for doc, _ in retrieved])\n",
                "    \n",
                "    # 2. Augment\n",
                "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
                "    \n",
                "    # 3. Generate (Mock)\n",
                "    # In real world: output = model.generate(prompt)\n",
                "    return f\"[LLM Generated Answer based on] {prompt[:50]}...\" \n",
                "\n",
                "print(rag_generate(\"Explain Python\", store))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}