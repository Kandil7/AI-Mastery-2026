{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfd7\ufe0f ResNet Architecture\n\n## Residual Learning Revolution\n\n**Problem**: Very deep networks degrade (not just overfitting!)\n**Solution**: Skip connections\n\n$$y = F(x) + x$$\n\n---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nprint('\u2705 ResNet ready!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why ResNet Works\n\n### The Degradation Problem\n- 56-layer plain network WORSE than 20-layer\n- Not overfitting\u2014training error higher!\n\n### Residual Block Solution\n\n$$H(x) = F(x) + x$$\n\nwhere $F(x)$ is learned residual.\n\n**Key insight**: Easier to learn residual $F(x) = 0$ than identity $H(x) = x$\n\n### Gradient Flow\n\n$$\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial H} \\left( \\frac{\\partial F}{\\partial x} + 1 \\right)$$\n\nThe \"+ 1\" ensures gradient always flows!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualBlock:\n    \"\"\"Basic ResNet building block.\"\"\"\n    \n    def __init__(self, channels):\n        self.channels = channels\n        # In practice: Conv \u2192 BN \u2192 ReLU \u2192 Conv \u2192 BN\n        # Then: out = ReLU(residual + skip)\n    \n    def forward(self, x):\n        # Save input for skip connection\n        identity = x\n        \n        # Residual path (2 conv layers)\n        out = self.conv1(x)  # Simplified\n        out = self.relu(out)\n        out = self.conv2(out)\n        \n        # Add skip connection\n        out += identity\n        out = self.relu(out)\n        \n        return out\n\nprint('\u2705 ResNet block structure!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet Variants\n\n- **ResNet-18**: 18 layers\n- **ResNet-34**: 34 layers\n- **ResNet-50**: 50 layers (uses bottleneck)\n- **ResNet-101**: 101 layers\n- **ResNet-152**: 152 layers\n\n**Bottleneck design**: 1\u00d71 \u2192 3\u00d73 \u2192 1\u00d71 (reduces parameters)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}