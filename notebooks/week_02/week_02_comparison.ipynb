{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udd2c Week 02 Algorithm Comparison\n\nComparing all 8 algorithms on the same dataset to understand their strengths and weaknesses.\n\n---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nfrom sklearn.datasets import make_classification, load_iris\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n# Import all sklearn versions for fair comparison\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\nprint('\u2705 All algorithms loaded!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset: Iris Classification\n\nUsing the classic Iris dataset for comparison:\n- **Samples**: 150\n- **Features**: 4 (continuous)\n- **Classes**: 3 (balanced)\n- **Task**: Multi-class classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare data\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Scale for algorithms that need it\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f'Training set: {X_train.shape}')\nprint(f'Test set: {X_test.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all algorithms\nalgorithms = {\n    'Logistic Regression': LogisticRegression(max_iter=1000),\n    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n    'SVM (RBF)': SVC(kernel='rbf', random_state=42),\n    'Naive Bayes': GaussianNB(),\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n}\n\n# Store results\nresults = []\n\nfor name, model in algorithms.items():\n    # Choose scaled or unscaled data\n    if name in ['Logistic Regression', 'KNN (k=5)', 'SVM (RBF)']:\n        X_tr, X_te = X_train_scaled, X_test_scaled\n    else:\n        X_tr, X_te = X_train, X_test\n    \n    # Training time\n    start = time.time()\n    model.fit(X_tr, y_train)\n    train_time = time.time() - start\n    \n    # Prediction time\n    start = time.time()\n    y_pred = model.predict(X_te)\n    pred_time = time.time() - start\n    \n    # Metrics\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='weighted')\n    \n    # Cross-validation\n    cv_scores = cross_val_score(model, X_tr, y_train, cv=5)\n    \n    results.append({\n        'Algorithm': name,\n        'Accuracy': acc,\n        'F1 Score': f1,\n        'CV Mean': cv_scores.mean(),\n        'CV Std': cv_scores.std(),\n        'Train Time (ms)': train_time * 1000,\n        'Predict Time (ms)': pred_time * 1000\n    })\n\nimport pandas as pd\ndf_results = pd.DataFrame(results)\ndf_results = df_results.sort_values('Accuracy', ascending=False)\nprint(df_results.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Insights\n\n### Top Performers\n1. **Random Forest** - Most robust, little tuning needed\n2. **SVM** - Excellent for this dataset size\n3. **Logistic Regression** - Simple baseline, surprisingly good\n\n### Speed Champions\n1. **Naive Bayes** - Fastest training\n2. **Decision Trees** - Fast both training and prediction\n3. **Logistic Regression** - Good balance\n\n### Trade-offs\n- **Accuracy vs Speed**: Random Forest wins accuracy, Naive Bayes wins speed\n- **Interpretability**: Decision Trees most interpretable\n- **Scalability**: Naive Bayes scales best\n\n---\n\n## When to Use Which Algorithm\n\n| Scenario | Recommended | Why |\n|----------|-------------|-----|\n| **Need high accuracy, have time** | Random Forest | Best performance, robust |\n| **Real-time predictions** | Naive Bayes | Fastest |\n| **Need to explain model** | Decision Trees | Interpretable |\n| **High-dimensional data** | SVM | Kernel trick |\n| **Simple baseline** | Logistic Regression | Fast, interpretable |\n| **Small dataset** | KNN | No training needed |\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}