# Phase 2: Modern Deep Learning & Transformers

**Objective:** Transition to modern deep learning frameworks (PyTorch) and master Transformer architecture for NLP and vision.

## Key Topics:

*   **PyTorch Fundamentals:** Tensors, autograd, building custom layers and models.
*   **CNNs:** Architectures (ResNet, VGG), transfer learning, image classification.
*   **RNNs/LSTMs:** Sequence modeling basics.
*   **Transformers:** Self-attention mechanism, Encoder-Decoder architecture, common models (BERT, GPT variants).

## Deliverables:

*   PyTorch implementations in [`src/llm/`](../../src/llm/) (attention mechanism) and [`src/ml/`](../../src/ml/) (CNNs).
*   Notebooks in [`notebooks/03_deep_learning/`](../../notebooks/03_deep_learning/).
*   Documentation on Transformers ([`docs/04_tutorials/examples/TRANSFORMER_EXAMPLES.md`](../04_tutorials/examples/TRANSFORMER_EXAMPLES.md)) and Vision ([`docs/04_tutorials/examples/VISION_EXAMPLES.md`](../04_tutorials/examples/VISION_EXAMPLES.md)).
