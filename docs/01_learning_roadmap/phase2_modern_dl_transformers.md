# Phase 2: Modern Deep Learning & Transformers

**Objective:** Transition to modern deep learning frameworks (PyTorch) and master Transformer architecture for NLP and vision.

## Key Topics:

*   **PyTorch Fundamentals:** Mastering the basics of PyTorch, including tensor operations, automatic differentiation (`autograd`), and constructing custom layers and models. Focus on building an intuition for the framework's design.
*   **CNNs:** Understanding Convolutional Neural Networks, exploring popular architectures like ResNet and VGG, and applying concepts like transfer learning for image classification tasks. Implement a basic CNN from scratch using PyTorch.
*   **RNNs/LSTMs:** Grasping the fundamentals of sequence modeling with Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, essential for processing sequential data like text.
*   **Transformers:** Deep diving into the Transformer architecture, focusing on the self-attention mechanism, multi-head attention, and the Encoder-Decoder structure. Study common models like BERT for understanding and GPT variants for generation.

## Deliverables:

*   PyTorch implementations of attention mechanisms in [`src/llm/`](../../src/llm/) and CNN architectures in [`src/ml/`](../../src/ml/). This includes building custom layers and models using PyTorch.
*   Completion of key notebooks in [`notebooks/03_deep_learning/`](../../notebooks/03_deep_learning/), focusing on practical exercises for CNNs, RNNs/LSTMs, and Transformers.
*   In-depth documentation and examples related to Transformers ([`docs/04_tutorials/examples/TRANSFORMER_EXAMPLES.md`](../04_tutorials/examples/TRANSFORMER_EXAMPLES.md)) and Computer Vision ([`docs/04_tutorials/examples/VISION_EXAMPLES.md`](../04_tutorials/examples/VISION_EXAMPLES.md)) within the tutorials section.
