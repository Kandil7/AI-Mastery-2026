{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Notebook 09: Semantic Chunking (High Precision)\n",
    "\n",
    "Traditional chunking (like fixed-size windows) often breaks context in the middle of a sentence or a logical thought. **Semantic Chunking** uses AI to find the \"natural breaks\" in a document.\n",
    "\n",
    "### Learning Objectives:\n",
    "1. Understand the limitations of fixed-size chunking.\n",
    "2. Implement a **Similarity-Based Splitter** from scratch.\n",
    "3. Compare Semantic vs. Fixed chunking results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:05:38.579935Z",
     "iopub.status.busy": "2026-01-31T14:05:38.579935Z",
     "iopub.status.idle": "2026-01-31T14:05:38.587941Z",
     "shell.execute_reply": "2026-01-31T14:05:38.586926Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root = os.getcwd()\n",
    "rag_root = None\n",
    "\n",
    "while True:\n",
    "    candidate = os.path.join(root, 'sprints', 'rag_engine', 'rag-engine-mini')\n",
    "    if os.path.isdir(os.path.join(candidate, 'src')):\n",
    "        rag_root = candidate\n",
    "        break\n",
    "    if os.path.basename(root) == 'rag-engine-mini' and os.path.isdir(os.path.join(root, 'src')):\n",
    "        rag_root = root\n",
    "        break\n",
    "    parent = os.path.dirname(root)\n",
    "    if parent == root:\n",
    "        break\n",
    "    root = parent\n",
    "\n",
    "if rag_root:\n",
    "    sys.path.insert(0, rag_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:05:38.590928Z",
     "iopub.status.busy": "2026-01-31T14:05:38.589947Z",
     "iopub.status.idle": "2026-01-31T14:05:51.642726Z",
     "shell.execute_reply": "2026-01-31T14:05:51.640858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY not set; using dummy embeddings for demo.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import numpy as np\n",
    "from src.core.bootstrap import get_container\n",
    "from src.application.services.chunking import count_tokens\n",
    "\n",
    "container = get_container()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    class DummyEmbedder:\n",
    "        def embed_one(self, text: str):\n",
    "            seed = abs(hash(text)) % (2**32)\n",
    "            rng = np.random.default_rng(seed)\n",
    "            return rng.normal(size=64).tolist()\n",
    "\n",
    "    print(\"OPENAI_API_KEY not set; using dummy embeddings for demo.\")\n",
    "    embedder = DummyEmbedder()\n",
    "else:\n",
    "    embedder = container[\"embeddings\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Strategy: Sentence Similarity\n",
    "\n",
    "We split the text into sentences, embed them, and then calculate the \"distance\" between adjacent sentences. When the distance crosses a threshold, we know the topic has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:05:51.646727Z",
     "iopub.status.busy": "2026-01-31T14:05:51.645728Z",
     "iopub.status.idle": "2026-01-31T14:05:51.658265Z",
     "shell.execute_reply": "2026-01-31T14:05:51.656342Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def semantic_split(text: str, threshold: float = 0.8):\n",
    "    # 1. Split into sentences (simple split for demo)\n",
    "    sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 10]\n",
    "    \n",
    "    # 2. Embed sentences\n",
    "    embeddings = [embedder.embed_one(s) for s in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = [sentences[0]]\n",
    "    \n",
    "    for i in range(len(sentences) - 1):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[i+1])\n",
    "        \n",
    "        if sim < threshold:\n",
    "            # Topic shift detected!\n",
    "            chunks.append(\". \".join(current_chunk) + \".\")\n",
    "            current_chunk = [sentences[i+1]]\n",
    "        else:\n",
    "            current_chunk.append(sentences[i+1])\n",
    "            \n",
    "    chunks.append(\". \".join(current_chunk) + \".\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Live Test\n",
    "\n",
    "Notice how the semantic chunker groups the sentences by theme rather than character count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:05:51.662787Z",
     "iopub.status.busy": "2026-01-31T14:05:51.661788Z",
     "iopub.status.idle": "2026-01-31T14:05:51.681595Z",
     "shell.execute_reply": "2026-01-31T14:05:51.679592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "The sun is a star at the center of the solar system.\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "It is a nearly perfect sphere of hot plasma.\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Quantum mechanics is a fundamental theory in physics.\n",
      "\n",
      "\n",
      "--- Chunk 4 ---\n",
      "It describes the physical properties of nature at the scale of atoms.\n",
      "\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Baking a cake requires flour, eggs, and sugar.\n",
      "\n",
      "\n",
      "--- Chunk 6 ---\n",
      "You must preheat the oven to 350 degrees.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "The sun is a star at the center of the solar system. It is a nearly perfect sphere of hot plasma.\n",
    "Quantum mechanics is a fundamental theory in physics. It describes the physical properties of nature at the scale of atoms.\n",
    "Baking a cake requires flour, eggs, and sugar. You must preheat the oven to 350 degrees.\n",
    "\"\"\"\n",
    "\n",
    "semantic_chunks = semantic_split(sample_text, threshold=0.6)\n",
    "\n",
    "for i, chunk in enumerate(semantic_chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Why this matters for RAG\n",
    "\n",
    "By keeping semantically related sentences together:\n",
    "1. **Better Retrieval**: The vector for the chunk is more \"focused.\"\n",
    "2. **Lower Costs**: You don't retrieve irrelevant half-sentences from adjacent topics.\n",
    "3. **Higher Accuracy**: The LLM has perfect context for the specific topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
