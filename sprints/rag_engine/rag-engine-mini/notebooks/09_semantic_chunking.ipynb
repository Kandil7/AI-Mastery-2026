{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ“ Notebook 09: Semantic Chunking (High Precision)\n",
                "\n",
                "Traditional chunking (like fixed-size windows) often breaks context in the middle of a sentence or a logical thought. **Semantic Chunking** uses AI to find the \"natural breaks\" in a document.\n",
                "\n",
                "### Learning Objectives:\n",
                "1. Understand the limitations of fixed-size chunking.\n",
                "2. Implement a **Similarity-Based Splitter** from scratch.\n",
                "3. Compare Semantic vs. Fixed chunking results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List\n",
                "import numpy as np\n",
                "from src.core.bootstrap import get_container\n",
                "from src.application.services.chunking import count_tokens\n",
                "\n",
                "container = get_container()\n",
                "embedder = container[\"embeddings\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The Strategy: Sentence Similarity\n",
                "\n",
                "We split the text into sentences, embed them, and then calculate the \"distance\" between adjacent sentences. When the distance crosses a threshold, we know the topic has changed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def cosine_similarity(a, b):\n",
                "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
                "\n",
                "def semantic_split(text: str, threshold: float = 0.8):\n",
                "    # 1. Split into sentences (simple split for demo)\n",
                "    sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 10]\n",
                "    \n",
                "    # 2. Embed sentences\n",
                "    embeddings = [embedder.embed_one(s) for s in sentences]\n",
                "    \n",
                "    chunks = []\n",
                "    current_chunk = [sentences[0]]\n",
                "    \n",
                "    for i in range(len(sentences) - 1):\n",
                "        sim = cosine_similarity(embeddings[i], embeddings[i+1])\n",
                "        \n",
                "        if sim < threshold:\n",
                "            # Topic shift detected!\n",
                "            chunks.append(\". \".join(current_chunk) + \".\")\n",
                "            current_chunk = [sentences[i+1]]\n",
                "        else:\n",
                "            current_chunk.append(sentences[i+1])\n",
                "            \n",
                "    chunks.append(\". \".join(current_chunk) + \".\")\n",
                "    return chunks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Live Test\n",
                "\n",
                "Notice how the semantic chunker groups the sentences by theme rather than character count."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_text = \"\"\"\n",
                "The sun is a star at the center of the solar system. It is a nearly perfect sphere of hot plasma.\n",
                "Quantum mechanics is a fundamental theory in physics. It describes the physical properties of nature at the scale of atoms.\n",
                "Baking a cake requires flour, eggs, and sugar. You must preheat the oven to 350 degrees.\n",
                "\"\"\"\n",
                "\n",
                "semantic_chunks = semantic_split(sample_text, threshold=0.6)\n",
                "\n",
                "for i, chunk in enumerate(semantic_chunks):\n",
                "    print(f\"--- Chunk {i+1} ---\")\n",
                "    print(chunk)\n",
                "    print(\"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Why this matters for RAG\n",
                "\n",
                "By keeping semantically related sentences together:\n",
                "1. **Better Retrieval**: The vector for the chunk is more \"focused.\"\n",
                "2. **Lower Costs**: You don't retrieve irrelevant half-sentences from adjacent topics.\n",
                "3. **Higher Accuracy**: The LLM has perfect context for the specific topic."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}