{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìê Evaluation as Education: Measuring 'Goodness'\n",
                "\n",
                "In AI Engineering, \"It feels better\" is not a metric. We need numbers.\n",
                "This notebook covers the basics of **Retrieval Evaluation**."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Recall vs. Precision\n",
                "\n",
                "- **Recall**: Did we find the right document? (FOMO metric)\n",
                "- **Precision**: Is the document we found actually relevant? (Noise metric)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_recall_at_k(retrieved_ids, relevant_ids, k=3):\n",
                "    top_k = set(retrieved_ids[:k])\n",
                "    relevant = set(relevant_ids)\n",
                "    intersection = top_k.intersection(relevant)\n",
                "    return len(intersection) / len(relevant)\n",
                "\n",
                "# Scenario: We need Doc #5 and Doc #8.\n",
                "relevant = [5, 8]\n",
                "# System returns:\n",
                "retrieved = [1, 2, 5, 9, 8]\n",
                "\n",
                "print(\"Recall@3:\", calculate_recall_at_k(retrieved, relevant, k=3))\n",
                "print(\"Recall@5:\", calculate_recall_at_k(retrieved, relevant, k=5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Mean Reciprocal Rank (MRR)\n",
                "\n",
                "How *early* did the right answer appear? Finding it at reasonable position #1 is better than #10."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_mrr(retrieved_ids, relevant_id):\n",
                "    try:\n",
                "        rank = retrieved_ids.index(relevant_id) + 1\n",
                "        return 1 / rank\n",
                "    except ValueError:\n",
                "        return 0.0\n",
                "\n",
                "print(\"MRR (Found at 3):\", calculate_mrr([1, 2, 5], 5))\n",
                "print(\"MRR (Found at 1):\", calculate_mrr([5, 1, 2], 5))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}