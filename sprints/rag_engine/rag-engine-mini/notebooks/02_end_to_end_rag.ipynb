{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîç End-to-End RAG Pipeline\n",
                "\n",
                "> **Educational Notebook 02**: Complete RAG flow from document to answer.\n",
                "\n",
                "---\n",
                "\n",
                "## üìã What We'll Cover\n",
                "\n",
                "1. Text Extraction from PDF/DOCX\n",
                "2. Token-Aware Chunking\n",
                "3. Embedding Generation\n",
                "4. Vector Storage (Qdrant)\n",
                "5. Retrieval\n",
                "6. Prompt Building\n",
                "7. Answer Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup imports from src/\n",
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "from src.core.config import settings\n",
                "from src.domain.entities import Chunk, TenantId, DocumentId, ChunkSpec, Answer\n",
                "from src.application.services.chunking import chunk_text_token_aware\n",
                "from src.application.services.prompt_builder import build_rag_prompt, build_chat_messages\n",
                "from src.application.services.fusion import rrf_fusion\n",
                "from src.application.services.scoring import ScoredChunk"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Step 1: Text Extraction\n",
                "\n",
                "Extract text from documents using pypdf and python-docx."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate extracted text (in production, use DefaultTextExtractor)\n",
                "sample_document = \"\"\"\n",
                "# Machine Learning Fundamentals\n",
                "\n",
                "Machine learning (ML) is a subset of artificial intelligence that enables computers\n",
                "to learn from data without being explicitly programmed. There are three main types:\n",
                "\n",
                "## Supervised Learning\n",
                "In supervised learning, the algorithm learns from labeled training data. Examples include:\n",
                "- Classification: Predicting categories (spam detection, image classification)\n",
                "- Regression: Predicting continuous values (house prices, stock prices)\n",
                "\n",
                "## Unsupervised Learning  \n",
                "Unsupervised learning finds patterns in unlabeled data:\n",
                "- Clustering: Grouping similar items (customer segmentation)\n",
                "- Dimensionality reduction: Reducing features while preserving information (PCA)\n",
                "\n",
                "## Reinforcement Learning\n",
                "An agent learns by interacting with an environment, receiving rewards or penalties.\n",
                "Applications include game playing (AlphaGo) and robotics.\n",
                "\n",
                "## Deep Learning\n",
                "Deep learning uses neural networks with many layers. Key architectures:\n",
                "- CNNs: Convolutional Neural Networks for images\n",
                "- RNNs: Recurrent Neural Networks for sequences\n",
                "- Transformers: Attention-based models for language (BERT, GPT)\n",
                "\"\"\"\n",
                "\n",
                "print(f\"Document length: {len(sample_document)} characters\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÇÔ∏è Step 2: Chunking\n",
                "\n",
                "Split text into overlapping chunks for retrieval."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Chunk the document\n",
                "chunks_text = chunk_text_token_aware(\n",
                "    sample_document,\n",
                "    spec=ChunkSpec(max_tokens=150, overlap_tokens=30)\n",
                ")\n",
                "\n",
                "print(f\"Created {len(chunks_text)} chunks:\")\n",
                "for i, text in enumerate(chunks_text, 1):\n",
                "    print(f\"\\n--- Chunk {i} ({len(text)} chars) ---\")\n",
                "    print(text[:200] + \"...\" if len(text) > 200 else text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üî¢ Step 3: Create Chunk Objects"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tenant = TenantId(\"demo_user\")\n",
                "doc_id = DocumentId(\"ml_fundamentals\")\n",
                "\n",
                "chunks = [\n",
                "    Chunk(\n",
                "        id=f\"chunk_{i}\",\n",
                "        tenant_id=tenant,\n",
                "        document_id=doc_id,\n",
                "        text=text\n",
                "    )\n",
                "    for i, text in enumerate(chunks_text, 1)\n",
                "]\n",
                "\n",
                "print(f\"Created {len(chunks)} Chunk objects\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîç Step 4: Simulate Retrieval\n",
                "\n",
                "In production, this would query Qdrant for vector similarity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate retrieval - select chunks containing relevant keywords\n",
                "question = \"What is the difference between supervised and unsupervised learning?\"\n",
                "\n",
                "# Simple keyword matching (in production: vector + keyword search)\n",
                "relevant_chunks = [\n",
                "    c for c in chunks\n",
                "    if \"supervised\" in c.text.lower() or \"unsupervised\" in c.text.lower()\n",
                "]\n",
                "\n",
                "print(f\"Found {len(relevant_chunks)} relevant chunks:\")\n",
                "for c in relevant_chunks:\n",
                "    print(f\"  - {c.id}: {c.text[:80]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìú Step 5: Build Prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build RAG prompt with guardrails\n",
                "prompt = build_rag_prompt(\n",
                "    question=question,\n",
                "    chunks=relevant_chunks,\n",
                "    max_context_chars=4000\n",
                ")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"GENERATED PROMPT:\")\n",
                "print(\"=\" * 60)\n",
                "print(prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üí¨ Step 6: Generate Answer (Simulated)\n",
                "\n",
                "In production, this would call OpenAI or Ollama."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate LLM response\n",
                "simulated_answer = \"\"\"\n",
                "Based on the context provided:\n",
                "\n",
                "**Supervised Learning** uses labeled training data where the algorithm learns\n",
                "from examples with known outcomes. Common applications include classification\n",
                "(like spam detection) and regression (like predicting house prices).\n",
                "\n",
                "**Unsupervised Learning** works with unlabeled data and finds patterns\n",
                "without predefined categories. It's used for clustering (grouping similar items)\n",
                "and dimensionality reduction (simplifying data while preserving information).\n",
                "\n",
                "The key difference is that supervised learning requires labeled examples,\n",
                "while unsupervised learning discovers structure in unlabeled data.\n",
                "\"\"\"\n",
                "\n",
                "# Create Answer object\n",
                "answer = Answer(\n",
                "    text=simulated_answer,\n",
                "    sources=[c.id for c in relevant_chunks]\n",
                ")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"ANSWER:\")\n",
                "print(\"=\" * 60)\n",
                "print(answer.text)\n",
                "print(f\"\\nSources: {list(answer.sources)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìö Next Steps\n",
                "\n",
                "Continue with:\n",
                "- **03_hybrid_search_and_rerank.ipynb** - Deep dive into hybrid retrieval and RRF fusion"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}