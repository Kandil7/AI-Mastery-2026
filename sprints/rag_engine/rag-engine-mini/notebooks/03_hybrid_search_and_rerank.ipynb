{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”€ Hybrid Search & Reranking\n",
    "\n",
    "> **Educational Notebook 03**: Deep dive into hybrid retrieval with RRF fusion.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Why Hybrid Search?\n",
    "\n",
    "| Method | Strengths | Weaknesses |\n",
    "|--------|-----------|------------|\n",
    "| **Vector** | Semantic similarity, synonyms | Misses exact matches |\n",
    "| **Keyword** | Exact matches, names, numbers | Misses paraphrases |\n",
    "| **Hybrid** | Best of both | More complex |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:09:22.541708Z",
     "iopub.status.busy": "2026-01-31T13:09:22.541708Z",
     "iopub.status.idle": "2026-01-31T13:09:24.572836Z",
     "shell.execute_reply": "2026-01-31T13:09:24.570241Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.domain.entities import Chunk, TenantId, DocumentId\n",
    "from src.application.services.fusion import rrf_fusion, weighted_fusion\n",
    "from src.application.services.scoring import ScoredChunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Simulating Vector vs Keyword Results\n",
    "\n",
    "Let's create sample results from both search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:09:24.575362Z",
     "iopub.status.busy": "2026-01-31T13:09:24.575362Z",
     "iopub.status.idle": "2026-01-31T13:09:24.582492Z",
     "shell.execute_reply": "2026-01-31T13:09:24.582260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Results:\n",
      "  v1: 0.92 - Machine learning enables computers to learn from d...\n",
      "  v2: 0.88 - AI systems can improve through experience....\n",
      "  v3: 0.85 - Deep learning uses neural networks....\n",
      "  v4: 0.80 - Data science involves statistical analysis....\n",
      "\n",
      "Keyword Results:\n",
      "  k1: 15.20 - Machine learning algorithms are widely used....\n",
      "  v1: 12.80 - Machine learning enables computers to learn from d...\n",
      "  k2: 10.50 - The term 'machine learning' was coined in 1959....\n",
      "  k3: 8.30 - Learning rate is an important hyperparameter....\n"
     ]
    }
   ],
   "source": [
    "# Helper to create chunks\n",
    "def make_chunk(id: str, text: str) -> Chunk:\n",
    "    return Chunk(\n",
    "        id=id,\n",
    "        tenant_id=TenantId(\"demo\"),\n",
    "        document_id=DocumentId(\"doc\"),\n",
    "        text=text\n",
    "    )\n",
    "\n",
    "# Simulated vector search results (semantic similarity)\n",
    "vector_results = [\n",
    "    ScoredChunk(make_chunk(\"v1\", \"Machine learning enables computers to learn from data.\"), 0.92),\n",
    "    ScoredChunk(make_chunk(\"v2\", \"AI systems can improve through experience.\"), 0.88),\n",
    "    ScoredChunk(make_chunk(\"v3\", \"Deep learning uses neural networks.\"), 0.85),\n",
    "    ScoredChunk(make_chunk(\"v4\", \"Data science involves statistical analysis.\"), 0.80),\n",
    "]\n",
    "\n",
    "# Simulated keyword search results (BM25/FTS)\n",
    "keyword_results = [\n",
    "    ScoredChunk(make_chunk(\"k1\", \"Machine learning algorithms are widely used.\"), 15.2),\n",
    "    ScoredChunk(make_chunk(\"v1\", \"Machine learning enables computers to learn from data.\"), 12.8),  # Same as v1!\n",
    "    ScoredChunk(make_chunk(\"k2\", \"The term 'machine learning' was coined in 1959.\"), 10.5),\n",
    "    ScoredChunk(make_chunk(\"k3\", \"Learning rate is an important hyperparameter.\"), 8.3),\n",
    "]\n",
    "\n",
    "print(\"Vector Results:\")\n",
    "for r in vector_results:\n",
    "    print(f\"  {r.chunk.id}: {r.score:.2f} - {r.chunk.text[:50]}...\")\n",
    "\n",
    "print(\"\\nKeyword Results:\")\n",
    "for r in keyword_results:\n",
    "    print(f\"  {r.chunk.id}: {r.score:.2f} - {r.chunk.text[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”€ RRF Fusion\n",
    "\n",
    "**Reciprocal Rank Fusion** merges results without needing to calibrate scores:\n",
    "\n",
    "$$\\text{RRF\\_score}(d) = \\sum_{r \\in R} \\frac{1}{k + \\text{rank}_r(d)}$$\n",
    "\n",
    "Where:\n",
    "- $k$ is a constant (default 60)\n",
    "- $\\text{rank}_r(d)$ is the rank of document $d$ in result list $r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:09:24.585689Z",
     "iopub.status.busy": "2026-01-31T13:09:24.585511Z",
     "iopub.status.idle": "2026-01-31T13:09:24.592834Z",
     "shell.execute_reply": "2026-01-31T13:09:24.592315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRF Fused Results:\n",
      "============================================================\n",
      "1. v1: RRF=0.0325\n",
      "   Machine learning enables computers to learn from data....\n",
      "2. k1: RRF=0.0164\n",
      "   Machine learning algorithms are widely used....\n",
      "3. v2: RRF=0.0161\n",
      "   AI systems can improve through experience....\n",
      "4. v3: RRF=0.0159\n",
      "   Deep learning uses neural networks....\n",
      "5. k2: RRF=0.0159\n",
      "   The term 'machine learning' was coined in 1959....\n",
      "6. v4: RRF=0.0156\n",
      "   Data science involves statistical analysis....\n",
      "7. k3: RRF=0.0156\n",
      "   Learning rate is an important hyperparameter....\n"
     ]
    }
   ],
   "source": [
    "# Apply RRF fusion\n",
    "fused = rrf_fusion(\n",
    "    vector_hits=vector_results,\n",
    "    keyword_hits=keyword_results,\n",
    "    k=60,\n",
    "    out_limit=10\n",
    ")\n",
    "\n",
    "print(\"RRF Fused Results:\")\n",
    "print(\"=\" * 60)\n",
    "for i, r in enumerate(fused, 1):\n",
    "    print(f\"{i}. {r.chunk.id}: RRF={r.score:.4f}\")\n",
    "    print(f\"   {r.chunk.text[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Understanding RRF Scores\n",
    "\n",
    "Notice that `v1` appears in BOTH result lists, so it gets boosted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:09:24.595707Z",
     "iopub.status.busy": "2026-01-31T13:09:24.595707Z",
     "iopub.status.idle": "2026-01-31T13:09:24.601083Z",
     "shell.execute_reply": "2026-01-31T13:09:24.601083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 RRF Score Breakdown:\n",
      "  Vector (rank 1): 1/(60+1) = 0.0164\n",
      "  Keyword (rank 2): 1/(60+2) = 0.0161\n",
      "  Total: 0.0325\n",
      "\n",
      "k1 RRF Score: 0.0164 (only in keyword list)\n",
      "\n",
      "v1 is higher because it appears in BOTH lists!\n"
     ]
    }
   ],
   "source": [
    "# Manual RRF calculation for v1\n",
    "k = 60\n",
    "\n",
    "# v1 is rank 1 in vector results\n",
    "v1_vector_contribution = 1 / (k + 1)\n",
    "\n",
    "# v1 is rank 2 in keyword results\n",
    "v1_keyword_contribution = 1 / (k + 2)\n",
    "\n",
    "v1_total = v1_vector_contribution + v1_keyword_contribution\n",
    "\n",
    "print(f\"v1 RRF Score Breakdown:\")\n",
    "print(f\"  Vector (rank 1): 1/(60+1) = {v1_vector_contribution:.4f}\")\n",
    "print(f\"  Keyword (rank 2): 1/(60+2) = {v1_keyword_contribution:.4f}\")\n",
    "print(f\"  Total: {v1_total:.4f}\")\n",
    "\n",
    "# Compare to k1 (only in keyword, rank 1)\n",
    "k1_total = 1 / (k + 1)\n",
    "print(f\"\\nk1 RRF Score: {k1_total:.4f} (only in keyword list)\")\n",
    "print(f\"\\nv1 is higher because it appears in BOTH lists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Cross-Encoder Reranking\n",
    "\n",
    "After fusion, we apply a Cross-Encoder to rerank by actual relevance.\n",
    "\n",
    "**How it works:**\n",
    "1. Take (query, passage) pairs\n",
    "2. Cross-Encoder scores each pair\n",
    "3. Sort by Cross-Encoder score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:09:24.605810Z",
     "iopub.status.busy": "2026-01-31T13:09:24.605712Z",
     "iopub.status.idle": "2026-01-31T13:09:24.611706Z",
     "shell.execute_reply": "2026-01-31T13:09:24.611706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'What is machine learning?'\n",
      "\n",
      "After Cross-Encoder Reranking:\n",
      "============================================================\n",
      "1. v1: CE=0.95\n",
      "   Machine learning enables computers to learn from data....\n",
      "2. k1: CE=0.88\n",
      "   Machine learning algorithms are widely used....\n",
      "3. k2: CE=0.85\n",
      "   The term 'machine learning' was coined in 1959....\n",
      "4. v2: CE=0.72\n",
      "   AI systems can improve through experience....\n",
      "5. v3: CE=0.65\n",
      "   Deep learning uses neural networks....\n"
     ]
    }
   ],
   "source": [
    "# Simulate Cross-Encoder scoring\n",
    "# In production, use CrossEncoderReranker from src/adapters/rerank/\n",
    "\n",
    "query = \"What is machine learning?\"\n",
    "\n",
    "# Simulated Cross-Encoder scores (would come from the model)\n",
    "cross_encoder_scores = {\n",
    "    \"v1\": 0.95,  # Best match for the query\n",
    "    \"k1\": 0.88,\n",
    "    \"v2\": 0.72,\n",
    "    \"k2\": 0.85,  # Historical context, decent match\n",
    "    \"v3\": 0.65,\n",
    "    \"k3\": 0.40,  # Poor match - about learning rate\n",
    "    \"v4\": 0.50,\n",
    "}\n",
    "\n",
    "# Rerank by Cross-Encoder score\n",
    "reranked = sorted(\n",
    "    fused,\n",
    "    key=lambda x: cross_encoder_scores.get(x.chunk.id, 0),\n",
    "    reverse=True\n",
    ")[:5]  # Top 5\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\nAfter Cross-Encoder Reranking:\")\n",
    "print(\"=\" * 60)\n",
    "for i, r in enumerate(reranked, 1):\n",
    "    ce_score = cross_encoder_scores.get(r.chunk.id, 0)\n",
    "    print(f\"{i}. {r.chunk.id}: CE={ce_score:.2f}\")\n",
    "    print(f\"   {r.chunk.text[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Comparison: Before vs After Reranking\n",
    "\n",
    "Notice how reranking improves precision by demoting less relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:09:24.611706Z",
     "iopub.status.busy": "2026-01-31T13:09:24.611706Z",
     "iopub.status.idle": "2026-01-31T13:09:24.620489Z",
     "shell.execute_reply": "2026-01-31T13:09:24.619396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE Reranking (RRF order):\n",
      "  1. v1 (CE=0.95)\n",
      "  2. k1 (CE=0.88)\n",
      "  3. v2 (CE=0.72)\n",
      "  4. v3 (CE=0.65)\n",
      "  5. k2 (CE=0.85)\n",
      "\n",
      "AFTER Reranking (CE order):\n",
      "  1. v1 (CE=0.95)\n",
      "  2. k1 (CE=0.88)\n",
      "  3. k2 (CE=0.85)\n",
      "  4. v2 (CE=0.72)\n",
      "  5. v3 (CE=0.65)\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE Reranking (RRF order):\")\n",
    "for i, r in enumerate(fused[:5], 1):\n",
    "    ce_score = cross_encoder_scores.get(r.chunk.id, 0)\n",
    "    print(f\"  {i}. {r.chunk.id} (CE={ce_score:.2f})\")\n",
    "\n",
    "print(\"\\nAFTER Reranking (CE order):\")\n",
    "for i, r in enumerate(reranked, 1):\n",
    "    ce_score = cross_encoder_scores.get(r.chunk.id, 0)\n",
    "    print(f\"  {i}. {r.chunk.id} (CE={ce_score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Key Takeaways\n",
    "\n",
    "1. **Hybrid Search** combines semantic (vector) and lexical (keyword) retrieval\n",
    "2. **RRF Fusion** merges results without requiring score calibration\n",
    "3. **Cross-Encoder Reranking** improves precision by scoring (query, passage) pairs\n",
    "4. Items appearing in BOTH result lists get boosted by RRF\n",
    "5. Reranking is crucial for production RAG quality\n",
    "\n",
    "---\n",
    "\n",
    "ðŸŽ‰ **Congratulations!** You've completed the RAG Engine Mini educational notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
