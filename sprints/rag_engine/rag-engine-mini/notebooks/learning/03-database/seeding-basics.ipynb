{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Seeding: Complete Guide\n",
    "\n",
    "## What You'll Learn\n",
    "- What database seeding is and why it matters\n",
    "- How to generate realistic test data using Faker\n",
    "- Strategies for seeding different data types\n",
    "- Best practices for idempotent, safe seeding\n",
    "- Performance optimization techniques\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of SQL and databases\n",
    "- Familiarity with SQLAlchemy ORM\n",
    "- Python 3.10+ environment\n",
    "\n",
    "---\n",
    "\n",
    "# Part 1: Introduction to Database Seeding\n",
    "\n",
    "## Definition\n",
    "\n",
    "**Database seeding** is the process of populating a database with initial data for development, testing, or demonstration purposes.\n",
    "\n",
    "### Why Seeding Matters\n",
    "\n",
    "1. **Development Productivity**: Pre-populated data accelerates feature development\n",
    "2. **Testing Realism**: Empty databases hide edge cases and performance issues\n",
    "3. **API Testing**: Endpoints need realistic data to validate behavior\n",
    "4. **UI/UX Validation**: Pagination, search, and filtering need varied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:13.323453Z",
     "iopub.status.busy": "2026-01-31T14:07:13.323453Z",
     "iopub.status.idle": "2026-01-31T14:07:13.332537Z",
     "shell.execute_reply": "2026-01-31T14:07:13.331250Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root = os.getcwd()\n",
    "rag_root = None\n",
    "\n",
    "while True:\n",
    "    candidate = os.path.join(root, 'sprints', 'rag_engine', 'rag-engine-mini')\n",
    "    if os.path.isdir(os.path.join(candidate, 'src')):\n",
    "        rag_root = candidate\n",
    "        break\n",
    "    if os.path.basename(root) == 'rag-engine-mini' and os.path.isdir(os.path.join(root, 'src')):\n",
    "        rag_root = root\n",
    "        break\n",
    "    parent = os.path.dirname(root)\n",
    "    if parent == root:\n",
    "        break\n",
    "    root = parent\n",
    "\n",
    "if rag_root:\n",
    "    sys.path.insert(0, rag_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:13.335489Z",
     "iopub.status.busy": "2026-01-31T14:07:13.334491Z",
     "iopub.status.idle": "2026-01-31T14:07:17.798896Z",
     "shell.execute_reply": "2026-01-31T14:07:17.797896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Database not available. Start Postgres or set DATABASE_URL to run this section.\n"
     ]
    }
   ],
   "source": [
    "# Let's see what happens without seeding\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import os\n",
    "\n",
    "# Database URL - adjust as needed\n",
    "DATABASE_URL = os.getenv(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql://postgres:postgres@localhost:5432/rag_engine\"\n",
    ")\n",
    "\n",
    "DB_AVAILABLE = False\n",
    "session = None\n",
    "try:\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    # Query empty database\n",
    "    user_count = session.execute(text(\"SELECT COUNT(*) FROM users\")).scalar()\n",
    "    doc_count = session.execute(text(\"SELECT COUNT(*) FROM documents\")).scalar()\n",
    "\n",
    "    DB_AVAILABLE = True\n",
    "\n",
    "    print(f\"Users: {user_count}\")\n",
    "    print(f\"Documents: {doc_count}\")\n",
    "    print(\"\\nEmpty database - can't test search or pagination!\")\n",
    "except OperationalError:\n",
    "    DB_AVAILABLE = False\n",
    "    session = None\n",
    "    print(\"??  Database not available. Start Postgres or set DATABASE_URL to run this section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: The Faker Library\n",
    "\n",
    "## What is Faker?\n",
    "\n",
    "Faker is a Python library that generates fake data for testing. It creates realistic data that mirrors production patterns.\n",
    "\n",
    "### Installation\n",
    "```bash\n",
    "pip install faker\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:17.801420Z",
     "iopub.status.busy": "2026-01-31T14:07:17.801420Z",
     "iopub.status.idle": "2026-01-31T14:07:18.280799Z",
     "shell.execute_reply": "2026-01-31T14:07:18.279786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== User Data ===\n",
      "Email:     zoconnor@example.com\n",
      "Name:      Tara Nelson\n",
      "UUID:      1fcff454-5f81-4cb9-a964-5f8b6facaa50\n",
      "\n",
      "=== Document Data ===\n",
      "Filename:  or.html\n",
      "MIME Type: image/svg+xml\n",
      "SHA256:    fa1f24e71ef8300134fa808e7d97eaf5...\n",
      "Size:      373141 bytes\n",
      "\n",
      "=== Content Data ===\n",
      "Sentence:  Most save one coach.\n",
      "Paragraph: Couple game age fund. Without season about vote that side condition....\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "# Create Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# For reproducibility, set a seed\n",
    "Faker.seed(12345)\n",
    "\n",
    "# Generate various types of data\n",
    "print(\"=== User Data ===\")\n",
    "print(f\"Email:     {fake.email()}\")\n",
    "print(f\"Name:      {fake.name()}\")\n",
    "print(f\"UUID:      {fake.uuid4()}\")\n",
    "\n",
    "print(\"\\n=== Document Data ===\")\n",
    "print(f\"Filename:  {fake.file_name()}\")\n",
    "print(f\"MIME Type: {fake.mime_type()}\")\n",
    "print(f\"SHA256:    {fake.sha256(raw_output=False)[:32]}...\")\n",
    "print(f\"Size:      {fake.random_int(min=1000, max=1000000)} bytes\")\n",
    "\n",
    "print(\"\\n=== Content Data ===\")\n",
    "print(f\"Sentence:  {fake.sentence()}\")\n",
    "print(f\"Paragraph: {fake.paragraph(nb_sentences=3)[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding for Reproducibility\n",
    "\n",
    "Setting a seed ensures the same data is generated each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:18.282782Z",
     "iopub.status.busy": "2026-01-31T14:07:18.282782Z",
     "iopub.status.idle": "2026-01-31T14:07:18.298344Z",
     "shell.execute_reply": "2026-01-31T14:07:18.297338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without seed:\n",
      "Run 1: delgadodaniel@example.net\n",
      "Run 2: jillhall@example.net\n",
      "\n",
      "With seed:\n",
      "Run 1: mosleyashley@example.net\n",
      "Run 2: mosleyashley@example.net\n"
     ]
    }
   ],
   "source": [
    "# Without seed - different each time\n",
    "fake1 = Faker()\n",
    "print(\"Without seed:\")\n",
    "print(f\"Run 1: {fake1.email()}\")\n",
    "\n",
    "fake2 = Faker()\n",
    "print(f\"Run 2: {fake2.email()}\")\n",
    "\n",
    "# With seed - same every time\n",
    "print(\"\\nWith seed:\")\n",
    "Faker.seed(999)\n",
    "fake3 = Faker()\n",
    "print(f\"Run 1: {fake3.email()}\")\n",
    "\n",
    "Faker.seed(999)\n",
    "fake4 = Faker()\n",
    "print(f\"Run 2: {fake4.email()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Seeding Users\n",
    "\n",
    "## Basic User Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:18.300378Z",
     "iopub.status.busy": "2026-01-31T14:07:18.300378Z",
     "iopub.status.idle": "2026-01-31T14:07:20.429705Z",
     "shell.execute_reply": "2026-01-31T14:07:20.428691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated users:\n",
      "  - zoconnor@example.com... (API key: sk_3193ca54-ee89-411...)\n",
      "  - ashlee25@example.org... (API key: sk_8fe46024-42d6-4b5...)\n",
      "  - cheryllopez@example.net... (API key: sk_87f26aee-175f-4cd...)\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Import models\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find rag-engine-mini root by walking upwards\n",
    "current = Path.cwd().resolve()\n",
    "repo_root = None\n",
    "for parent in [current, *current.parents]:\n",
    "    if (parent / \"src\").exists() and (parent / \"notebooks\").exists():\n",
    "        repo_root = parent\n",
    "        break\n",
    "\n",
    "if repo_root is None:\n",
    "    raise RuntimeError(\"Could not locate rag-engine-mini root for imports\")\n",
    "\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from src.adapters.persistence.postgres.models import User\n",
    "\n",
    "# Generate users\n",
    "Faker.seed(12345)\n",
    "fake = Faker()\n",
    "\n",
    "users = []\n",
    "for i in range(5):\n",
    "    user = User(\n",
    "        id=str(uuid.uuid4()),\n",
    "        email=fake.email(),\n",
    "        api_key=f\"sk_{fake.uuid4()[:24]}\",  # API key format\n",
    "    )\n",
    "    users.append(user)\n",
    "\n",
    "print(\"Generated users:\")\n",
    "for user in users[:3]:\n",
    "    print(f\"  - {user.email[:30]}... (API key: {user.api_key[:20]}...)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.432383Z",
     "iopub.status.busy": "2026-01-31T14:07:20.432383Z",
     "iopub.status.idle": "2026-01-31T14:07:20.437118Z",
     "shell.execute_reply": "2026-01-31T14:07:20.436154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    # Insert users using bulk_save_objects (performance)\n",
    "    session.bulk_save_objects(users)\n",
    "    session.commit()\n",
    "\n",
    "    # Verify\n",
    "    user_count = session.query(User).count()\n",
    "    print(f\"Users in database: {user_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Seeding Documents\n",
    "\n",
    "## Document Seeding with Realistic Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.441122Z",
     "iopub.status.busy": "2026-01-31T14:07:20.440125Z",
     "iopub.status.idle": "2026-01-31T14:07:20.451854Z",
     "shell.execute_reply": "2026-01-31T14:07:20.450857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    from src.adapters.persistence.postgres.models import Document\n",
    "\n",
    "    # Get existing users\n",
    "    users = session.query(User).all()\n",
    "    print(f\"Found {len(users)} users\")\n",
    "\n",
    "    # Generate documents for each user\n",
    "    Faker.seed(12345)\n",
    "    fake = Faker()\n",
    "\n",
    "    # Content type mapping\n",
    "    CONTENT_TYPES = {\n",
    "        \"pdf\": \"application/pdf\",\n",
    "        \"docx\": \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n",
    "        \"txt\": \"text/plain\",\n",
    "        \"md\": \"text/markdown\",\n",
    "        \"csv\": \"text/csv\",\n",
    "    }\n",
    "\n",
    "    documents = []\n",
    "    for user in users:\n",
    "        for _ in range(3):  # 3 documents per user\n",
    "            filename = fake.file_name(category=\"document\")\n",
    "            extension = filename.split(\".\")[-1] if \".\" in filename else \"txt\"\n",
    "        \n",
    "            doc = Document(\n",
    "                id=str(uuid.uuid4()),\n",
    "                user_id=user.id,\n",
    "                filename=filename,\n",
    "                content_type=CONTENT_TYPES.get(extension, \"application/octet-stream\"),\n",
    "                file_path=f\"/uploads/{fake.uuid4()}/{filename}\",\n",
    "                size_bytes=fake.random_int(min=1000, max=1000000),\n",
    "                file_sha256=fake.sha256(raw_output=False),\n",
    "                status=fake.random_element(elements=(\"indexed\", \"indexed\", \"indexed\", \"failed\")),  # Mostly indexed\n",
    "            )\n",
    "            if doc.status == \"failed\":\n",
    "                doc.error = fake.sentence()\n",
    "        \n",
    "            documents.append(doc)\n",
    "\n",
    "    print(f\"Generated {len(documents)} documents\")\n",
    "    print(f\"\\nSample documents:\")\n",
    "    for doc in documents[:3]:\n",
    "        print(f\"  - {doc.filename} ({doc.status})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.455854Z",
     "iopub.status.busy": "2026-01-31T14:07:20.454856Z",
     "iopub.status.idle": "2026-01-31T14:07:20.464996Z",
     "shell.execute_reply": "2026-01-31T14:07:20.461982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    # Insert documents\n",
    "    session.bulk_save_objects(documents)\n",
    "    session.commit()\n",
    "\n",
    "    # Verify\n",
    "    doc_count = session.query(Document).count()\n",
    "    print(f\"Documents in database: {doc_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Seeding Chunks\n",
    "\n",
    "## Chunk Seeding with Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.468992Z",
     "iopub.status.busy": "2026-01-31T14:07:20.468055Z",
     "iopub.status.idle": "2026-01-31T14:07:20.481895Z",
     "shell.execute_reply": "2026-01-31T14:07:20.480899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    from src.adapters.persistence.postgres.models_chunk_store import (\n",
    "        ChunkStoreRow,\n",
    "        DocumentChunkRow,\n",
    "    )\n",
    "    import hashlib\n",
    "\n",
    "    # Get indexed documents (only these have chunks)\n",
    "    indexed_docs = session.query(Document).filter_by(status=\"indexed\").all()\n",
    "    print(f\"Found {len(indexed_docs)} indexed documents\")\n",
    "\n",
    "    Faker.seed(12345)\n",
    "    fake = Faker()\n",
    "\n",
    "    chunk_rows = []\n",
    "    document_chunk_rows = []\n",
    "\n",
    "    for doc in indexed_docs:\n",
    "        num_chunks = fake.random_int(min=3, max=8)\n",
    "    \n",
    "        for i in range(num_chunks):\n",
    "            chunk_text = fake.paragraph(nb_sentences=5)\n",
    "        \n",
    "            # Create unique hash for deduplication\n",
    "            chunk_hash = hashlib.sha256(\n",
    "                f\"{doc.user_id}:{chunk_text}\".encode()\n",
    "            ).hexdigest()\n",
    "        \n",
    "            chunk = ChunkStoreRow(\n",
    "                id=str(uuid.uuid4()),\n",
    "                user_id=doc.user_id,\n",
    "                chunk_hash=chunk_hash,\n",
    "                text=chunk_text,\n",
    "                parent_id=None,  # Hierarchical chunks not used in seed\n",
    "                chunk_context=None,\n",
    "            )\n",
    "            chunk_rows.append(chunk)\n",
    "        \n",
    "            # Create mapping\n",
    "            mapping = DocumentChunkRow(\n",
    "                document_id=doc.id,\n",
    "                ord=i,  # Order of chunk in document\n",
    "                chunk_id=chunk.id,\n",
    "            )\n",
    "            document_chunk_rows.append(mapping)\n",
    "\n",
    "    print(f\"Generated {len(chunk_rows)} chunks\")\n",
    "    print(f\"Generated {len(document_chunk_rows)} mappings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.484896Z",
     "iopub.status.busy": "2026-01-31T14:07:20.484896Z",
     "iopub.status.idle": "2026-01-31T14:07:20.495347Z",
     "shell.execute_reply": "2026-01-31T14:07:20.494336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    # Insert chunks\n",
    "    session.bulk_save_objects(chunk_rows)\n",
    "    session.bulk_save_objects(document_chunk_rows)\n",
    "    session.commit()\n",
    "\n",
    "    # Verify\n",
    "    chunk_count = session.query(ChunkStoreRow).count()\n",
    "    mapping_count = session.query(DocumentChunkRow).count()\n",
    "    print(f\"Chunks in database: {chunk_count}\")\n",
    "    print(f\"Mappings in database: {mapping_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Seeding Chat Data\n",
    "\n",
    "## Chat Sessions and Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.499347Z",
     "iopub.status.busy": "2026-01-31T14:07:20.498346Z",
     "iopub.status.idle": "2026-01-31T14:07:20.514222Z",
     "shell.execute_reply": "2026-01-31T14:07:20.512210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    from src.adapters.persistence.postgres.models_chat import (\n",
    "        ChatSessionRow,\n",
    "        ChatTurnRow,\n",
    "    )\n",
    "\n",
    "    # Get users\n",
    "    users = session.query(User).all()\n",
    "\n",
    "    Faker.seed(12345)\n",
    "    fake = Faker()\n",
    "\n",
    "    sessions = []\n",
    "    turns = []\n",
    "\n",
    "    for user in users:\n",
    "        for _ in range(2):  # 2 sessions per user\n",
    "            session_row = ChatSessionRow(\n",
    "                id=str(uuid.uuid4()),\n",
    "                user_id=user.id,\n",
    "                title=fake.sentence()[:50],\n",
    "            )\n",
    "            sessions.append(session_row)\n",
    "        \n",
    "            for _ in range(2):  # 2 turns per session\n",
    "                turn = ChatTurnRow(\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    session_id=session_row.id,\n",
    "                    user_id=user.id,\n",
    "                    question=fake.sentence(),\n",
    "                    answer=fake.paragraph(nb_sentences=3),\n",
    "                    sources=[str(uuid.uuid4()) for _ in range(fake.random_int(1, 3))],\n",
    "                    retrieval_k=fake.random_int(3, 10),\n",
    "                    embed_ms=fake.random_int(min=50, max=200),\n",
    "                    search_ms=fake.random_int(min=10, max=100),\n",
    "                    llm_ms=fake.random_int(min=500, max=2000),\n",
    "                    prompt_tokens=fake.random_int(min=100, max=500),\n",
    "                    completion_tokens=fake.random_int(min=50, max=300),\n",
    "                )\n",
    "                turns.append(turn)\n",
    "\n",
    "    print(f\"Generated {len(sessions)} chat sessions\")\n",
    "    print(f\"Generated {len(turns)} chat turns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.518220Z",
     "iopub.status.busy": "2026-01-31T14:07:20.518220Z",
     "iopub.status.idle": "2026-01-31T14:07:20.536566Z",
     "shell.execute_reply": "2026-01-31T14:07:20.535569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    # Insert chat data\n",
    "    session.bulk_save_objects(sessions)\n",
    "    session.bulk_save_objects(turns)\n",
    "    session.commit()\n",
    "\n",
    "    # Verify\n",
    "    session_count = session.query(ChatSessionRow).count()\n",
    "    turn_count = session.query(ChatTurnRow).count()\n",
    "    print(f\"Chat sessions in database: {session_count}\")\n",
    "    print(f\"Chat turns in database: {turn_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Idempotent Seeding\n",
    "\n",
    "## Making Seeding Safe to Run Multiple Times\n",
    "\n",
    "Idempotent seeding means running the script multiple times doesn't create duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.541499Z",
     "iopub.status.busy": "2026-01-31T14:07:20.540496Z",
     "iopub.status.idle": "2026-01-31T14:07:20.549496Z",
     "shell.execute_reply": "2026-01-31T14:07:20.548494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    def seed_idempotently(session, count: int):\n",
    "        \"\"\"Seed users only if database is empty.\"\"\"\n",
    "        existing_count = session.query(User).count()\n",
    "    \n",
    "        if existing_count == 0:\n",
    "            print(\"Database empty - seeding...\")\n",
    "            # ... seeding logic ...\n",
    "        elif existing_count < count:\n",
    "            print(f\"Partial data found ({existing_count}/{count} users) - seeding remaining...\")\n",
    "            # ... seeding only remaining ...\n",
    "        else:\n",
    "            print(f\"Data already seeded ({existing_count} users) - skipping.\")\n",
    "\n",
    "    # Example usage\n",
    "    seed_idempotently(session, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8: Performance Optimization\n",
    "\n",
    "## Bulk Operations vs Individual Inserts\n",
    "\n",
    "Bulk operations are significantly faster than individual inserts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.553495Z",
     "iopub.status.busy": "2026-01-31T14:07:20.552495Z",
     "iopub.status.idle": "2026-01-31T14:07:20.566024Z",
     "shell.execute_reply": "2026-01-31T14:07:20.565202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??  Skipping this section because the database is not available.\n"
     ]
    }
   ],
   "source": [
    "if not DB_AVAILABLE:\n",
    "    print(\"??  Skipping this section because the database is not available.\")\n",
    "else:\n",
    "    import time\n",
    "\n",
    "    # Method 1: Individual inserts (SLOW)\n",
    "    def seed_individual(session, count: int):\n",
    "        \"\"\"Seed using individual adds.\"\"\"\n",
    "        start = time.time()\n",
    "    \n",
    "        for _ in range(count):\n",
    "            user = User(\n",
    "                id=str(uuid.uuid4()),\n",
    "                email=fake.email(),\n",
    "                api_key=f\"sk_{fake.uuid4()[:24]}\",\n",
    "            )\n",
    "            session.add(user)\n",
    "    \n",
    "        session.commit()\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"Individual inserts: {elapsed:.2f}s for {count} records\")\n",
    "\n",
    "    # Method 2: Bulk save_objects (FAST)\n",
    "    def seed_bulk(session, count: int):\n",
    "        \"\"\"Seed using bulk_save_objects.\"\"\"\n",
    "        start = time.time()\n",
    "    \n",
    "        users = []\n",
    "        for _ in range(count):\n",
    "            user = User(\n",
    "                id=str(uuid.uuid4()),\n",
    "                email=fake.email(),\n",
    "                api_key=f\"sk_{fake.uuid4()[:24]}\",\n",
    "            )\n",
    "            users.append(user)\n",
    "    \n",
    "        session.bulk_save_objects(users)\n",
    "        session.commit()\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"Bulk save_objects:  {elapsed:.2f}s for {count} records\")\n",
    "\n",
    "    # Note: Running with real data to see the performance difference\n",
    "    # seed_individual(session, 100)  # Uncomment to test\n",
    "    # seed_bulk(session, 100)         # Uncomment to test\n",
    "\n",
    "    print(\"Tip: Bulk operations can be 10-100x faster!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9: Environment-Aware Seeding\n",
    "\n",
    "## Different Seeds for Different Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T14:07:20.570045Z",
     "iopub.status.busy": "2026-01-31T14:07:20.569035Z",
     "iopub.status.idle": "2026-01-31T14:07:20.581034Z",
     "shell.execute_reply": "2026-01-31T14:07:20.580034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: development\n",
      "Config: {'num_users': 50, 'num_docs_per_user': 20, 'num_sessions': 10}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ENVIRONMENTS = {\n",
    "    \"development\": {\n",
    "        \"num_users\": 50,\n",
    "        \"num_docs_per_user\": 20,\n",
    "        \"num_sessions\": 10,\n",
    "    },\n",
    "    \"testing\": {\n",
    "        \"num_users\": 3,\n",
    "        \"num_docs_per_user\": 5,\n",
    "        \"num_sessions\": 2,\n",
    "    },\n",
    "    \"staging\": {\n",
    "        \"num_users\": 20,\n",
    "        \"num_docs_per_user\": 10,\n",
    "        \"num_sessions\": 5,\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_seed_config(env: str) -> dict:\n",
    "    \"\"\"Get seed configuration for environment.\"\"\"\n",
    "    if env == \"production\":\n",
    "        raise ValueError(\"Cannot seed production database!\")\n",
    "    \n",
    "    return ENVIRONMENTS.get(env, ENVIRONMENTS[\"development\"])\n",
    "\n",
    "# Example\n",
    "env = os.getenv(\"ENVIRONMENT\", \"development\")\n",
    "config = get_seed_config(env)\n",
    "print(f\"Environment: {env}\")\n",
    "print(f\"Config: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 10: Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Seeding accelerates development** by providing instant test data\n",
    "2. **Use Faker for realistic data** that mirrors production patterns\n",
    "3. **Keep seeds idempotent** to support multiple runs\n",
    "4. **Bulk inserts improve performance** for large datasets\n",
    "5. **Environment-aware seeding** prevents production accidents\n",
    "\n",
    "## Running the Seed Script\n",
    "\n",
    "```bash\n",
    "# Seed development database\n",
    "python scripts/seed_sample_data.py\n",
    "\n",
    "# Seed with custom config\n",
    "python scripts/seed_sample_data.py --num-users 20 --num-docs 200\n",
    "\n",
    "# Reset and reseed\n",
    "python scripts/seed_sample_data.py --reset\n",
    "```\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Run `scripts/seed_sample_data.py` to seed your database\n",
    "- Test the API with seeded data\n",
    "- Create custom seed data for your specific use case\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Faker Documentation](https://faker.readthedocs.io/)\n",
    "- [Factory Boy](https://factoryboy.readthedocs.io/)\n",
    "- [SQLAlchemy Bulk Operations](https://docs.sqlalchemy.org/en/14/orm/persistence_techniques.html#bulk-operations)\n",
    "- `docs/learning/database/01-seeding-strategies.md` - Complete guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
