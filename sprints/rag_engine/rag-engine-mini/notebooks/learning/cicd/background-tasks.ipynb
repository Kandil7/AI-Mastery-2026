{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Tasks with Celery - Interactive Learning\n",
    "# مهام الخلفية مع Celery - تعلم تفاعلي\n",
    "\n",
    "This notebook covers:\n",
    "- Understanding background tasks\n",
    "- Celery architecture\n",
    "- Implementing Celery tasks\n",
    "- Task patterns and best practices\n",
    "\n",
    "يغطي هذا المفكرة:\n",
    "- فهم مهام الخلفية\n",
    "- معمارية Celery\n",
    "- تنفيذ مهام Celery\n",
    "- أنماط المهام وأفضل الممارسات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Background Tasks\n",
    "## الجزء 1: فهم مهام الخلفية\n",
    "\n",
    "### What are background tasks?\n",
    "### ما هي مهام الخلفية؟\n",
    "\n",
    "Background tasks allow you to execute operations asynchronously, outside the request-response cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronous processing (blocks the request)\n",
    "def process_document_sync(document):\n",
    "    print(\"1. Extracting text...\")\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "    print(\"2. Generating embeddings...\")\n",
    "    time.sleep(3)\n",
    "    print(\"3. Saving to vector store...\")\n",
    "    time.sleep(1)\n",
    "    return \"Done\"\n",
    "\n",
    "print(\"Synchronous processing:\")\n",
    "process_document_sync(\"doc.pdf\")\n",
    "print(\"Total time: ~6 seconds (blocks everything)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Convert to Async\n",
    "### تمرين 1: تحويل إلى غير متزامن\n",
    "\n",
    "Convert the synchronous function above to use async processing (simulate with threading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "# TODO: Create an async version using threading\n",
    "def process_document_async(document):\n",
    "    \"\"\"\n",
    "    TODO: Implement async processing using threading\n",
    "    Queue the task and return immediately\n",
    "    \"\"\"\n",
    "    pass  # Your code here\n",
    "\n",
    "print(\"Synchronous processing:\")\n",
    "print(process_document_sync(\"doc.pdf\"))\n",
    "\n",
    "print(\"\\nAsynchronous processing:\")\n",
    "print(process_document_async(\"doc.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution / الحل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "task_queue = queue.Queue()\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        document = task_queue.get()\n",
    "        if document == \"STOP\":\n",
    "            break\n",
    "        result = process_document_sync(document)\n",
    "        print(f\"\\nCompleted: {document}\")\n",
    "        task_queue.task_done()\n",
    "\n",
    "# Start worker thread\n",
    "worker_thread = threading.Thread(target=worker, daemon=True)\n",
    "worker_thread.start()\n",
    "\n",
    "def process_document_async(document):\n",
    "    task_queue.put(document)\n",
    "    return {\"status\": \"queued\", \"document\": document}\n",
    "\n",
    "print(\"Asynchronous processing:\")\n",
    "print(process_document_async(\"doc1.pdf\"))\n",
    "print(process_document_async(\"doc2.pdf\"))\n",
    "print(\"\\nReturns immediately! Tasks running in background...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Celery Architecture\n",
    "## الجزء 2: معمارية Celery\n",
    "\n",
    "Celery consists of three main components:\n",
    "- **Broker**: Stores task messages (Redis, RabbitMQ)\n",
    "- **Worker**: Processes tasks\n",
    "- **Backend**: Stores task results (optional)\n",
    "\n",
    "يتكون Celery من ثلاثة مكونات رئيسية:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Celery Architecture\n",
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(comment='Celery Architecture')\n",
    "dot.node('A', 'FastAPI\\n(Request)')\n",
    "dot.node('B', 'Celery Broker\\n(Redis)')\n",
    "dot.node('C', 'Celery Worker\\n(Processing)')\n",
    "dot.node('D', 'Backend\\n(Results)')\n",
    "\n",
    "dot.edge('A', 'B', label='delay()')\n",
    "dot.edge('B', 'C', label='pull()')\n",
    "dot.edge('C', 'D', label='store()')\n",
    "dot.edge('D', 'A', label='get_result()', style='dashed')\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Defining Celery Tasks\n",
    "## الجزء 3: تعريف مهام Celery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic task definition\n",
    "from celery import Celery\n",
    "\n",
    "app = Celery('tasks', broker='redis://localhost:6379/0')\n",
    "\n",
    "@app.task(name='index_document')\n",
    "def index_document(document_id):\n",
    "    \"\"\"Index a document in the background.\"\"\"\n",
    "    print(f\"Indexing document: {document_id}\")\n",
    "    # Simulate work\n",
    "    import time\n",
    "    time.sleep(2)\n",
    "    return {\"document_id\": document_id, \"status\": \"indexed\"}\n",
    "\n",
    "# Task with retry configuration\n",
    "@app.task(\n",
    "    name='process_with_retry',\n",
    "    autoretry_for=(ConnectionError, TimeoutError),\n",
    "    retry_backoff=True,\n",
    "    retry_kwargs={'max_retries': 3}\n",
    ")\n",
    "def process_with_retry(document_id):\n",
    "    \"\"\"Task that retries on failure.\"\"\"\n",
    "    print(f\"Processing: {document_id}\")\n",
    "    # Simulate potential failure\n",
    "    import random\n",
    "    if random.random() < 0.3:\n",
    "        raise ConnectionError(\"Network issue\")\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "# Task with timeout\n",
    "@app.task(name='timeout_task', time_limit=30)\n",
    "def timeout_task(data):\n",
    "    \"\"\"Task with time limit.\"\"\"\n",
    "    import time\n",
    "    time.sleep(10)\n",
    "    return {\"status\": \"done\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create a Task with Monitoring\n",
    "### تمرين 2: إنشاء مهمة مع المراقبة\n",
    "\n",
    "Create a task that:\n",
    "- Accepts a list of items\n",
    "- Processes each item\n",
    "- Updates progress using `update_state()`\n",
    "- Returns results\n",
    "\n",
    "أنشئ مهمة:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.task(bind=True, name='process_with_progress')\n",
    "def process_with_progress(self, items):\n",
    "    \"\"\"\n",
    "    TODO: Implement a task with progress updates\n",
    "    - Process each item in the list\n",
    "    - Update progress with self.update_state()\n",
    "    - Return results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(items)\n",
    "    \n",
    "    # TODO: Process items with progress updates\n",
    "    # for i, item in enumerate(items):\n",
    "    #     result = process(item)\n",
    "    #     self.update_state(\n",
    "    #         state='PROGRESS',\n",
    "    #         meta={'current': i+1, 'total': total, 'percent': ((i+1)/total)*100}\n",
    "    #     )\n",
    "    \n",
    "    return {\"status\": \"completed\", \"results\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Task Patterns\n",
    "## الجزء 4: أنماط المهام"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Chaining tasks (sequential execution)\n",
    "from celery import chain\n",
    "\n",
    "workflow = chain(\n",
    "    index_document.s('doc1'),\n",
    "    index_document.s('doc2'),\n",
    "    index_document.s('doc3')\n",
    ")\n",
    "\n",
    "# workflow.apply_async()\n",
    "\n",
    "# Pattern 2: Grouping tasks (parallel execution)\n",
    "from celery import group\n",
    "\n",
    "parallel_tasks = group(\n",
    "    index_document.s('doc1'),\n",
    "    index_document.s('doc2'),\n",
    "    index_document.s('doc3')\n",
    ")\n",
    "\n",
    "# parallel_tasks.apply_async()\n",
    "\n",
    "# Pattern 3: Chord (group + callback)\n",
    "from celery import chord\n",
    "\n",
    "def summarize_results(results):\n",
    "    return {\"total\": len(results), \"status\": \"summarized\"}\n",
    "\n",
    "workflow = chord(\n",
    "    (index_document.s(f'doc{i}') for i in range(10)),\n",
    "    summarize_results.s()\n",
    ")\n",
    "\n",
    "# workflow.apply_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Design a Workflow\n",
    "### تمرين 3: تصميم سير عمل\n",
    "\n",
    "Design a workflow that:\n",
    "1. Processes 5 documents in parallel\n",
    "2. After all complete, generates a summary\n",
    "\n",
    "صمم سير عمل:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a workflow with chord\n",
    "# def summarize_batch(results):\n",
    "#     return {\"processed\": len(results), \"status\": \"complete\"}\n",
    "# \n",
    "# batch_workflow = chord(\n",
    "#     # TODO: Add tasks\n",
    "#     summarize_batch.s()\n",
    "# )\n",
    "# \n",
    "# batch_workflow.apply_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implementing RAG Engine Tasks\n",
    "## الجزء 5: تنفيذ مهام محرك RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating the bulk upload task from tasks.py\n",
    "class BulkUploadResult:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.success = 0\n",
    "        self.failure = 0\n",
    "\n",
    "def simulate_bulk_upload(files):\n",
    "    \"\"\"Simulate bulk upload processing.\"\"\"\n",
    "    result = BulkUploadResult()\n",
    "    \n",
    "    for file_info in files:\n",
    "        try:\n",
    "            # Simulate file upload\n",
    "            print(f\"  Uploading: {file_info['filename']}\")\n",
    "            \n",
    "            # Simulate indexing task\n",
    "            print(f\"    Queued indexing for: {file_info['filename']}\")\n",
    "            \n",
    "            result.results.append({\n",
    "                \"filename\": file_info['filename'],\n",
    "                \"status\": \"queued\"\n",
    "            })\n",
    "            result.success += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            result.results.append({\n",
    "                \"filename\": file_info.get('filename', 'unknown'),\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            result.failure += 1\n",
    "    \n",
    "    return {\n",
    "        \"total\": len(files),\n",
    "        \"success\": result.success,\n",
    "        \"failures\": result.failure,\n",
    "        \"results\": result.results\n",
    "    }\n",
    "\n",
    "# Test bulk upload\n",
    "files = [\n",
    "    {\"filename\": \"doc1.pdf\", \"content_type\": \"application/pdf\"},\n",
    "    {\"filename\": \"doc2.pdf\", \"content_type\": \"application/pdf\"},\n",
    "    {\"filename\": \"doc3.pdf\", \"content_type\": \"application/pdf\"},\n",
    "]\n",
    "\n",
    "print(\"Bulk Upload Simulation:\")\n",
    "result = simulate_bulk_upload(files)\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating PDF merge task\n",
    "import io\n",
    "\n",
    "class MockPDFWriter:\n",
    "    def __init__(self):\n",
    "        self.pages = []\n",
    "    \n",
    "    def add_page(self, page):\n",
    "        self.pages.append(page)\n",
    "    \n",
    "    def write(self, output):\n",
    "        output.write(b'MERGED_PDF:' + b','.join(self.pages))\n",
    "\n",
    "class MockPDFReader:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.pages = [f\"page_{i+1}\".encode() for i in range(3)]\n",
    "\n",
    "def simulate_pdf_merge(source_docs, merged_filename):\n",
    "    \"\"\"Simulate PDF merging.\"\"\"\n",
    "    print(f\"\\nMerging {len(source_docs)} PDFs...\")\n",
    "    \n",
    "    # Step 1: Read source PDFs\n",
    "    source_readers = [MockPDFReader(d) for d in source_docs]\n",
    "    \n",
    "    # Step 2: Merge pages\n",
    "    merged_writer = MockPDFWriter()\n",
    "    for reader in source_readers:\n",
    "        for page in reader.pages:\n",
    "            merged_writer.add_page(page)\n",
    "            print(f\"  Added page from {reader.filename}\")\n",
    "    \n",
    "    # Step 3: Write merged PDF\n",
    "    merged_bytes = io.BytesIO()\n",
    "    merged_writer.write(merged_bytes)\n",
    "    content = merged_bytes.getvalue()\n",
    "    \n",
    "    print(f\"\\nCreated merged PDF: {merged_filename}\")\n",
    "    print(f\"Total pages: {len(merged_writer.pages)}\")\n",
    "    print(f\"Size: {len(content)} bytes\")\n",
    "    \n",
    "    return {\n",
    "        \"merged_document_id\": \"new-doc-123\",\n",
    "        \"source_count\": len(source_docs),\n",
    "        \"filename\": merged_filename,\n",
    "        \"size_bytes\": len(content)\n",
    "    }\n",
    "\n",
    "# Test PDF merge\n",
    "result = simulate_pdf_merge([\"doc1.pdf\", \"doc2.pdf\"], \"merged.pdf\")\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Best Practices Quiz\n",
    "## الجزء 6: اختبار أفضل الممارسات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Questions / أسئلة الاختبار\n",
    "\n",
    "**Q1:** Why should you use keyword arguments in Celery tasks?\n",
    "a) They're faster\n",
    "b) Order-independent, less error-prone\n",
    "c) Required by Celery\n",
    "d) Better for type hints\n",
    "\n",
    "**Q2:** What's the purpose of `bind=True` in a task definition?\n",
    "a) Bind to specific worker\n",
    "b) Access task instance for retry and progress\n",
    "c) Bind to specific queue\n",
    "d) Enable task chaining\n",
    "\n",
    "**Q3:** When should you use exponential backoff for retries?\n",
    "a) Always\n",
    "b) Never\n",
    "c) For transient failures (network, timeouts)\n",
    "d) Only for database errors\n",
    "\n",
    "### أسئلة الاختبار\n",
    "\n",
    "**س1:** لماذا يجب استخدام الحجج المسمية في مهام Celery؟\n",
    "أ) أسرع\n",
    "ب) مستقلة عن الترتيب، أقل عرضة للأخطاء\n",
    "ج) مطلوبة من Celery\n",
    "د) أفضل لتلميحات النوع"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer check\n",
    "quiz_answers = {\n",
    "    \"Q1\": \"b\",\n",
    "    \"Q2\": \"b\",\n",
    "    \"Q3\": \"c\"\n",
    "}\n",
    "\n",
    "for q, answer in quiz_answers.items():\n",
    "    print(f\"{q}: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Monitoring with Prometheus\n",
    "## الجزء 7: المراقبة مع Prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated metrics collection\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class TaskMetrics:\n",
    "    def __init__(self):\n",
    "        self.count = defaultdict(lambda: defaultdict(int))\n",
    "        self.duration = defaultdict(list)\n",
    "    \n",
    "    def record(self, task_name, status, duration_ms):\n",
    "        self.count[task_name][status] += 1\n",
    "        self.duration[task_name].append(duration_ms)\n",
    "    \n",
    "    def get_summary(self):\n",
    "        summary = {}\n",
    "        for task in self.count:\n",
    "            total = sum(self.count[task].values())\n",
    "            success = self.count[task].get(\"success\", 0)\n",
    "            failure = self.count[task].get(\"failure\", 0)\n",
    "            durations = self.duration[task]\n",
    "            avg_duration = sum(durations) / len(durations) if durations else 0\n",
    "            \n",
    "            summary[task] = {\n",
    "                \"total\": total,\n",
    "                \"success\": success,\n",
    "                \"failure\": failure,\n",
    "                \"success_rate\": success / total if total > 0 else 0,\n",
    "                \"avg_duration_ms\": round(avg_duration, 2)\n",
    "            }\n",
    "        return summary\n",
    "\n",
    "# Simulate task execution with metrics\n",
    "metrics = TaskMetrics()\n",
    "\n",
    "def execute_task_with_metrics(task_name, func):\n",
    "    \"\"\"Execute task and record metrics.\"\"\"\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = func()\n",
    "        duration = (time.time() - start) * 1000\n",
    "        metrics.record(task_name, \"success\", duration)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        duration = (time.time() - start) * 1000\n",
    "        metrics.record(task_name, \"failure\", duration)\n",
    "        raise\n",
    "\n",
    "# Simulate tasks\n",
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        execute_task_with_metrics(\"index_document\", lambda: (\n",
    "            time.sleep(0.1),\n",
    "            None if random.random() < 0.1 else Exception(\"Failed\")\n",
    "        )[0])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"Task Metrics Summary:\")\n",
    "import json\n",
    "print(json.dumps(metrics.get_summary(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary / الملخص\n",
    "\n",
    "**Key concepts covered / المفاهيم الرئيسية المشمولة:**\n",
    "\n",
    "1. **Background tasks** allow non-blocking operations\n",
    "2. **Celery architecture**: Broker → Worker → Backend\n",
    "3. **Task patterns**: Chaining, grouping, chords\n",
    "4. **RAG Engine tasks**: Bulk upload, PDF merge, chat enhancements\n",
    "5. **Best practices**: Keyword arguments, retry strategies, monitoring\n",
    "\n",
    "**النقاط الرئيسية المشمولة:**\n",
    "\n",
    "1. **مهمة الخلفية** تسمح بالعمليات غير الحظر\n",
    "2. **معمارية Celery**: الوسيط → العامل → الخلفية\n",
    "3. **أنماط المهام**: الربط، التجميع، الأوتار\n",
    "4. **مهام محرك RAG**: الرفع بالجملة، دمج PDF، تحسينات المحادثة\n",
    "5. **أفضل الممارسات**: الحجج المسمية، استراتيجيات إعادة المحاولة، المراقبة"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
