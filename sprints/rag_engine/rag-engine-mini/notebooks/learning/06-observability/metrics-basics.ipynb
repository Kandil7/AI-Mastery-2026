{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics & Observability - Interactive Tutorial\n",
    "# ==========================================\n",
    "In this notebook, you'll learn about metrics and observability.\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By the end of you will:\n",
    "- Understand Prometheus metrics\n",
    "- Implement counters, histograms, gauges\n",
    "- Learn about OpenTelemetry tracing\n",
    "- Track request latency\n",
    "- Monitor error rates\n",
    "\n",
    "## ðŸ”§ Prerequisites\n",
    "\n",
    "Ensure you have installed:\n",
    "- prometheus-client\n",
    "- opentelemetry-api\n",
    "- python 3.11+\n",
    "\n",
    "## ðŸ“¦ Setup\n",
    "\n",
    "Let's start by importing necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:07:44.370543Z",
     "iopub.status.busy": "2026-01-31T13:07:44.370543Z",
     "iopub.status.idle": "2026-01-31T13:07:44.468263Z",
     "shell.execute_reply": "2026-01-31T13:07:44.459267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "   - Prometheus client: prometheus_client.metrics\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from prometheus_client import Counter, Histogram, Gauge, start_http_server, exposition\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Print setup confirmation\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"   - Prometheus client: {Counter.__module__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prometheus Metrics\n",
    "\n",
    "### 1.1 Counters\n",
    "\n",
    "Counters track cumulative values (e.g., total requests).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:07:44.473262Z",
     "iopub.status.busy": "2026-01-31T13:07:44.472263Z",
     "iopub.status.idle": "2026-01-31T13:07:44.483714Z",
     "shell.execute_reply": "2026-01-31T13:07:44.482712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Counters defined!\n",
      "   - api_requests_total: counter:api_requests\n",
      "   - api_errors_total: counter:api_errors\n"
     ]
    }
   ],
   "source": [
    "# Define counters\n",
    "REQUEST_COUNT = Counter(\n",
    "    'api_requests_total',\n",
    "    'API Total Requests',\n",
    "    ['endpoint', 'method', 'status']\n",
    ")\n",
    "\n",
    "ERROR_COUNT = Counter(\n",
    "    'api_errors_total',\n",
    "    'API Total Errors',\n",
    "    ['error_type']\n",
    ")\n",
    "\n",
    "# Increment counters\n",
    "REQUEST_COUNT.labels(endpoint='graphql', method='POST', status='200').inc()\n",
    "ERROR_COUNT.labels(error_type='validation').inc()\n",
    "\n",
    "print(\"âœ… Counters defined!\")\n",
    "print(f\"   - api_requests_total: {REQUEST_COUNT}\")\n",
    "print(f\"   - api_errors_total: {ERROR_COUNT}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Histograms\n",
    "\n",
    "Histograms track distributions of values (e.g., request latency).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:07:44.486743Z",
     "iopub.status.busy": "2026-01-31T13:07:44.485719Z",
     "iopub.status.idle": "2026-01-31T13:07:44.593571Z",
     "shell.execute_reply": "2026-01-31T13:07:44.592117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Latency observed: 0.101s\n"
     ]
    }
   ],
   "source": [
    "# Define histogram\n",
    "REQUEST_LATENCY = Histogram(\n",
    "    'api_request_duration_seconds',\n",
    "    'API Request Duration',\n",
    "    buckets=[0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0],\n",
    ")\n",
    "\n",
    "# Observe latency\n",
    "start = time.time()\n",
    "time.sleep(0.1)\n",
    "latency = time.time() - start\n",
    "REQUEST_LATENCY.observe(latency)\n",
    "\n",
    "print(f\"âœ… Latency observed: {latency:.3f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Gauges\n",
    "\n",
    "Gauges track current values (e.g., active connections, queue size).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:07:44.596410Z",
     "iopub.status.busy": "2026-01-31T13:07:44.596410Z",
     "iopub.status.idle": "2026-01-31T13:07:44.601172Z",
     "shell.execute_reply": "2026-01-31T13:07:44.601172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gauges defined and set!\n",
      "   - webhooks_active: gauge:webhooks_active\n",
      "   - cache_hit_rate: gauge:cache_hit_rate\n"
     ]
    }
   ],
   "source": [
    "# Define gauges\n",
    "ACTIVE_WEBHOOKS = Gauge(\n",
    "    'webhooks_active',\n",
    "    'Active Webhooks',\n",
    ")\n",
    "\n",
    "CACHE_HIT_RATE = Gauge(\n",
    "    'cache_hit_rate',\n",
    "    'Cache Hit Rate',\n",
    ")\n",
    "\n",
    "# Set gauge values\n",
    "ACTIVE_WEBHOOKS.set(5)\n",
    "CACHE_HIT_RATE.set(0.75)\n",
    "\n",
    "print(\"âœ… Gauges defined and set!\")\n",
    "print(f\"   - webhooks_active: {ACTIVE_WEBHOOKS}\")\n",
    "print(f\"   - cache_hit_rate: {CACHE_HIT_RATE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exposing Metrics\n",
    "\n",
    "### 2.1 Metrics Endpoint\n",
    "\n",
    "Prometheus provides a /metrics endpoint for scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:07:44.604931Z",
     "iopub.status.busy": "2026-01-31T13:07:44.604773Z",
     "iopub.status.idle": "2026-01-31T13:07:45.046742Z",
     "shell.execute_reply": "2026-01-31T13:07:45.045675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metrics endpoint mounted at /metrics\n",
      "   Access at: http://localhost:8000/metrics\n"
     ]
    }
   ],
   "source": [
    "from prometheus_client import make_asgi_app\n",
    "from fastapi import FastAPI\n",
    "\n",
    "# Create sample app\n",
    "app = FastAPI()\n",
    "\n",
    "# Create metrics app\n",
    "metrics_app = make_asgi_app()\n",
    "\n",
    "# Mount metrics endpoint\n",
    "app.mount(\"/metrics\", metrics_app)\n",
    "\n",
    "print(\"âœ… Metrics endpoint mounted at /metrics\")\n",
    "print(f\"   Access at: http://localhost:8000/metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practice Exercise\n",
    "\n",
    "### Task: Create custom metrics\n",
    "\n",
    "Create metrics for:\n",
    "1. Document retrieval time\n",
    "2. Embedding cache hit rate\n",
    "3. LLM token usage\n",
    "4. Reranking latency\n",
    "5. Webhook delivery success rate\n",
    "\n",
    "Implement these metrics below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:07:45.049271Z",
     "iopub.status.busy": "2026-01-31T13:07:45.049271Z",
     "iopub.status.idle": "2026-01-31T13:07:45.055927Z",
     "shell.execute_reply": "2026-01-31T13:07:45.055927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? Custom metrics defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Implemented: custom metrics\n",
    "\n",
    "# Custom metrics for RAG system\n",
    "RETRIEVAL_TIME = Histogram(\n",
    "    \"document_retrieval_seconds\",\n",
    "    \"Document retrieval latency in seconds\",\n",
    "    buckets=[0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0],\n",
    ")\n",
    "\n",
    "EMBEDDING_CACHE_HIT_RATE = Gauge(\n",
    "    \"embedding_cache_hit_rate\",\n",
    "    \"Embedding cache hit rate (0-1)\",\n",
    ")\n",
    "\n",
    "LLM_TOKEN_USAGE = Counter(\n",
    "    \"llm_tokens_total\",\n",
    "    \"Total LLM tokens consumed\",\n",
    "    [\"model\", \"type\"],\n",
    ")\n",
    "\n",
    "RERANK_LATENCY = Histogram(\n",
    "    \"rerank_latency_seconds\",\n",
    "    \"Reranking latency in seconds\",\n",
    "    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],\n",
    ")\n",
    "\n",
    "WEBHOOK_DELIVERY_TOTAL = Counter(\n",
    "    \"webhook_delivery_total\",\n",
    "    \"Webhook delivery attempts\",\n",
    "    [\"status\"],\n",
    ")\n",
    "\n",
    "# Example observations\n",
    "RETRIEVAL_TIME.observe(0.12)\n",
    "EMBEDDING_CACHE_HIT_RATE.set(0.82)\n",
    "LLM_TOKEN_USAGE.labels(model=\"gpt-4.1\", type=\"prompt\").inc(512)\n",
    "LLM_TOKEN_USAGE.labels(model=\"gpt-4.1\", type=\"completion\").inc(128)\n",
    "RERANK_LATENCY.observe(0.03)\n",
    "WEBHOOK_DELIVERY_TOTAL.labels(status=\"success\").inc()\n",
    "\n",
    "print(\"? Custom metrics defined successfully!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Prometheus Metrics** - Counters, histograms, gauges\n",
    "2. **Metric Types** - Counters (cumulative), Histograms (distribution), Gauges (current)\n",
    "3. **Metrics Endpoint** - /metrics for Prometheus scraping\n",
    "4. **Labeling** - Use labels for filtering (endpoint, method, status)\n",
    "5. **Best Practices** - Track latency, errors, resource usage\n",
    "\n",
    "### ðŸŽ¯ Key Takeaways\n",
    "\n",
    "- Use counters for cumulative values (total requests)\n",
    "- Use histograms for distributions (latency, response times)\n",
    "- Use gauges for current values (active connections, queue size)\n",
    "- Add labels for multi-dimensional metrics\n",
    "- Expose /metrics endpoint for Prometheus\n",
    "- Track business metrics (retrieval time, cache hit rate)\n",
    "\n",
    "### ðŸš€ Next Steps\n",
    "\n",
    "1. Implement custom metrics in production\n",
    "2. Add Grafana dashboard configuration\n",
    "3. Set up alerting rules\n",
    "4. Monitor metrics in production\n",
    "\n",
    "### ðŸ“š Further Reading\n",
    "\n",
    "- [Prometheus Best Practices](https://prometheus.io/docs/practices/)\n",
    "- [OpenTelemetry](https://opentelemetry.io/)\n",
    "- [Metrics Types](https://prometheus.io/docs/concepts/metric_types/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
