{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending RAG Engine Mini: A Practical Guide\n",
    "\n",
    "This notebook demonstrates how to extend the RAG Engine Mini with a custom feature while maintaining educational quality and following architectural best practices.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand how to add a new feature following the existing architecture\n",
    "2. Know how to implement a custom adapter following the ports and adapters pattern\n",
    "3. Learn how to register your new component in the dependency injection container\n",
    "4. Practice proper testing of your extension\n",
    "5. Document your extension for educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = Path(\"../../../\")\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"Modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the Architecture\n",
    "\n",
    "Before extending the system, let's review the key architectural components we'll be working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the source structure\n",
    "src_path = project_root / \"src\"\n",
    "print(\"Source structure:\")\n",
    "for item in sorted(src_path.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  {item.name}/\")\n",
    "        sub_items = [sub_item.name for sub_item in item.iterdir() if sub_item.is_file()][:3]  # Show first 3 files\n",
    "        if sub_items:\n",
    "            print(f\"    {', '.join(sub_items)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining Our Custom Feature\n",
    "\n",
    "For this demonstration, we'll implement a **Query Intent Classifier** - a component that categorizes user queries to help route them to the most appropriate processing pipeline.\n",
    "\n",
    "Our classifier will identify if a query is asking for:\n",
    "- Factual information\n",
    "- Comparative analysis\n",
    "- Procedure/tutorials\n",
    "- Unknown intent\n",
    "\n",
    "This could help optimize the retrieval and generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's define our intent types\n",
    "from enum import Enum\n",
    "\n",
    "class QueryIntent(Enum):\n",
    "    FACTUAL = \"factual\"\n",
    "    COMPARATIVE = \"comparative\"\n",
    "    PROCEDURAL = \"procedural\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "# Define the port interface for our classifier\n",
    "from typing import Protocol\n",
    "\n",
    "class QueryIntentClassifierPort(Protocol):\n",
    "    async def classify_intent(self, query: str) -> QueryIntent:\n",
    "        \"\"\"Classify the intent of a given query.\"\"\"\n",
    "        ...\n",
    "        \n",
    "# Define a data structure for our classification result\n",
    "@dataclass\n",
    "class IntentClassificationResult:\n",
    "    query: str\n",
    "    intent: QueryIntent\n",
    "    confidence: float  # Confidence score between 0 and 1\n",
    "    explanation: str  # Brief explanation of the classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing the Adapter\n",
    "\n",
    "Now let's implement a simple classifier adapter that follows the ports and adapters pattern. For this example, we'll implement a rule-based classifier that can be easily understood and extended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a rule-based classifier\n",
    "import re\n",
    "import asyncio\n",
    "from typing import Tuple\n",
    "\n",
    "class RuleBasedQueryIntentClassifier:\n",
    "    def __init__(self, default_confidence: float = 0.7):\n",
    "        self.default_confidence = default_confidence\n",
    "        \n",
    "        # Define keywords for each intent type\n",
    "        self.intent_keywords = {\n",
    "            QueryIntent.FACTUAL: [\n",
    "                r'what is', r'what was', r'who is', r'who was', r'when', r'define', \n",
    "                r'meaning of', r'explain', r'tell me about', r'how much', r'how many',\n",
    "                r'give me information about', r'what does \\w+ mean'\n",
    "            ],\n",
    "            QueryIntent.COMPARATIVE: [\n",
    "                r'compare', r'vs', r'versus', r'difference between', r'similarities',\n",
    "                r'better than', r'advantages of', r'disadvantages of', r'contrast',\n",
    "                r'which is better', r'similar to', r'compared to'\n",
    "            ],\n",
    "            QueryIntent.PROCEDURAL: [\n",
    "                r'how to', r'steps to', r'procedure for', r'process of',\n",
    "                r'guide to', r'tutorial', r'instructions', r'make', r'build',\n",
    "                r'implement', r'do', r'create', r'perform', r'execute'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    async def classify_intent(self, query: str) -> IntentClassificationResult:\n",
    "        \"\"\"Classify the intent of a query using keyword matching and rules.\"\"\"\n",
    "        query_lower = query.lower().strip()\n",
    "        \n",
    "        # Check each intent type for keyword matches\n",
    "        for intent, keywords in self.intent_keywords.items():\n",
    "            for keyword_pattern in keywords:\n",
    "                if re.search(keyword_pattern, query_lower):\n",
    "                    explanation = f\"Matched keyword pattern: '{keyword_pattern}'\"\n",
    "                    return IntentClassificationResult(\n",
    "                        query=query,\n",
    "                        intent=intent,\n",
    "                        confidence=self.default_confidence,\n",
    "                        explanation=exploration\n",
    "                    )\n",
    "        \n",
    "        # If no specific intent matched, return unknown\n",
    "        return IntentClassificationResult(\n",
    "            query=query,\n",
    "            intent=QueryIntent.UNKNOWN,\n",
    "            confidence=0.1,  # Low confidence for unknown\n",
    "            explanation=\"No specific intent patterns matched\"\n",
    "        )\n",
    "\n",
    "# Verify our implementation satisfies the protocol\n",
    "classifier = RuleBasedQueryIntentClassifier()\n",
    "print(\"Classifier created successfully\")\n",
    "print(f\"Type: {type(classifier)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Our Implementation\n",
    "\n",
    "Let's test our classifier with various types of queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier with different query types\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How to implement a neural network?\",\n",
    "    \"Compare supervised and unsupervised learning\",\n",
    "    \"Tell me about AI ethics\",\n",
    "    \"Steps to deploy a model in production\",\n",
    "    \"Which is better: SVM or Random Forest?\",\n",
    "    \"Random question about weather\"\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "print(\"Testing Query Intent Classifier:\\n\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    result = await classifier.classify_intent(query)\n",
    "    print(f\"{i}. Query: {result.query}\")\n",
    "    print(f\"   Intent: {result.intent.value}\")\n",
    "    print(f\"   Confidence: {result.confidence:.2f}\")\n",
    "    print(f\"   Explanation: {result.explanation}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating an Enhanced RAG Service\n",
    "\n",
    "Now let's create an enhanced RAG service that uses our intent classifier to customize the retrieval process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enhanced RAG service that uses intent classification\n",
    "from src.application.services.retrieval import RetrievalService\n",
    "from src.adapters.vector.qdrant_adapter import QdrantAdapter\n",
    "from src.adapters.llm.openai_adapter import OpenAIAdapter\n",
    "\n",
    "class IntentAwareRAGService:\n",
    "    def __init__(\n",
    "        self,\n",
    "        retrieval_service: RetrievalService,\n",
    "        intent_classifier: QueryIntentClassifierPort,\n",
    "        llm_adapter: Any  # Simplified for this example\n",
    "    ):\n",
    "        self._retrieval_service = retrieval_service\n",
    "        self._intent_classifier = intent_classifier\n",
    "        self._llm_adapter = llm_adapter\n",
    "        \n",
    "    async def ask_with_intent_awareness(self, query: str, k: int = 5):\n",
    "        \"\"\"Perform RAG with intent-aware optimizations.\"\"\"\n",
    "        # First, classify the intent\n",
    "        intent_result = await self._intent_classifier.classify_intent(query)\n",
    "        print(f\"Query intent classified as: {intent_result.intent.value} (confidence: {intent_result.confidence:.2f})\")\n",
    "        \n",
    "        # Adjust retrieval strategy based on intent\n",
    "        adjusted_k = k\n",
    "        if intent_result.intent == QueryIntent.FACTUAL:\n",
    "            # For factual queries, we might want more focused results\n",
    "            adjusted_k = max(3, k // 2)\n",
    "            print(f\"Adjusted k for factual query: {adjusted_k}\")\n",
    "        elif intent_result.intent == QueryIntent.COMPARATIVE:\n",
    "            # For comparative queries, we might want more diverse results\n",
    "            adjusted_k = min(10, k * 2)\n",
    "            print(f\"Adjusted k for comparative query: {adjusted_k}\")\n",
    "        elif intent_result.intent == QueryIntent.PROCEDURAL:\n",
    "            # For procedural queries, we might want to prioritize instructional content\n",
    "            print(\"Prioritizing instructional content for procedural query\")\n",
    "        \n",
    "        # Perform the retrieval with the adjusted strategy\n",
    "        chunks = await self._retrieval_service.retrieve(query, adjusted_k)\n",
    "        \n",
    "        # Generate the response\n",
    "        # Note: This is simplified - in reality, you'd call the LLM with context\n",
    "        response = f\"Response generated with intent awareness. Intent: {intent_result.intent.value}, Chunks retrieved: {len(chunks)}\"\n",
    "        \n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"chunks\": chunks,\n",
    "            \"intent_classification\": intent_result,\n",
    "            \"adjusted_k\": adjusted_k\n",
    "        }\n",
    "\n",
    "print(\"IntentAwareRAGService defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integration with Dependency Injection\n",
    "\n",
    "Let's demonstrate how to register our new component in the dependency injection container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how we would register our component in the container\n",
    "# (This is illustrative - actual implementation would be in the bootstrap file)\n",
    "\n",
    "from src.core.bootstrap import DIContainer\n",
    "\n",
    "def demonstrate_container_registration():\n",
    "    \"\"\"Demonstrate how to register our new component in the DI container.\"\"\"\n",
    "    container = DIContainer()\n",
    "    \n",
    "    # Register our intent classifier\n",
    "    container.register_singleton(QueryIntentClassifierPort, RuleBasedQueryIntentClassifier)\n",
    "    \n",
    "    # In a real implementation, we would also register our enhanced RAG service\n",
    "    # container.register_transient(IntentAwareRAGService, IntentAwareRAGService)\n",
    "    \n",
    "    print(\"Components registered in container:\")\n",
    "    print(\"- QueryIntentClassifierPort -> RuleBasedQueryIntentClassifier\")\n",
    "    \n",
    "    # Resolve the service\n",
    "    resolved_classifier = container.resolve(QueryIntentClassifierPort)\n",
    "    print(f\"Resolved classifier type: {type(resolved_classifier).__name__}\")\n",
    "    \n",
    "    return container\n",
    "\n",
    "# Demonstrate the registration\n",
    "container = demonstrate_container_registration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Writing Tests for Our Extension\n",
    "\n",
    "Let's create unit tests for our new component following the project's testing patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example test code (this would normally go in the tests/ directory)\n",
    "import pytest\n",
    "from unittest.mock import AsyncMock, MagicMock\n",
    "\n",
    "async def test_intent_classifier_factual_query():\n",
    "    \"\"\"Test that factual queries are correctly identified.\"\"\"\n",
    "    classifier = RuleBasedQueryIntentClassifier()\n",
    "    result = await classifier.classify_intent(\"What is machine learning?\")\n",
    "    \n",
    "    assert result.intent == QueryIntent.FACTUAL\n",
    "    assert result.confidence >= 0.5\n",
    "    assert \"what is\" in result.explanation.lower()\n",
    "    \n",
    "    print(\"✓ Factual query test passed\")\n",
    "\n",
    "async def test_intent_classifier_procedural_query():\n",
    "    \"\"\"Test that procedural queries are correctly identified.\"\"\"\n",
    "    classifier = RuleBasedQueryIntentClassifier()\n",
    "    result = await classifier.classify_intent(\"How to implement a neural network?\")\n",
    "    \n",
    "    assert result.intent == QueryIntent.PROCEDURAL\n",
    "    assert result.confidence >= 0.5\n",
    "    assert \"how to\" in result.explanation.lower()\n",
    "    \n",
    "    print(\"✓ Procedural query test passed\")\n",
    "\n",
    "async def test_intent_classifier_unknown_query():\n",
    "    \"\"\"Test that unknown queries are handled properly.\"\"\"\n",
    "    classifier = RuleBasedQueryIntentClassifier()\n",
    "    result = await classifier.classify_intent(\"Random text with no clear intent\")\n",
    "    \n",
    "    assert result.intent == QueryIntent.UNKNOWN\n",
    "    assert result.confidence <= 0.3  # Lower confidence for unknown\n",
    "    \n",
    "    print(\"✓ Unknown query test passed\")\n",
    "\n",
    "# Run our tests\n",
    "await test_intent_classifier_factual_query()\n",
    "await test_intent_classifier_procedural_query()\n",
    "await test_intent_classifier_unknown_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Creating Educational Documentation\n",
    "\n",
    "Now let's create documentation for our extension to maintain the educational quality of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate documentation for our extension\n",
    "documentation = f\"\"\"\n",
    "# Query Intent Classification Extension\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Query Intent Classification extension adds the ability to categorize user queries by their intent before processing them. This allows for intent-aware optimizations in the RAG pipeline.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The extension follows the ports and adapters pattern:\n",
    "\n",
    "- **Port**: `QueryIntentClassifierPort` defines the interface\n",
    "- **Adapter**: `RuleBasedQueryIntentClassifier` provides the implementation\n",
    "- **Service**: `IntentAwareRAGService` uses the classification to optimize processing\n",
    "\n",
    "## Intent Categories\n",
    "\n",
    "The classifier recognizes these intent types:\n",
    "\n",
    "- `{QueryIntent.FACTUAL.value}`: Queries seeking factual information\n",
    "- `{QueryIntent.COMPARATIVE.value}`: Queries comparing different concepts\n",
    "- `{QueryIntent.PROCEDURAL.value}`: Queries seeking instructions/processes\n",
    "- `{QueryIntent.UNKNOWN.value}`: Queries that don't match other categories\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "# Example usage\n",
    "classifier = RuleBasedQueryIntentClassifier()\n",
    "result = await classifier.classify_intent(\"What is machine learning?\")\n",
    "print(f\"Intent: {{result.intent.value}}\")\n",
    "print(f\"Confidence: {{result.confidence}}\")\n",
    "```\n",
    "\n",
    "## Benefits\n",
    "\n",
    "1. **Optimized Retrieval**: Different query intents may benefit from different retrieval strategies\n",
    "2. **Enhanced Response**: Knowing the intent allows for tailored response generation\n",
    "3. **Analytics**: Track which types of queries are most common\n",
    "\n",
    "## Possible Improvements\n",
    "\n",
    "1. Replace the rule-based approach with a machine learning model\n",
    "2. Add more sophisticated NLP techniques\n",
    "3. Create intent-specific prompt templates\n",
    "\"\"\"\n",
    "\n",
    "# Save documentation to a file\n",
    "docs_path = project_root / \"docs\" / \"educational\" / \"query_intent_classification_extension.md\"\n",
    "with open(docs_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(documentation.strip())\n",
    "\n",
    "print(f\"Documentation saved to: {docs_path}\")\n",
    "print(\"Documentation preview:\")\n",
    "print(documentation.strip()[:500] + \"...\")  # Show first 500 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Creating an ADR (Architecture Decision Record)\n",
    "\n",
    "Let's document our architectural decision with an ADR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ADR for our extension\n",
    "adr_content = f\"\"\"\n",
    "# ADR 006: Query Intent Classification for RAG Optimization\n",
    "\n",
    "## Context\n",
    "\n",
    "Different types of queries may benefit from different retrieval and generation strategies. \n",
    "A \"one-size-fits-all\" approach to RAG processing may not be optimal for all query types.\n",
    "\n",
    "For example:\n",
    "- Factual queries might benefit from focused retrieval\n",
    "- Comparative queries might benefit from diverse retrieval\n",
    "- Procedural queries might benefit from instructional content prioritization\n",
    "\n",
    "## Decision\n",
    "\n",
    "We will implement a Query Intent Classification system that:\n",
    "1. Categorizes incoming queries into intent types (factual, comparative, procedural, unknown)\n",
    "2. Adjusts the RAG pipeline based on the detected intent\n",
    "3. Follows the ports and adapters pattern for extensibility\n",
    "4. Provides confidence scores for transparency\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. Create a `QueryIntentClassifierPort` interface\n",
    "2. Implement a rule-based classifier as the initial implementation\n",
    "3. Create an enhanced RAG service that uses intent classification\n",
    "4. Register the component in the dependency injection container\n",
    "5. Provide comprehensive tests and documentation\n",
    "\n",
    "## Consequences\n",
    "\n",
    "### Positive\n",
    "- More tailored responses for different query types\n",
    "- Potential performance improvements through optimized retrieval\n",
    "- Extensible design allows for more sophisticated classification later\n",
    "- Educational example of adding features to the RAG engine\n",
    "\n",
    "### Negative\n",
    "- Additional computational overhead for intent classification\n",
    "- Complexity increase in the RAG pipeline\n",
    "- Risk of misclassification leading to suboptimal processing\n",
    "\n",
    "## Alternatives Considered\n",
    "\n",
    "1. **No Intent Classification**: Keep the current generic approach - simpler but less optimized\n",
    "2. **ML-Based Classification**: Use a trained model for classification - more accurate but more complex\n",
    "3. **Hybrid Approach**: Combine rule-based and ML approaches - most flexible but most complex\n",
    "\n",
    "## Status\n",
    "\n",
    "Proposed → Accepted\n",
    "\n",
    "## Implementation Notes\n",
    "\n",
    "The initial implementation uses a rule-based approach for educational purposes and simplicity. \n",
    "Future iterations could replace this with a machine learning model while maintaining the same interface.\n",
    "\"\"\"\n",
    "\n",
    "# Save ADR to a file\n",
    "adr_path = project_root / \"docs\" / \"adr\" / \"006-query-intent-classification.md\"\n",
    "with open(adr_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(adr_content.strip())\n",
    "\n",
    "print(f\"ADR saved to: {adr_path}\")\n",
    "print(\"ADR preview:\")\n",
    "print(adr_content.strip()[:500] + \"...\")  # Show first 500 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "In this notebook, we demonstrated how to extend the RAG Engine Mini with a custom feature while following best practices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_points = [\n",
    "    \"Defined a clear interface (port) for our new feature\",\n",
    "    \"Implemented the feature following the existing architectural patterns\",\n",
    "    \"Created comprehensive tests for our implementation\",\n",
    "    \"Integrated our component with the dependency injection system\",\n",
    "    \"Documented our extension with educational materials\",\n",
    "    \"Created an ADR to record our architectural decisions\",\n",
    "    \"Ensured our extension maintains the educational quality of the project\"\n",
    "]\n",
    "\n",
    "print(\"Summary: Key steps for extending the RAG Engine Mini:\")\n",
    "for i, point in enumerate(summary_points, 1):\n",
    "    print(f\"{i}. {point}\")\n",
    "\n",
    "print(\"\\nThe extension is now ready to be integrated into the full codebase!\")\n",
    "\n",
    "next_steps = [\n",
    "    \"Move the implementation code to the appropriate files in src/\",\n",
    "    \"Add the component to the main dependency injection container\",\n",
    "    \"Write additional tests covering edge cases\",\n",
    "    \"Implement a more sophisticated ML-based classifier as an alternative\",\n",
    "    \"Add the feature to the API layer with appropriate endpoints\",\n",
    "    \"Create a notebook demonstrating the feature in action\"\n",
    "]\n",
    "\n",
    "print(\"\\nNext steps to fully integrate this extension:\")\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    print(f\"{i}. {step}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}