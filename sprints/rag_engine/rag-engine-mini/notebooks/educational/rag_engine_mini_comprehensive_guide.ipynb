{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Engine Mini - Hands-On Learning Notebook\n",
    "\n",
    "Welcome to the RAG Engine Mini hands-on learning notebook! This notebook will guide you through the key concepts and implementation details of the RAG system.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Project Overview](#overview)\n",
    "2. [Architecture Deep Dive](#architecture)\n",
    "3. [Domain Layer Exploration](#domain)\n",
    "4. [Application Layer Walkthrough](#application)\n",
    "5. [Adapters Layer Analysis](#adapters)\n",
    "6. [API Layer Interaction](#api)\n",
    "7. [Workers Layer Understanding](#workers)\n",
    "8. [Complete RAG Pipeline](#pipeline)\n",
    "9. [Practical Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## 1. Project Overview\n",
    "\n",
    "RAG Engine Mini is a production-grade Retrieval-Augmented Generation (RAG) starter template that bridges the gap between notebook experiments and real-world AI systems. Built with Clean Architecture principles, it provides a solid foundation for building intelligent document Q&A systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by exploring the project structure\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the project root\n",
    "project_root = Path(\"../../../\")  # Adjust based on your notebook location\n",
    "print(f\"Project Root: {project_root}\")\n",
    "\n",
    "# List main directories\n",
    "main_dirs = [d for d in project_root.iterdir() if d.is_dir()]\n",
    "print(\"\\nMain directories:\")\n",
    "for d in main_dirs:\n",
    "    print(f\"  - {d.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the source code structure\n",
    "src_dir = project_root / \"src\"\n",
    "if src_dir.exists():\n",
    "    print(\"\\nSource code structure:\")\n",
    "    for d in src_dir.iterdir():\n",
    "        if d.is_dir():\n",
    "            print(f\"  - {d.name}\")\n",
    "else:\n",
    "    print(\"Source directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"architecture\"></a>\n",
    "## 2. Architecture Deep Dive\n",
    "\n",
    "The RAG Engine Mini follows Clean Architecture principles with four main layers:\n",
    "\n",
    "1. **Domain Layer**: Pure business logic with no external dependencies\n",
    "2. **Application Layer**: Use cases, services, and ports (interfaces)\n",
    "3. **Adapters Layer**: Concrete implementations (DB, vector store, LLM, etc.)\n",
    "4. **API Layer**: FastAPI routes and controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the main.py file to understand the application structure\n",
    "main_py_path = src_dir / \"main.py\"\n",
    "if main_py_path.exists():\n",
    "    with open(main_py_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Print first 50 lines to understand the structure\n",
    "    lines = content.split('\\n')\n",
    "    print(\"First 50 lines of main.py:\")\n",
    "    for i, line in enumerate(lines[:50]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "else:\n",
    "    print(\"main.py not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the bootstrap module to understand dependency injection\n",
    "bootstrap_path = src_dir / \"core\" / \"bootstrap.py\"\n",
    "if bootstrap_path.exists():\n",
    "    with open(bootstrap_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Find the get_container function\n",
    "    lines = content.split('\\n')\n",
    "    in_function = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if '@lru_cache' in line and 'get_container' in content[i:i+100]:\n",
    "            in_function = True\n",
    "        if in_function:\n",
    "            print(f\"{i+1:2d}: {line}\")\n",
    "            if line.strip().endswith('}') and in_function:\n",
    "                break\n",
    "else:\n",
    "    print(\"bootstrap.py not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"domain\"></a>\n",
    "## 3. Domain Layer Exploration\n",
    "\n",
    "The domain layer contains pure business logic and entities. Let's explore the key domain concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the domain entities\n",
    "domain_entities_path = src_dir / \"domain\" / \"entities.py\"\n",
    "if domain_entities_path.exists():\n",
    "    with open(domain_entities_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"Domain Entities:\")\n",
    "    print(content[:1000])  # Show first 1000 characters\n",
    "else:\n",
    "    print(\"entities.py not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the TenantId value object\n",
    "import re\n",
    "\n",
    "if domain_entities_path.exists():\n",
    "    with open(domain_entities_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Extract TenantId class\n",
    "    tenant_id_pattern = r\"(@dataclass\\(frozen=True\\)\\s+class TenantId:[^}]+?\\})\"\n",
    "    matches = re.findall(tenant_id_pattern, content, re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        print(\"TenantId class definition:\")\n",
    "        print(matches[0])\n",
    "    else:\n",
    "        print(\"TenantId class not found in the expected format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"application\"></a>\n",
    "## 4. Application Layer Walkthrough\n",
    "\n",
    "The application layer orchestrates business logic through use cases and services. Let's explore the key components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the ask question hybrid use case\n",
    "ask_hybrid_path = src_dir / \"application\" / \"use_cases\" / \"ask_question_hybrid.py\"\n",
    "if ask_hybrid_path.exists():\n",
    "    with open(ask_hybrid_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"AskQuestionHybridUseCase - First 100 lines:\")\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:100]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "else:\n",
    "    print(\"ask_question_hybrid.py not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the AskHybridRequest class\n",
    "if ask_hybrid_path.exists():\n",
    "    with open(ask_hybrid_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Extract AskHybridRequest class\n",
    "    request_pattern = r\"(@dataclass\\s+class AskHybridRequest:[^}]+?\\})\"\n",
    "    matches = re.findall(request_pattern, content, re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        print(\"AskHybridRequest class definition:\")\n",
    "        print(matches[0])\n",
    "    else:\n",
    "        print(\"AskHybridRequest class not found in the expected format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adapters\"></a>\n",
    "## 5. Adapters Layer Analysis\n",
    "\n",
    "The adapters layer provides concrete implementations for the ports defined in the application layer. Let's explore some key adapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the Qdrant vector store adapter\n",
    "qdrant_adapter_path = src_dir / \"adapters\" / \"vector\" / \"qdrant_store.py\"\n",
    "if qdrant_adapter_path.exists():\n",
    "    with open(qdrant_adapter_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"QdrantVectorStore - First 50 lines:\")\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:50]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "else:\n",
    "    print(\"qdrant_store.py not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the OpenAI LLM adapter\n",
    "openai_adapter_path = src_dir / \"adapters\" / \"llm\" / \"openai_llm.py\"\n",
    "if not openai_adapter_path.exists():\n",
    "    # Try alternative path\n",
    "    openai_adapter_path = src_dir / \"adapters\" / \"llm\" / \"openai_llm.py\"\n",
    "    \n",
    "if openai_adapter_path.exists():\n",
    "    with open(openai_adapter_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"OpenAILLM - First 50 lines:\")\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:50]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "else:\n",
    "    print(\"OpenAI LLM adapter not found\")\n",
    "    \n",
    "    # Look for any LLM adapter\n",
    "    llm_dir = src_dir / \"adapters\" / \"llm\"\n",
    "    if llm_dir.exists():\n",
    "        print(\"\\nAvailable LLM adapters:\")\n",
    "        for adapter in llm_dir.iterdir():\n",
    "            if adapter.suffix == '.py':\n",
    "                print(f\"  - {adapter.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"api\"></a>\n",
    "## 6. API Layer Interaction\n",
    "\n",
    "The API layer exposes functionality through FastAPI routes. Let's explore the key endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the ask route\n",
    "ask_route_path = src_dir / \"api\" / \"v1\" / \"routes_ask.py\"\n",
    "if ask_route_path.exists():\n",
    "    with open(ask_route_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"Routes Ask - Full content:\")\n",
    "    print(content)\n",
    "else:\n",
    "    print(\"routes_ask.py not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dependencies module\n",
    "deps_path = src_dir / \"api\" / \"v1\" / \"deps.py\"\n",
    "if deps_path.exists():\n",
    "    with open(deps_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"API Dependencies:\")\n",
    "    print(content)\n",
    "else:\n",
    "    print(\"deps.py not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"workers\"></a>\n",
    "## 7. Workers Layer Understanding\n",
    "\n",
    "The workers layer handles background processing tasks using Celery. Let's explore the key tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the tasks module\n",
    "tasks_path = src_dir / \"workers\" / \"tasks.py\"\n",
    "if tasks_path.exists():\n",
    "    with open(tasks_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    print(\"Celery Tasks - First 100 lines:\")\n",
    "    lines = content.split('\\n')\n",
    "    for i, line in enumerate(lines[:100]):\n",
    "        print(f\"{i+1:2d}: {line}\")\n",
    "else:\n",
    "    print(\"tasks.py not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "## 8. Complete RAG Pipeline\n",
    "\n",
    "Now let's simulate the complete RAG pipeline by walking through the key steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simplified simulation of the RAG pipeline\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "# Simplified domain entities\n",
    "@dataclass\n",
    "class DocumentId:\n",
    "    value: str\n",
    "\n",
    "@dataclass\n",
    "class TenantId:\n",
    "    value: str\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    id: str\n",
    "    text: str\n",
    "    score: float = 0.0\n",
    "\n",
    "# Simplified RAG pipeline simulation\n",
    "class RAGPipelineSimulator:\n",
    "    def __init__(self):\n",
    "        self.documents = {}\n",
    "        self.chunks = []\n",
    "        self.vectors = {}  # Mock vector store\n",
    "        \n",
    "    def upload_document(self, tenant_id: str, content: str, filename: str):\n",
    "        print(f\"Step 1: Uploading document '{filename}' for tenant {tenant_id}\")\n",
    "        \n",
    "        # Create document ID\n",
    "        import uuid\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Store document\n",
    "        self.documents[doc_id] = {\n",
    "            'tenant_id': tenant_id,\n",
    "            'content': content,\n",
    "            'filename': filename,\n",
    "            'status': 'uploaded'\n",
    "        }\n",
    "        \n",
    "        print(f\"  Created document ID: {doc_id}\")\n",
    "        return doc_id\n",
    "    \n",
    "    def index_document(self, doc_id: str):\n",
    "        print(f\"\\nStep 2: Indexing document {doc_id}\")\n",
    "        \n",
    "        # Update status\n",
    "        self.documents[doc_id]['status'] = 'processing'\n",
    "        print(\"  Status updated to 'processing'\")\n",
    "        \n",
    "        # Simulate text extraction\n",
    "        content = self.documents[doc_id]['content']\n",
    "        print(f\"  Extracted text (first 50 chars): {content[:50]}...\")\n",
    "        \n",
    "        # Simulate chunking\n",
    "        print(\"  Performing chunking...\")\n",
    "        # Simple chunking: split by sentences\n",
    "        sentences = content.split('. ')\n",
    "        chunks = []\n",
    "        for i, sentence in enumerate(sentences[:5]):  # Just first 5 for demo\n",
    "            chunk_id = f\"{doc_id}_chunk_{i}\"\n",
    "            chunk = Chunk(id=chunk_id, text=sentence.strip())\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            # Simulate embedding\n",
    "            # In real system, this would call embedding API\n",
    "            vector = [float(ord(c) % 100) for c in sentence[:20]]  # Mock vector\n",
    "            self.vectors[chunk_id] = vector\n",
    "        \n",
    "        self.chunks.extend(chunks)\n",
    "        print(f\"  Created {len(chunks)} chunks and stored vectors\")\n",
    "        \n",
    "        # Update status\n",
    "        self.documents[doc_id]['status'] = 'indexed'\n",
    "        print(f\"  Status updated to 'indexed'\")\n",
    "        \n",
    "    def search(self, query: str, top_k: int = 3):\n",
    "        print(f\"\\nStep 3: Searching for query: '{query}'\")\n",
    "        \n",
    "        # Simulate query embedding\n",
    "        query_vector = [float(ord(c) % 100) for c in query[:20]]  # Mock vector\n",
    "        print(f\"  Generated query vector (first 10 dims): {query_vector[:10]}\")\n",
    "        \n",
    "        # Simulate similarity search\n",
    "        print(\"  Performing similarity search...\")\n",
    "        \n",
    "        # Calculate mock similarities\n",
    "        results = []\n",
    "        for chunk in self.chunks:\n",
    "            # Calculate mock similarity (in real system, this would be cosine similarity)\n",
    "            similarity = sum(min(q, v) for q, v in zip(query_vector, self.vectors[chunk.id]))\n",
    "            chunk.score = similarity\n",
    "            results.append(chunk)\n",
    "        \n",
    "        # Sort by score and return top-k\n",
    "        results.sort(key=lambda x: x.score, reverse=True)\n",
    "        top_results = results[:top_k]\n",
    "        \n",
    "        print(f\"  Found {len(top_results)} relevant chunks\")\n",
    "        return top_results\n",
    "    \n",
    "    def generate_answer(self, query: str, context_chunks: List[Chunk]):\n",
    "        print(f\"\\nStep 4: Generating answer for query: '{query}'\")\n",
    "        \n",
    "        # Build context from chunks\n",
    "        context = \" \".join([chunk.text for chunk in context_chunks])\n",
    "        print(f\"  Context length: {len(context)} characters\")\n",
    "        \n",
    "        # Simulate LLM generation\n",
    "        print(\"  Generating answer with LLM...\")\n",
    "        time.sleep(0.5)  # Simulate processing time\n",
    "        \n",
    "        # Mock answer generation\n",
    "        answer = f\"Based on the provided context, the answer to '{query}' is: This is a simulated answer based on the context: '{context[:100]}...'\"\n",
    "        \n",
    "        print(f\"  Generated answer: {answer[:100]}...\")\n",
    "        return answer\n",
    "    \n",
    "    def rag_pipeline(self, tenant_id: str, query: str, doc_content: str = None):\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING RAG PIPELINE SIMULATION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Upload document (if provided)\n",
    "        doc_id = None\n",
    "        if doc_content:\n",
    "            doc_id = self.upload_document(tenant_id, doc_content, \"sample_doc.txt\")\n",
    "        \n",
    "        # Step 2: Index document (if uploaded)\n",
    "        if doc_id:\n",
    "            self.index_document(doc_id)\n",
    "        \n",
    "        # Step 3: Search\n",
    "        search_results = self.search(query)\n",
    "        \n",
    "        # Step 4: Generate answer\n",
    "        answer = self.generate_answer(query, search_results)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RAG PIPELINE COMPLETED\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            'answer': answer,\n",
    "            'sources': [chunk.id for chunk in search_results],\n",
    "            'query': query\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the RAG pipeline simulation\n",
    "simulator = RAGPipelineSimulator()\n",
    "\n",
    "# Sample document content\n",
    "sample_doc = \"\"\"\n",
    "Artificial Intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Colloquially, the term \"artificial intelligence\" is often used to describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n",
    "\n",
    "As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says \"AI is whatever hasn't been done yet.\"\n",
    "\"\"\"\n",
    "\n",
    "# Run the pipeline\n",
    "result = simulator.rag_pipeline(\n",
    "    tenant_id=\"user_123\",\n",
    "    query=\"What is artificial intelligence?\",\n",
    "    doc_content=sample_doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercises\"></a>\n",
    "## 9. Practical Exercises\n",
    "\n",
    "Now let's try some exercises to reinforce your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Modify the simulator to add reranking\n",
    "print(\"EXERCISE 1: Enhance the RAG simulator with reranking functionality\")\n",
    "print(\"\\nCurrently, our simulator only does basic similarity search.\")\n",
    "print(\"Try to implement a reranking step that reorders results based on\")\n",
    "print(\"how well they match the query keywords.\")\n",
    "\n",
    "# TODO: Implement reranking functionality\n",
    "# Hint: You could implement a simple keyword matching score\n",
    "# and combine it with the similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Add multi-tenancy validation\n",
    "print(\"EXERCISE 2: Add tenant isolation validation\")\n",
    "print(\"\\nModify the simulator to ensure that one tenant cannot access\")\n",
    "print(\"another tenant's documents or vectors.\")\n",
    "\n",
    "# TODO: Add tenant validation to all methods\n",
    "# Hint: Check tenant_id in all operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Implement caching\n",
    "print(\"EXERCISE 3: Add embedding caching\")\n",
    "print(\"\\nAdd a cache to store previously computed embeddings\")\n",
    "print(\"to avoid recomputing them for the same text.\")\n",
    "\n",
    "# TODO: Add embedding cache to the simulator\n",
    "# Hint: Use a dictionary to store text -> vector mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored:\n",
    "\n",
    "1. **Project Overview**: Understanding the RAG Engine Mini architecture\n",
    "2. **Clean Architecture**: How the system separates concerns into layers\n",
    "3. **Domain Layer**: Pure business logic with tenant isolation\n",
    "4. **Application Layer**: Use cases that orchestrate business logic\n",
    "5. **Adapters Layer**: Concrete implementations of external services\n",
    "6. **API Layer**: FastAPI endpoints exposing functionality\n",
    "7. **Workers Layer**: Background processing with Celery\n",
    "8. **Complete RAG Pipeline**: From document upload to answer generation\n",
    "9. **Hands-on Practice**: Simulating the RAG pipeline and exercises\n",
    "\n",
    "This system demonstrates production-ready patterns for building scalable RAG applications with proper separation of concerns, multi-tenancy, and observability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}